# Section 17: Surprising Cross-Trust Dynamics
## Analysis Date: 2025-09-02T21:16:55

### Question 17.1: Global Trust Rankings
**Finding:** Based on aggregated agreement scores, AI animal translators show mixed trust (43.6% somewhat trust, 18.1% somewhat distrust), while social media shows higher distrust (32.2% somewhat distrust, 22.0% strongly distrust). Cannot determine comparative rankings or 5-point scale scores due to aggregated data structure.

**Method:** Analysis of segment-level agreement scores for trust questions from 1005 participants with PRI >= 0.3.

**Details:** Available data shows AI translator trust distribution: 43.6% somewhat trust, 27.9% neutral, 18.1% somewhat distrust, 7.1% strongly trust, 3.3% strongly distrust. Social media trust is lower: 32.2% somewhat distrust, 26.7% neutral, 22.0% strongly distrust, 16.9% somewhat trust, 2.3% strongly trust. The aggregated nature of the data prevents establishing a definitive trust hierarchy or calculating mean scores on a 5-point scale. Individual-level comparisons between different trust targets cannot be determined.

### Question 17.2: AI vs. Doctors Trust  
**Finding:** Cannot determine individual-level comparisons between AI translator and doctor trust due to aggregated data structure. Age-based segment scores show varying trust patterns but individual preferences cannot be calculated.

**Method:** Attempted cross-tabulation of trust questions; limited by segment-level aggregation.

**Details:** The aggregated data structure prevents calculating percentages who trust AI more than doctors. Available segment scores show age variations in AI translator trust but cannot be directly compared to doctor trust scores at the individual level. The database contains agreement scores for demographic segments but lacks the individual response linkages needed to determine relative trust preferences or calculate correlation with AI enthusiasm.

### Question 17.3: Social Media and AI Distrust
**Finding:** Both social media and AI translators show mixed trust patterns in aggregated data. Social media shows 54.2% distrust (somewhat + strongly) versus AI translators' 21.4% distrust. Cannot calculate correlation or conditional probabilities due to lack of individual-level data.

**Method:** Comparison of segment-level agreement scores for social media and AI translator trust questions.

**Details:** Social media shows higher distrust (54.2% somewhat/strongly distrust) compared to AI translators (21.4% somewhat/strongly distrust). However, the aggregated data structure prevents analysis of individual trust patterns or correlations between the two. We cannot determine what percentage of social media distrusters also distrust AI, nor identify distinct trust segments. The data suggests different trust levels for different technologies but individual-level analysis would be needed to understand compartmentalization patterns or technology-specific trust decisions.