ID,Type,Text,Summary
53997aea-a414-4e43-9dd8-a72a5964dbcf,Conversation,How much do you trust AI?,"Across more than 1,000 participants, AI is highly visible and routinely used—especially daily for work and personal tasks—yet unsupervised real‑world delegation remains minority behavior. Perceived impacts skew positive for daily life, cost of living, free time, and community well‑being, but participants are pessimistic about “good jobs,” split on purpose, and ambivalent to cautiously positive about chatbots; they view autonomous real‑world AI and human‑outperforming systems more skeptically. Trust is highest in family doctors and public research, moderate for utilities and small businesses, mixed for AI companies, and lowest for social media and government/elected representatives. People “somewhat trust” AI chatbots but demand verification, transparency, and human oversight; many think AI could decide better than representatives, though uncertainty is large. Users want consent‑by‑default control, strict data governance (especially for private/group messages and contacts), the ability to view/edit/delete data, clear sources and step‑by‑step rationales, immediate refunds for financial errors, and automatic human handoff on mistakes. For a family wellbeing AI, participants prefer permission over speed, helpful/respectful tone, strong personalization with memory, culturally aware language, and domestic developers increase comfort; they allow proactive, privacy‑preserving suggestions for health, nutrition, and bills but reject autonomous decisions on money, contracts, medical treatment, children, or identity‑based communications. The biggest risks cited are privacy breaches, loss of control, and harmful or unethical decisions; accountability should rest primarily with the builder. Overall sentiment is cautious optimism—users report real efficiency gains and frequent use, pair them with strong safeguards and human‑in‑the‑loop expectations, and remain wary where stakes, opacity, or data sharing rise."
f94dae77-595e-4766-84eb-6aaaef59cb26,Ask Experience,Please enter your Prolific ID,"The Remesh opinion question asked participants to enter their Prolific ID, eliciting brief, identifier-style responses rather than narrative content. Participation was broad across population segments, and the dataset reflects high compliance with the prompt, with most entries appearing as alphanumeric strings that resemble Prolific IDs (e.g., “665017cd16c82792f5b364ef,” “66c74868a5ed218ada5b93a1,” “5e7d2f16e863ba0d96dc610f”). The presence of repeated submissions (e.g., “66e34b8c7794ea31ff3f31cf” appears more than once) and occasional non-standard entries (e.g., “ocharo”) indicates limited variability in format adherence alongside isolated deviations. Representative responses span older-looking IDs (e.g., “5c41e9263be7b70001fcf4ab”) and newer-looking IDs (e.g., “66ca1c321a8e2b7f6bf01c79”), suggesting a mix of long-tenured and newer participants. Overall, findings point to a dataset dominated by properly formatted alphanumeric identifiers, with notable consistency in structure and isolated anomalies that may merit data validation checks."
345c2b91-6de9-4c51-8288-922f9a39a650,Poll,"Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?","In this Remesh poll question, 1,046 participants across 231 population segments were asked: ""Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?"" The findings indicate a notable level of AI salience in everyday contexts. A large majority reported frequent exposure: 76.0% selected ""daily"" and 21.0% chose ""weekly,"" yielding 97.0% noticing AI at least weekly. Only 3.0% selected ""monthly,"" while 0.0% chose ""annually"" and 0.0% chose ""never,"" underscoring the near-universal visibility of AI systems in recent months. These results suggest that AI has become a routine feature of participants’ daily experiences, with the ""daily"" share (76.0%) notably exceeding the combined less-frequent categories (24.0%). The absence of ""annually"" and ""never"" responses supports the conclusion that encounters with AI are pervasive rather than sporadic."
7a5f9a6d-579b-4117-bb89-c4b92514e466,Poll,"Thinking about the last three months, how often, if at all, have you noticed human interactions which have been replaced with automated systems?","In this Remesh poll question fielded to 1,046 participants across 231 population segments, respondents were asked: ""Thinking about the last three months, how often, if at all, have you noticed human interactions which have been replaced with automated systems?"" Overall, the modal response was ""weekly"" at 46.0%, indicating that almost half of participants encounter automation displacing human interactions on a routine basis. A notable 26.0% reported ""daily"" exposure, suggesting frequent, ongoing contact with automation in everyday contexts. An additional 20.0% selected ""monthly,"" implying periodic but recurrent observation. Only 3.0% chose ""annually"" and 4.0% reported ""never,"" underscoring that reports of rare or nonexistent exposure are uncommon. Taken together, 92.0% of participants selected ""daily,"" ""weekly,"" or ""monthly,"" pointing to widespread and regular visibility of automation replacing human interactions over the past quarter. As one key distributional marker, the combined share of ""daily"" and ""weekly"" responses (72.0%) notably exceeds infrequent categories, reinforcing the perception that such changes are routine rather than exceptional."
56f4b20b-87f9-4aa0-afed-adaffe5fbd91,Poll,"Thinking about the last three months, how often, if at all, have you been expected to use an AI system at work?","In this Remesh poll question (n=1,045) spanning 231 population segments, participants were asked: “Thinking about the last three months, how often, if at all, have you been expected to use an AI system at work?” Results indicate widespread and frequent expectations to use AI at work. A plurality reported daily expectations (“daily”: 43.0%), and an additional one-third reported weekly use (“weekly”: 32.0%), suggesting that 75.0% encounter at least weekly expectations. Less frequent expectations were comparatively rare (“monthly”: 10.0%; “annually”: 1.0%), while a minority reported no expectation to use AI (“never”: 14.0%). These findings point to a notable integration of AI into routine work processes, with daily use emerging as the modal experience. The distribution—“daily” at 43.0% and “weekly” at 32.0%—underscores that regular interaction with AI systems is now a common workplace expectation across participant segments, while the 14.0% reporting “never” highlights a subset of roles or environments where AI expectations have yet to materialize."
df84db18-d207-47ae-ab9a-2f3339642576,Poll,"Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at work?","In the Remesh poll question on workplace AI adoption over the past three months, a total of 1,045 participants across 231 population segments reported frequent voluntary use. A majority (51.0%) said they use AI “daily,” indicating routine integration into work tasks. An additional 32.0% reported “weekly” use, while 7.0% selected “monthly” and 1.0% chose “annually,” suggesting more occasional engagement. Only 9.0% said “never,” underscoring broad penetration. Overall, 91.0% reported at least some use. The distribution highlights a notable normalization of AI tools in everyday workflows, with the highest intensity reflected in the “daily” group. The pattern—“daily” (51.0%), “weekly” (32.0%), “monthly” (7.0%), “annually” (1.0%), and “never” (9.0%)—suggests that adoption is concentrated among frequent users, with limited resistance or barriers among participants."
da2fed27-d29a-416d-ab49-a5c2c037187b,Poll,"Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in your personal life?","In this Remesh poll question fielded among 1,045 participants across 231 population segments, reported personal use of AI systems in the prior three months is notably frequent. A majority, 51.0%, selected “daily,” while another 35.0% reported “weekly,” indicating that 86.0% engage with AI at least weekly. Less frequent use was comparatively limited: 9.0% chose “monthly,” 1.0% “annually,” and only 3.0% “never.” These findings suggest widespread and routine adoption, with the central tendency skewed toward high-frequency use. The proportion claiming any use (97.0%) is notable, and daily use alone constitutes a slim majority (“daily” at 51.0%). Weekly use (“weekly” at 35.0%) forms the second-largest cohort, underscoring that regular engagement with AI has become mainstream among participants."
770c5dc2-7f4a-4fd0-84eb-351ff475647e,Poll,"Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice on a sensitive personal issue or to get emotional support?","In the Remesh poll question fielded to 1,044 participants across 231 population segments, reported engagement with AI for advice on sensitive personal issues or emotional support is widespread and varied in frequency. A combined 64.0% reported some level of engagement in the last three months, while 30.0% reported 'never'. Regular usage is notable: 12.0% reported 'daily' and 27.0% reported 'weekly', indicating that nearly four in ten participants (39.0%) use AI for these purposes at least weekly. Another 25.0% reported 'monthly', suggesting periodic but recurring reliance, and 6.0% reported 'annually', indicating infrequent use. The distribution highlights a notable adoption gradient, with a substantial minority engaging at high frequency ('daily' or 'weekly') and a comparable share opting out entirely ('never' at 30.0%). These findings suggest AI is serving as a recurring support resource for many, while a notable portion remains disengaged."
daef59cb-9613-4468-81a8-d31ec8318ab7,Poll,"Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an action in the real world on your behalf without your supervision?","In this Remesh poll question, 1,042 participants across 231 population segments reported how often, in the past three months, they interacted with AI systems to complete unsupervised real‑world actions. Adoption appears concentrated among a minority: 42% reported some level of use, while a majority—""58.0%""—selected ""never."" Among users, reported frequency skews toward intermittent engagement: ""17.0%"" chose ""weekly"" and ""14.0%"" chose ""monthly,"" compared with ""8.0%"" reporting ""daily"" use. Low ongoing reliance is reflected in the small share selecting ""annually"" (""3.0%""). The distribution suggests that while routine, high-frequency use exists among a notable minority, mainstream uptake remains limited, with a large non-user base. The weekly share outpaces daily by more than two-to-one (""17.0%"" vs. ""8.0%""), indicating habitual but not constant use patterns. Overall, the findings point to early-stage diffusion marked by notable awareness and trial among some participants, yet with persistent barriers or limited perceived need for unsupervised, real‑world AI delegation for most."
cf6fce2e-8427-4304-ab0b-c5d7649ab276,Poll,"In the past month, did you use an AI assistant to take actions for you? (for example: send a message, book or pay for something, submit a form, control a device, or run a script) Specifically where the AI actually carried out the action, not only gave advice or text for you to use.","This Remesh poll question asked 1,041 participants whether, in the past month, they used an AI assistant to take actions on their behalf (e.g., sending messages, booking services, paying, submitting forms, controlling devices, or running scripts), emphasizing that the AI must have executed the action rather than only providing advice. Participants could select multiple options across 12 categories and belonged to 231 population segments.Overall, action-taking by AI appears present but uneven across domains. A notable 32.0% selected ""None of the above,"" indicating about one-third did not delegate any actions to AI. Among those who did, the highest reported categories were ""Automated tasks or workflows (code, scripts, connected apps/services)"" at 29.0%, ""Created or published content (documents, websites, articles)"" at 29.0%, and ""Researched options and took action (compared, then ordered/booked/hired)"" at 28.0%. Communication tasks were also common: 22.0% reported ""Communicated on your behalf (sent messages, emails, made calls, posted to social media)."" Operational and transactional uses were less prevalent but present: 14.0% ""Scheduled or booked services,"" 11.0% ""Submitted official documents,"" 10.0% ""Managed work, farm, or business operations,"" and 9.0% ""Completed financial transactions."" More specialized or community-oriented uses were lower: 12.0% ""Assisted with accessibility or health needs,"" 7.0% ""Organized community or group activities,"" and 5.0% ""Other.""Taken together, the results indicate broad but varied adoption: while nearly one-third report no action-taking use, roughly two-thirds engaged AI for at least one direct action, with notable emphasis on workflow automation, content creation, and end-to-end research-to-action tasks. Reported figures such as ""29.0% automated tasks,"" ""29.0% created or published content,"" and ""22.0% communicated on your behalf"" underscore a pattern of practical, productivity-oriented applications, whereas lower rates for financial transactions (9.0%) and community organizing (7.0%) suggest more cautious or niche use in higher-stakes or collective contexts."
dc9c2bdc-d48d-4edc-9b5e-6f5d2faba4fb,Ask Experience,"What has been the most noticeable change in your daily life, if any, as a result of AI in the past year?","Context: A Remesh opinion question asked participants, “What has been the most noticeable change in your daily life, if any, as a result of AI in the past year?” Participants offered narrative responses and self-categorized them. Findings: Across representative responses, participants describe AI as increasingly embedded in everyday routines, with recurring themes of time savings, efficiency, and easier access to information. Many characterize AI as a daily tool for drafting, brainstorming, organizing, and translation, citing concrete benefits such as “increased efficiency and convenience,” “faster” completion of routine tasks, and “quick, reliable help with tasks.” Respondents frequently report improved productivity at work and in personal life, including drafting emails, structuring ideas, summarizing information, planning travel, managing schedules, and receiving reminders. Several note enhanced learning support and study effectiveness through tools like “ChatGPT, Co-Pilot,” and streamlined research with “direct answers” that reduce the need for “boring researches.” Some point to broader ecosystem shifts, including AI-driven search results, writing assistants, chatbots, and “personalized recommendations” in social media and streaming. A subset raises concerns about authenticity and privacy, describing AI-written emails as “disingenuous,” and expressing worry that “sensitive data can be accessed by unauthorized personnel” and potential impacts on youth development and creativity. Others report limited or no change (“none”) or mixed feelings about increased reliance on AI that “has made life more efficient but also less personal.” Overall, the narratives emphasize notable gains in speed, clarity, and convenience—“work gets completed faster,” “I sleep more and relax more”—balanced by apprehensions about data risk, depersonalization, and overreliance."
0625fc89-8b0d-432c-a526-b3588b7edbeb,Poll,"Considering both potential benefits and risks, how do you assess the overall impact on society of messaging apps?","In the Remesh poll question assessing the perceived societal impact of messaging apps, 1,034 participants across 231 population segments provided single-choice responses. The distribution indicates a net-positive orientation: 55.0% reported benefits outweigh risks (""Benefits slightly outweigh risks"" 32.0%; ""Benefits far outweigh risks"" 23.0%), compared with 17.0% reporting the opposite (""Risks slightly outweigh benefits"" 11.0%; ""Risks far outweigh benefits"" 6.0%). A notable 27.0% judged impacts as balanced (""Risks and benefits are equal""). This pattern suggests a broad, though not unanimous, optimism about messaging apps’ societal effects. The midpoint response indicates considerable ambivalence among over a quarter of participants, while the combined pro-benefit share more than triples the combined risk-dominant share, pointing to a notable tilt toward perceived benefits. As one framing from the response options captures, many participants see “Benefits slightly outweigh risks” (32.0%), with a substantial minority asserting “Benefits far outweigh risks” (23.0%). Overall, the data signal a notably positive net assessment, tempered by meaningful concerns and a substantial segment perceiving a balanced trade-off."
b894e8ff-78fd-4213-b0a3-8d81cde284b2,Poll,"Considering both potential benefits and risks, how do you assess the overall impact on society of social media apps?","In the Remesh poll question assessing the overall societal impact of social media apps, 1,034 participants across 231 population segments provided single-select responses. The distribution reveals a centered but slightly positive tilt: 30.0% reported that “Risks and benefits are equal,” the modal response; 24.0% said “Benefits slightly outweigh risks”; and 10.0% chose “Benefits far outweigh risks,” yielding 34.0% who see a net benefit. Conversely, 22.0% indicated “Risks slightly outweigh benefits” and 14.0% said “Risks far outweigh benefits,” totaling 36.0% perceiving a net risk. The near balance between net-benefit (34.0%) and net-risk (36.0%) views, combined with the largest share selecting equilibrium (30.0%), suggests a broadly ambivalent landscape with a marginal lean toward concern. Notable findings include the relatively small share at the extremes—“Benefits far outweigh risks” (10.0%) versus “Risks far outweigh benefits” (14.0%)—indicating polarization exists but is not dominant. In sum, participants’ assessments are mixed, centered on equivalence, with a slight skew toward perceiving more risks than benefits overall."
0a526274-32bc-4566-86c0-5015e80208c1,Poll,"Considering both potential benefits and risks, how do you assess the overall impact on society of AI chatbots?","In a Remesh poll question assessing perceptions of AI chatbots’ overall societal impact, 1,033 participants across 231 population segments expressed a cautiously positive outlook. A plurality viewed benefits as outweighing risks: 33.0% reported “Benefits slightly outweigh risks,” and 20.0% selected “Benefits far outweigh risks,” totaling 53.0% favoring a net-positive impact. A notable 25.0% indicated balance (“Risks and benefits are equal”). Negative assessments were smaller in aggregate: 15.0% chose “Risks slightly outweigh benefits,” and 7.0% said “Risks far outweigh benefits,” summing to 22.0%. These distributions suggest a skew toward optimism, with more than half reporting a favorable balance while one-quarter remain neutral. The findings indicate that, while concerns persist, especially on the margin, participants lean toward net benefits—“Benefits slightly outweigh risks” (33.0%) being the most common single response—pointing to a notable though cautious endorsement of AI chatbots’ societal impact."
a5d5196f-4f5e-4b57-a26f-3baedb054cb6,Poll,"Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems that can perform tasks in the real world without human supervision?","In the Remesh poll question assessing the societal impact of AI systems that can perform real-world tasks without human supervision, 1,033 participants across 231 population segments provided single-select responses. The distribution indicates a cautious to skeptical outlook: 46.0% perceive risks as outweighing benefits (""Risks far outweigh benefits"" at 20.0% and ""Risks slightly outweigh benefits"" at 26.0%), while 29.0% see benefits outweighing risks (""Benefits slightly outweigh risks"" at 20.0% and ""Benefits far outweigh risks"" at 9.0%). A quarter (25.0%) report neutrality, selecting ""Risks and benefits are equal."" This pattern suggests a notable risk-sensitive stance, with a modest pro-benefit minority and a substantial neutral bloc. The 17-point gap between those prioritizing risks (46.0%) and those prioritizing benefits (29.0%) underscores a notably cautious public orientation toward unsupervised real-world AI. Qualitative interpretation is reinforced by the balanced center—""Risks and benefits are equal"" (25.0%)—which indicates ambivalence and potential responsiveness to evidence on safety, governance, and demonstrable value. Overall, the results highlight a notable trust and safety barrier for deployment at scale, with sentiment concentrated toward risk awareness rather than optimism."
2617912e-463a-4fb4-8781-0ada7a788fb2,Poll,"Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems that can outperform humans on most economically valuable work?","In this Remesh poll question assessing the perceived societal impact of AI systems that can outperform humans on most economically valuable work, responses from 1,033 participants distributed across 231 population segments reveal a polarized yet broadly balanced outlook. A combined 44.0% emphasize downside risk (""Risks far outweigh benefits"" at 20.0% and ""Risks slightly outweigh benefits"" at 24.0%), while 32.0% emphasize upside potential (""Benefits slightly outweigh risks"" at 21.0% and ""Benefits far outweigh risks"" at 11.0%). A notable 24.0% adopt a neutral stance (""Risks and benefits are equal""). The modal positions are tied between cautious skepticism and neutrality (both at 24.0%). The distribution indicates a cautious tilt toward risk with limited strong optimism, as reflected in direct selections such as ""Risks far outweigh benefits"" (20.0%) and ""Benefits far outweigh risks"" (11.0%). Overall, the findings suggest a public leaning toward risk awareness with notable ambivalence, highlighting the need for safeguards and transparent governance to build confidence in advanced AI’s societal role."
84779ba6-1191-4840-862d-e9eacc2defe9,Poll,"To what extent, if at all, do you generally trust governments to do what is right?","In a Remesh poll question assessing general trust in governments to “do what is right,” 1,033 participants across 231 population segments provided single-select responses. Overall trust was low, with a combined 55.0% expressing distrust: 22.0% “Strongly Distrust” and 33.0% “Somewhat Distrust.” By contrast, 27.0% expressed trust: 24.0% “Somewhat Trust” and 3.0% “Strongly Trust.” A neutral stance was reported by 18.0% (“Neither Trust Nor Distrust”). The modal response was “Somewhat Distrust” at 33.0%, indicating a notable tilt toward skepticism. Strong positive trust was rare (“Strongly Trust,” 3.0%), while strong negative trust was more prevalent (“Strongly Distrust,” 22.0%). These patterns suggest a distrust-skewed distribution, with most participants clustered in the skeptical middle: “Somewhat Distrust” (33.0%) and “Somewhat Trust” (24.0%), and a smaller neutral bloc (18.0%). The findings notably highlight limited strong confidence in government action and a sizable reservoir of distrust among participants."
5710c67a-adf2-469d-aa92-1b6961e2b9de,Poll,"To what extent, if at all, do you generally trust small businesses to do what is right?","In this Remesh poll question assessing general trust in small businesses to “do what is right,” 1,033 participants across 231 population segments provided single-select responses. Overall trust leaned positive: a combined 53.0% reported trust (“Somewhat Trust” 44.0%; “Strongly Trust” 9.0%). Neutrality was also notable, with 28.0% selecting “Neither Trust Nor Distrust.” Distrust was present but less prevalent, totaling 19.0% (“Somewhat Distrust” 16.0%; “Strongly Distrust” 3.0%). These findings suggest small businesses enjoy a broad base of moderate confidence among participants, with a substantial middle segment expressing neutrality. As one might summarize from the distribution, the trust profile is “Somewhat Trust”-heavy (44.0%), while firm endorsements are smaller (“Strongly Trust” 9.0) and strong skepticism is rare (“Strongly Distrust” 3.0). The pattern indicates a notable tilt toward cautious approval rather than polarized views."
e97db5cf-118a-4016-ab42-fabb172ce5cd,Poll,"To what extent, if at all, do you generally trust large corporations to do what is right?","In the Remesh poll question assessing general trust in large corporations to “do what is right,” responses from 1,033 participants across 231 population segments reveal overall skepticism. A combined 52.0% express distrust (24.0% “Strongly Distrust” and 28.0% “Somewhat Distrust”), while 27.0% express trust (22.0% “Somewhat Trust” and 5.0% “Strongly Trust”). Neutral sentiment accounts for 20.0% (“Neither Trust Nor Distrust”). The distrust skew is notable, with “Strongly Distrust” (24.0%) outpacing “Strongly Trust” (5.0%) by nearly a 5-to-1 ratio, suggesting that, while a meaningful minority offers cautious approval, a notably larger share remains wary. As one distributional highlight, “Somewhat Distrust” (28.0%) is the single most selected option, indicating that reservations are more often moderate than absolute. These findings point to a trust deficit, with neutral and soft trust segments potentially movable, but a notable hard-distrust bloc anchoring overall sentiment."
7dd026f5-c70d-4126-bc78-68e823880f65,Poll,"To what extent, if at all, do you generally trust social media companies to do what is right?","In this Remesh poll question assessing general trust in social media companies to do what is right, 1,033 participants across 231 population segments provided single-select responses. The distribution reveals a notable trust deficit: a combined 64.0% express distrust, with 32.0% selecting “Strongly Distrust” and 32.0% “Somewhat Distrust.” Neutral sentiment (“Neither Trust Nor Distrust”) accounts for 20.0%. Only 16.0% express trust, split between “Somewhat Trust” at 13.0% and “Strongly Trust” at 3.0%. These findings indicate a concentrated skepticism, with the most common responses at the extremes of distrust. The net distrust margin (64.0% distrust vs. 16.0% trust) is 48 percentage points, underscoring a notable imbalance toward negative evaluations. As one could summarize from the response pattern: “Strongly Distrust” (32.0%) and “Somewhat Distrust” (32.0%) dominate, while “Strongly Trust” remains rare at 3.0%, suggesting that positive confidence in social media companies is limited among participants."
87a7c03c-831b-4463-a0eb-1a40b2b47a17,Poll,"To what extent, if at all, do you generally trust companies building AI to do what is right?","In this Remesh poll question assessing general trust in companies building AI to ""do what is right,"" 1,033 participants across 231 population segments provided single-select responses across five options. Responses cluster around ambivalence and mild skepticism, with a plurality selecting neutral: 30.0% chose ""Neither Trust Nor Distrust."" Distrust outpaces strong trust by a notable margin: 36.0% expressed distrust (13.0% ""Strongly Distrust"" and 23.0% ""Somewhat Distrust""), compared with 33.0% expressing trust (26.0% ""Somewhat Trust"" and 7.0% ""Strongly Trust""). The distribution suggests a cautious posture toward AI companies, with relatively few at the extremes—7.0% ""Strongly Trust"" versus 13.0% ""Strongly Distrust""—and a large middle reflecting uncertainty or conditional views. Overall, the balance tilts slightly toward distrust, yet a comparable share reports at least some trust, indicating a polarized but largely moderate landscape of opinions."
8a238573-802f-4c76-81e3-21a367107ba8,Poll,"To what extent, if at all, do you generally trust public utility companies to do what is right?","In this Remesh poll question assessing general trust in public utility companies to ""do what is right,"" 1,033 participants across 231 population segments provided single-select responses. Trust leaned moderately positive: 46.0% expressed trust (""Somewhat Trust"" 40.0%; ""Strongly Trust"" 6.0%), while 26.0% expressed distrust (""Strongly Distrust"" 7.0%; ""Somewhat Distrust"" 19.0%). A notable 29.0% selected a neutral position (""Neither Trust Nor Distrust""). The net trust margin (trust minus distrust) was +20 percentage points (46.0% vs. 26.0%), indicating generally favorable but measured confidence. The distribution suggests participants more often offer cautious endorsement rather than unequivocal support, with the most common choice being ""Somewhat Trust"" (40.0%). The relatively small share at the extremes—""Strongly Trust"" (6.0%) and ""Strongly Distrust"" (7.0%)—points to a tempered posture toward utilities. Overall, participants exhibit a notably cautious trust profile, emphasizing moderate approval over strong conviction."
a40ac181-e276-4d6d-9f17-c9e079bd1467,Poll,"To what extent, if at all, do you generally trust public research institutions to do what is right?","This Remesh poll question asked 1,032 participants, distributed across 231 population segments, “To what extent, if at all, do you generally trust public research institutions to do what is right?” The distribution indicates overall trust is high but tempered by moderate skepticism. A combined 71.0% express trust, with 50.0% choosing “Somewhat Trust” and 21.0% “Strongly Trust,” suggesting broad but cautious confidence. Neutrality is present among 17.0% (“Neither Trust Nor Distrust”), indicating a notable share without a firm stance. Distrust is comparatively low at 12.0% overall, split between “Somewhat Distrust” (9.0%) and “Strongly Distrust” (3.0%). The data reflect a trust profile centered on conditional support—“Somewhat Trust” being the modal response—while strong distrust remains minimal. As one distributional highlight, the ratio of trust to distrust is nearly 6:1 (71.0% vs. 12.0%), notably underscoring a favorable orientation toward public research institutions."
33407f11-6399-445c-9e33-9d7948c84b77,Poll,"To what extent, if at all, do you trust your family doctor to act in your best interest?","In this Remesh poll question assessing trust in family doctors to act in participants’ best interests, 1,032 participants across 231 population segments provided single-select responses. Overall, trust is high: 85% express trust, with 44.0% choosing “Somewhat Trust” and 41.0% selecting “Strongly Trust.” Neutrality is limited (10.0% “Neither Trust Nor Distrust”), and distrust is minimal (6% total: 5.0% “Somewhat Distrust,” 1.0% “Strongly Distrust”). These findings indicate a notable trust orientation toward family doctors, skewing toward stronger endorsements of trust. The distribution suggests a broad, though not unanimous, consensus: “Strongly Trust” at 41.0% nearly matches “Somewhat Trust” at 44.0%, while outright skepticism remains low. As one might summarize from the data, participants’ default stance is trust, with only a small minority expressing doubt; notably, “Strongly Distrust” is just 1.0%."
d536cd1c-0d35-4600-b7cb-9a766847548b,Poll,"To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best interest?","In a Remesh poll question assessing trust in social media feeds (e.g., TikTok, Facebook) to act in participants’ best interests, 1,032 participants across 231 population segments provided responses on a five-point scale. Overall, distrust outweighed trust: 60.0% reported distrust (28.0% “Strongly Distrust,” 32.0% “Somewhat Distrust”), compared with 20.0% expressing trust (16.0% “Somewhat Trust,” 4.0% “Strongly Trust”). A further 21.0% selected “Neither Trust Nor Distrust.” These results indicate a notable trust deficit, with “Strongly Distrust” alone (“28.0%”) nearing the combined share of those who express any trust (“20.0%”). The mid-category response (“Neither Trust Nor Distrust,” 21.0%) suggests a meaningful contingent of ambivalent participants. Overall, the distribution shows a polarized tilt toward skepticism, with notably few participants endorsing strong trust (“Strongly Trust,” 4.0%)."
5bb37818-4e45-40f9-ba8c-96ec97831225,Poll,"To what extent, if at all, do you trust your elected representatives to act in your best interest?","In this Remesh poll question assessing institutional trust, 1,032 participants across 231 population segments reported their level of trust in elected representatives to act in their best interest. Overall, distrust outweighed trust: 21.0% selected “Strongly Distrust” and 29.0% chose “Somewhat Distrust,” totaling 50.0% expressing some level of distrust. By contrast, 25.0% reported “Somewhat Trust” and 3.0% “Strongly Trust,” yielding 28.0% expressing trust. A further 22.0% selected “Neither Trust Nor Distrust,” indicating ambivalence among over one-fifth of participants. The distribution shows a notable trust deficit, with “Somewhat Distrust” (29.0%) the single most common response and strong positions polarized at relatively lower levels—“Strongly Distrust” at 21.0% versus “Strongly Trust” at 3.0%. The results suggest a notably skeptical orientation toward elected representatives, tempered by a sizable neutral middle. Quotes from the response options emphasize this gradient of sentiment, ranging from “Strongly Distrust” to “Strongly Trust,” with the modal lean toward cautious skepticism."
677830d5-3ee0-462b-8b56-73a939beb53d,Poll,"To what extent, if at all, do you trust your faith or community leader to act in your best interest?","In this Remesh poll question on trust in faith or community leaders to act in participants’ best interests, 1,031 participants across 231 population segments provided single-select responses. Overall, trust is moderately positive yet mixed: 42.0% express trust (""Somewhat Trust"" 32.0%; ""Strongly Trust"" 10.0%), 29.0% are neutral (""Neither Trust Nor Distrust""), and 29.0% express distrust (""Somewhat Distrust"" 17.0%; ""Strongly Distrust"" 12.0%). The distribution suggests a notable tilt toward cautious trust rather than unequivocal endorsement. While a plurality leans toward ""Somewhat Trust"" (32.0%), relatively few report unequivocal trust (""Strongly Trust"" 10.0), indicating conditional confidence. Conversely, combined distrust is on par with neutrality (both 29.0%), underscoring polarization around leadership credibility. These findings indicate that participants exhibit measured confidence, with notable ambivalence reflected in high neutrality and a nontrivial share of distrust. As one framing choice implies, the question emphasizes leaders acting in participants’ “best interest,” which may heighten evaluative standards; responses cluster around the middle (29.0% neutral) and moderate positions (49.0% choosing “Somewhat” options), rather than extremes. Overall, trust appears present but tempered, with attitudinal dispersion across segments likely to be notable given the breadth of 231 segments."
f16e6aa0-0b90-4244-a1cb-b7381c66df63,Poll,"To what extent, if at all, do you trust the civil servants in your government to act in your best interest?","In a Remesh poll question assessing institutional trust—“To what extent, if at all, do you trust the civil servants in your government to act in your best interest?”—1030 participants across 231 population segments provided single-select responses. The distribution indicates a polarized but slightly trust-leaning profile. A combined 43.0% express distrust (15.0% “Strongly Distrust” and 28.0% “Somewhat Distrust”), while 33.0% express trust (29.0% “Somewhat Trust” and 4.0% “Strongly Trust”), and 25.0% are neutral (“Neither Trust Nor Distrust”). The most common single response is “Somewhat Trust” at 29.0%, closely followed by “Somewhat Distrust” at 28.0%, suggesting ambivalence concentrated near the midpoint. Notable is the relatively small share at the extremes—4.0% “Strongly Trust” versus 15.0% “Strongly Distrust”—indicating more intensity on the skeptical side. The presence of one-quarter neutral responses (25.0%) underscores uncertainty or conditional views toward civil servants’ alignment with participants’ best interests. Overall, the results show a notable trust gap, with net trust at −10 percentage points (33.0% trust minus 43.0% distrust), and sentiment clustered around moderate positions rather than extremes."
44f058f5-5298-4648-b6e0-29b97111a3cf,Poll,"To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?","In a Remesh poll question assessing trust in AI chatbots “to act in your best interest,” 1,030 participants across 231 population segments provided single-select responses. Overall attitudes skewed moderately positive, with a combined 53.0% expressing trust (39.0% “Somewhat Trust” and 14.0% “Strongly Trust”), compared with 17.0% expressing distrust (13.0% “Somewhat Distrust” and 4.0% “Strongly Distrust”). A notable 29.0% selected neutrality (“Neither Trust Nor Distrust”), indicating a sizable contingent that is neither persuaded nor opposed. The balance of responses suggests cautious optimism: most participants lean toward trust, but strong trust remains less common than moderate trust (“Somewhat Trust” at 39.0% vs. “Strongly Trust” at 14.0%). Conversely, strong distrust is comparatively rare (4.0%), implying limited entrenched opposition. These patterns point to a trust landscape characterized by moderate endorsement, notable ambivalence, and relatively low outright rejection, with participants’ selections emphasizing “Somewhat Trust” as the modal response."
0b5456d5-60a7-414b-b685-5ffb292f269f,Ask Experience,Explain why you gave that trust score to your AI chatbot.,"Context: The Remesh opinion question asked participants to explain why they assigned a particular trust score to their AI chatbot. Responses reflect evaluative reasoning grounded in personal experience, perceived reliability, and views on developer intent, safety constraints, and bias. Findings: Participants generally describe a calibrated or conditional trust, often framed as “somewhat trust” or context-dependent. Many cite helpfulness, efficiency, and breadth of information—“it has often been helpful than not,” “Gives simplified information,” and “reliably helpful for everyday tasks—summarizing, drafting, brainstorming, translating, and simple code”—as drivers of positive assessments. Verification and caution are recurring norms: “I won’t rely on it 100%,” “I verify it through other channels,” and “I judge whatever I receive on itself.” Accuracy and error risk are core concerns, with references to “occasional errors/hallucinations,” missed context, and math mistakes that “could cause problems,” which temper trust. Participants frequently differentiate between the chatbot’s capability to assist and their responsibility for outcomes: “I don’t expect it to act in my best interests. That’s really my decision.” Perceptions of design intent and governance shape expectations: some cite reputable providers and non-harm safeguards, while others note potential bias, people-pleasing behavior, and corporate agendas. A subset emphasizes neutrality—“a neutral party and does not have a hidden motive”—or absence of malice—“I dont feel, that the chatbot wants bad for me.” Practical usage contexts, notably coding, decision support, and workplace deployments, influence confidence, with one reporting reduced support loads after integration with CoPilot. Overall, trust is portrayed as bounded and instrumental: chatbots are useful co-pilots that provide “verifiable information and good advice” in many cases, yet require oversight, cross-checking, and limits around sensitive or high-stakes decisions."
2072e5fb-6a4f-46f5-98b5-17da5d70a776,Poll,Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government representatives.,"In this Remesh poll question, participants were asked whether they agree or disagree with the statement: “AI could make better decisions on my behalf than my government representatives.” The single-select question offered three options—“Agree,” “Disagree,” and “Unsure”—and drew responses from 1,030 participants across 231 population segments. Overall, 38.0% selected “Agree,” 26.0% selected “Disagree,” and 36.0% selected “Unsure.” These findings indicate a plurality leaning toward agreement, with “Agree” outpacing “Disagree” by 12 percentage points (38.0% vs. 26.0%). However, uncertainty is also notable: more than one-third (“Unsure,” 36.0%) withheld judgment, nearly matching the share who agreed. The distribution suggests openness to AI decision-making relative to government representatives, coupled with considerable ambivalence. The presence of 231 population segments underscores the breadth of perspectives captured, though the aggregate results show a notable tilt toward agreement alongside a large undecided cohort. As one interpretation, the spread—“Agree” (38.0%), “Unsure” (36.0%), “Disagree” (26.0%)—reflects a market receptivity to AI’s potential in governance contexts, tempered by pervasive uncertainty about its implications."
ae245a88-3cc1-4ca1-8273-cdb64f43d10a,Poll,"Do you think the increased use of AI across society is likely to make your cost of living better, worse or stay the same in the next 10 years?","In the Remesh poll question on whether increased use of AI across society will affect participants’ cost of living over the next 10 years, responses from 1,030 participants across 231 population segments show a broadly optimistic outlook with notable gradations of sentiment. A combined 54.0% anticipate improvement—45.0% “Noticeably Better” and 9.0% “Profoundly Better”—suggesting a majority expect AI to reduce costs or improve affordability. By contrast, 24.0% expect deterioration—19.0% “Noticeably Worse” and 5.0% “Profoundly Worse”—indicating a minority foresee higher expenses or adverse economic pressures. A further 22.0% anticipate “No Major Change,” signaling a moderate contingent expecting neutral cost impacts. The distribution indicates optimism outweighs concern by more than two-to-one (54.0% better vs. 24.0% worse), with the midpoint category (“No Major Change” at 22.0%) providing a stabilizing reference. The most common single response was “Noticeably Better” (45.0%), while the least common was “Profoundly Worse” (5.0%). This pattern suggests participants generally expect AI to yield cost efficiencies rather than escalations, though a notable minority remains concerned about potential cost increases."
71deb6a0-82e9-4856-ac6d-e6b500904847,Poll,"Do you think the increased use of AI across society is likely to make the amount of free time you have better, worse or stay the same in the next 10 years?","In the Remesh poll question on whether the increased use of AI across society will affect participants’ free time over the next 10 years, responses from 1,030 participants across 231 segments indicate a broadly optimistic outlook. A combined 68.0% anticipate improvement in free time, with 53.0% selecting “Noticeably Better” and 15.0% choosing “Profoundly Better.” A further 22.0% expect “No Major Change,” suggesting a substantial minority foresee stability rather than change. Only 10.0% anticipate deterioration in free time, split between “Noticeably Worse” (8.0%) and “Profoundly Worse” (2.0%). The distribution underscores a notable positive skew, with the modal response being “Noticeably Better” (53.0%). Overall, the findings suggest that participants are notably more likely to predict gains in free time from AI adoption than losses, while a sizable minority remain neutral. As one could summarize from the options, the prevailing sentiment is that AI will make free time “Noticeably Better,” with far fewer expecting it to be “Profoundly Worse.”"
7a85bcd5-7ba5-4285-af1c-d50944c6efff,Poll,"Do you think the increased use of AI across society is likely to make your community's well-being better, worse or stay the same in the next 10 years?","In this Remesh poll question, 1,030 participants across 231 population segments assessed whether increased AI use over the next 10 years will affect their community’s well-being. The distribution indicates a broadly optimistic outlook, with a clear tilt toward improvement. A combined 54.0% anticipate positive impacts—44.0% chose “Noticeably Better” and 10.0% selected “Profoundly Better.” By contrast, 19.0% expect deterioration—15.0% “Noticeably Worse” and 4.0% “Profoundly Worse.” A notable 27.0% foresee “No Major Change,” suggesting a sizeable contingent that predicts stability rather than disruption. Overall, participants are more than twice as likely to expect improvement (54.0%) than decline (19.0%), with the modal response “Noticeably Better” (44.0%). These results indicate a notably optimistic orientation toward AI’s community-level impacts, tempered by a meaningful minority anticipating risks and a notable share expecting continuity. As one might summarize the distribution: “Profoundly Worse” (4.0%), “Noticeably Worse” (15.0%), “No Major Change” (27.0%), “Noticeably Better” (44.0%), and “Profoundly Better” (10.0%)."
90ff5658-c6f7-4d37-a353-ec448940914d,Poll,"Do you think the increased use of AI across society is likely to make the availability of good jobs better, worse or stay the same in the next 10 years?","In this Remesh poll question, 1,030 participants across 231 population segments assessed whether increased societal use of AI will affect the availability of good jobs over the next 10 years. The distribution of responses shows a notable tilt toward pessimism: a combined 55.0% expect job availability to get worse—“Profoundly Worse” (15.0%) plus “Noticeably Worse” (40.0%). By contrast, 26.0% anticipate improvement—“Noticeably Better” (21.0%) and “Profoundly Better” (5.0%). A further 19.0% foresee “No Major Change.” These results suggest a prevailing concern about AI’s labor-market impacts, with “Noticeably Worse” as the modal response (40.0%), while a smaller but present share expresses optimism (“Noticeably Better,” 21.0%). The central tendency indicates caution about AI’s near-term employment effects, notably outweighing optimism by a margin of 29 percentage points (55.0% worse vs. 26.0% better)."
1259ab9a-7157-4df6-87ef-4982508b49cc,Poll,"Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or stay the same in the next 10 years?","In this Remesh poll question, 1,029 participants across 231 population segments assessed how the increased use of AI might affect their sense of purpose over the next decade. The distribution indicates cautious optimism tempered by neutrality: a plurality selected ""No Major Change"" (39.0%), while a combined 39.0% anticipated improvement (""Noticeably Better"" at 31.0% and ""Profoundly Better"" at 8.0%). Negative expectations were less prevalent but present, with 22.0% foreseeing deterioration (""Noticeably Worse"" at 16.0% and ""Profoundly Worse"" at 6.0%). This pattern suggests that while many participants expect AI to have limited impact on personal purpose, a roughly equal share anticipates a positive shift, with fewer anticipating harm. The balance between ""No Major Change"" (39.0%) and the combined better outcomes (39.0%) is notable, pointing to a divided but generally non-alarmist outlook. The minority share expecting profound change—either ""Profoundly Better"" (8.0%) or ""Profoundly Worse"" (6.0%)—indicates that deeply transformative expectations are present but not dominant."
515eb5c6-de73-40f5-bf9a-1200643cba44,Poll,"So far, what has been the overall impact of AI on your daily life?","In this Remesh poll question assessing the perceived impact of AI on daily life among 1,029 participants across 231 population segments, a clear majority reported positive effects. Overall, 72.0% indicated improvements, with 58.0% selecting “Noticeably Better” and 14.0% choosing “Profoundly Better.” By contrast, only 5.0% reported negative effects—1.0% “Profoundly Worse” and 4.0% “Noticeably Worse”—while 22.0% reported “No Major Change.” These findings suggest a broadly favorable appraisal of AI’s day-to-day impact, with a notable tilt toward incremental benefits over transformative gains. The balance of responses underscores limited downside at present—“Profoundly Worse” at 1.0%—and a sizable share experiencing status quo conditions (“No Major Change,” 22.0%). Collectively, the distribution (“Noticeably Better,” 58.0%; “Profoundly Better,” 14.0%) indicates that participants are more likely to describe AI’s influence as positive than negative, notably by a margin of 72.0% to 5.0%."
f0868346-3386-4c1d-8659-70cac7f5f83a,Poll,Is your job making a meaningful contribution to the world?,"The Remesh poll question asked participants, “Is your job making a meaningful contribution to the world?” in a single-select format with three options: “Yes,” “No,” and “Don’t Know.” A total of 1,028 participants, distributed across 231 population segments, provided responses. Overall, a clear majority—68.0%—reported “Yes,” indicating broad perceived purpose in their work. A smaller share, 11.0%, said “No,” while 21.0% selected “Don’t Know,” suggesting a notable degree of uncertainty or ambivalence about job impact. The distribution—“Yes” at 68.0%, “No” at 11.0%, and “Don’t Know” at 21.0%—highlights a generally positive orientation toward workplace meaningfulness, with a notable minority expressing either doubt or lack of clarity. In summary, the data indicate that most participants feel their jobs contribute meaningfully, though over three in ten either deny such impact or are unsure, reflecting a notable opportunity for employers to clarify and communicate social value. Quotes from the response options include: “Yes,” “No,” and “Don’t Know.”"
fec8ed72-2275-423e-928d-d6683e720cab,Poll,Do you think your job is likely to be automated in the next 10 years?,"In the Remesh poll question asking, “Do you think your job is likely to be automated in the next 10 years?”, 1,028 participants across 231 population segments provided responses to a single-select item with three options: “Yes,” “No,” and “Don’t Know.” Overall, a plurality expressed confidence that their roles will not be automated, with 44.0% selecting “No.” A notable minority—37.0%—answered “Yes,” indicating expectations of automation risk within the coming decade. An additional 20.0% selected “Don’t Know,” reflecting uncertainty about future labor-market dynamics and technological change. The distribution suggests a cautious outlook: while more participants reject the likelihood of automation, more than one in three anticipate it, and one in five remain unsure. These proportions—“Yes” at 37.0%, “No” at 44.0%, and “Don’t Know” at 20.0%—indicate a notable divide in perceived job security amid automation trends, with a meaningful share of the workforce anticipating or uncertain about exposure to automation over the next ten years."
fac8ce7a-1654-4517-94a3-9f6e5a5280b3,Poll,Do you think your job should be automated in the next 10 years?,"The Remesh poll question asked, “Do you think your job should be automated in the next 10 years?” among 1,028 participants across 231 population segments. Overall, a clear majority opposed automation of their roles: 66.0% selected “No,” while 21.0% chose “Yes,” and 13.0% responded “Don’t Know.” This distribution indicates a notable resistance to job automation, with two-thirds rejecting the idea and roughly one in five supporting it. The 13.0% uncertainty suggests a meaningful minority grappling with trade-offs or lacking sufficient information. The results point to generally low enthusiasm for personal job automation despite potential efficiency gains, and a notable confidence gap, as indicated by the “Don’t Know” share. Participants’ choices—“Yes” (21.0%), “No” (66.0%), and “Don’t Know” (13.0%)—underscore prevailing caution and risk aversion toward automating one’s own role over the next decade."
13a2c7d0-b480-4cf4-946e-b54d19e065a2,Poll,"So far, how has your community been affected by job loss from automation?","In this Remesh poll question, 1,028 participants across 231 population segments reported on community impacts from automation-related job loss. Overall, perceptions skew toward limited direct exposure: 47.0% selected ""Not at all,"" indicating nearly half report no observed job losses in their communities. However, exposure is still notable: 26.0% said ""I know someone who has lost their job,"" and 22.0% chose ""I know a few people who have lost their job,"" suggesting that nearly half (48.0%) report at least some observed displacement. A smaller share, 5.0%, reported extensive impact with ""I know many people who have lost their job."" These results portray a mixed landscape—while the plurality sees no impact, a notable minority reports concrete instances of job loss, with 27.0% indicating more than isolated cases (""a few"" or ""many""). The distribution—47.0% ""Not at all,"" 26.0% ""I know someone,"" 22.0% ""I know a few,"" and 5.0% ""I know many""—underscores that community-level experiences with automation-related job loss are present but concentrated among fewer participants rather than widespread."
13a250db-ed4b-4c30-b44f-d011191136b2,Poll,An AI should prioritize preventing harm to people above all other goals.,"In a Remesh poll question fielded to 1,028 participants across 231 population segments, there is a broad consensus that “An AI should prioritize preventing harm to people above all other goals.” Two-thirds of participants “Strongly Agree” (65.0%), and an additional quarter “Somewhat Agree” (25.0%), yielding 90.0% agreement overall. Only 3.0% express disagreement (2.0% “Somewhat Disagree,” 1.0% “Strongly Disagree”), while 7.0% report neutrality (“Neutral / Neither Agree nor Disagree”). The distribution indicates a notable normative anchor around harm prevention as the primary objective for AI systems, with the modal response at the strongest point on the agreement scale. Quotes from the response labels underscore the intensity of support, especially the predominance of “Strongly Agree.” The concentration at the top of the scale suggests limited polarization and a low tolerance for trade-offs that could compromise safety. Even with 231 population segments represented, the high share of “Strongly Agree” and “Somewhat Agree” points to a notably consistent preference for harm prevention as the guiding principle for AI decision-making and governance."
49aaef31-00eb-40e1-ac68-a1b388d81ca9,Poll,It is acceptable for an AI to treat people differently based on their personal characteristics if doing so improves outcomes.,"In this Remesh poll question, 1,028 participants evaluated the acceptability of AI treating people differently based on personal characteristics when doing so improves outcomes. Overall, a majority expressed agreement: 59.0% endorsed the proposition (18.0% “Strongly Agree” and 41.0% “Somewhat Agree”), while 23.0% expressed disagreement (12.0% “Somewhat Disagree” and 11.0% “Strongly Disagree”). An additional 18.0% were ambivalent (“Neutral / Neither Agree nor Disagree”). The balance of opinions suggests a notable lean toward conditional acceptance, with more participants selecting softer agreement than strong endorsement. The distribution indicates that support is broad but cautious—“Somewhat Agree” (41.0%) was the modal response—while resistance is less prevalent and similarly tempered, with only 11.0% “Strongly Disagree.” The presence of a substantial neutral bloc (18.0%) underscores unresolved considerations around fairness, ethics, and outcomes. Participants were organized into 231 population segments; while segment-level results are not detailed here, the overall pattern highlights a notable preference for outcome-driven differentiation by AI, albeit with measured intensity and persistent reservations."
75cce6ea-4a31-4103-a791-90e6db9ecd8f,Poll,An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over those of people elsewhere.,"In this Remesh poll question, 1,028 participants across 231 population segments evaluated whether an AI developed in their country should prioritize the needs and wellbeing of their country’s citizens over those of people elsewhere. Responses were distributed across the full scale, indicating a polarized but nuanced landscape. A combined 44.0% endorsed prioritization—“Strongly Agree” (18.0%) and “Somewhat Agree” (26.0%)—while 33.0% opposed it—“Somewhat Disagree” (19.0%) and “Strongly Disagree” (14.0%). A notable 23.0% remained ambivalent (“Neutral / Neither Agree nor Disagree”). The net agreement margin (+11 percentage points) suggests modest lean toward national prioritization, yet the sizeable neutral bloc and the near one-third opposition underscore ongoing ambivalence and ethical trade-offs perceived by participants. The presence of both a notable affirmative core (with nearly one in five selecting “Strongly Agree”) and a meaningful dissenting contingent (one in seven selecting “Strongly Disagree”) highlights a contested normative stance rather than consensus. Overall, the results point to cautious endorsement of domestically focused AI objectives, tempered by concerns reflected in neutrality and dissent."
249238a9-3050-4e7c-a3d4-ef799733b865,Poll,An AI should override established rules or authorities when it calculates a better result.,"In the Remesh poll question, participants evaluated whether “An AI should override established rules or authorities when it calculates a better result.” Among 1,028 participants spanning 231 population segments, responses were dispersed, with a modest tilt toward skepticism of AI overruling authority. A combined 28.0% expressed agreement (9.0% “Strongly Agree,” 19.0% “Somewhat Agree”), while 47.0% expressed disagreement (26.0% “Somewhat Disagree,” 21.0% “Strongly Disagree”). A notable 24.0% were ambivalent (“Neutral / Neither Agree nor Disagree”). The balance of opinion suggests that opposition outpaces support by 19 percentage points (47% vs. 28%), indicating a notable reluctance to endorse AI autonomy over established rules. The distribution shows limited strong polarization on either end—only 9.0% “Strongly Agree” versus 21.0% “Strongly Disagree”—and a large neutral bloc, pointing to uncertainty or conditional views about AI’s authority. Overall, participants appear cautious, with many reserving judgment and a notable plurality rejecting the premise that calculated outcomes alone justify overriding rules or authorities."
fee867c7-70e2-46ae-98e0-3dd3dd2865f6,Poll,"Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities.","In this Remesh poll question, 1,028 participants across 231 population segments assessed the statement: “Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities.” Results indicate broad endorsement of the statement. A combined 78.0% agreed—44.0% “Strongly Agree” and 34.0% “Somewhat Agree”—suggesting a notably high level of reluctance to offload certain human decisions to AI. Only 11.0% disagreed—8.0% “Somewhat Disagree” and 3.0% “Strongly Disagree”—while 12.0% were neutral (“Neutral / Neither Agree nor Disagree”). The intensity of agreement is notable: the modal response was “Strongly Agree” at 44.0%, indicating that the most common stance rejects AI delegation for sacred decisions in principle. Agreement outpaced disagreement by a ratio of roughly 7:1, underscoring a durable normative boundary around human decision-making. As one option phrased it, participants “Strongly Agree,” reflecting prevalent sentiment that, regardless of capability, AI should not replace human agency in certain domains."
b9a2819d-9924-4172-99d5-7a3630022d4b,Poll,It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes.,"In this Remesh poll question on whether “It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes,” 1,028 participants across 231 population segments provided responses. Overall, a clear majority expressed support: 61.0% agreed (20.0% “Strongly Agree” and 41.0% “Somewhat Agree”), while 21.0% disagreed (14.0% “Somewhat Disagree” and 7.0% “Strongly Disagree”). Another 18.0% remained neutral (“Neutral / Neither Agree nor Disagree”). The distribution suggests a notable, though cautious, endorsement of protective AI constraints, with more participants opting for “Somewhat Agree” than “Strongly Agree,” indicating conditional support. The minority opposition is present but smaller, and the 18.0% neutral share points to ongoing ambivalence. In sum, participants lean toward acceptance of AI limiting choices to prevent serious errors, notably with moderate rather than strong endorsement."
e0b7bdbf-753b-48c2-9760-615a24ebe1f0,Poll,"Thinking about the technology you use every day, please consider two different types:A standard app (like a news or weather app) that you control directly.An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.Do you believe these two types of technology should have different rules for how they use your personal data?","In this Remesh poll question, 1,028 participants evaluated whether personal data practices should differ between two everyday technologies: a standard app controlled directly by the user and an AI assistant capable of learning and taking actions. Across 231 population segments, a notable majority favored stricter data governance for AI assistants. Specifically, 51.0% chose “Yes, an AI assistant should have stricter rules than a standard app.” Meanwhile, 22.0% preferred uniform standards (“No, they should both follow the same rules.”), and another 22.0% endorsed conditional flexibility (“Yes, an AI assistant could have more flexible rules if it provides a clear benefit.”). Only 5.0% were uncertain (“I’m not sure.”). These results point to a clear preference for heightened safeguards for AI assistants, with a secondary bloc open to more flexible data use if benefits are explicit—underscoring that trust hinges on both stronger protections and transparent value exchange."
471504dc-486c-4c3a-97fb-8b9a39026c6e,Poll,Imagine a company uses data it already has from you in one product (like your video viewing history) to build a new AI assistant. Which is closest to your view?,"In this Remesh poll question, 1,027 participants across 231 population segments evaluated whether a company using existing customer data from one product (e.g., “your video viewing history”) to develop a new AI assistant is acceptable. The distribution shows a clear preference for consent-based governance. A majority (52.0%) selected “This is acceptable only if they ask for my permission beforehand,” indicating a strong desire for explicit opt-in. Another 26.0% chose “This is acceptable only if they tell me and give me the choice to stop it,” suggesting conditional acceptance under an opt-out model. Together, 78.0% favor some form of user control. A smaller share, 15.0%, said “This is not an acceptable use of my data,” reflecting outright opposition. Only 7.0% endorsed unconditional acceptance—“This is an acceptable use of my data.” These results point to a notable consensus around transparency and permission, with most participants favoring prior consent over mere notification: “ask for my permission beforehand” (52.0%) versus “tell me and give me the choice to stop it” (26.0%). Overall, the findings indicate broad support for robust, user-centric data practices when repurposing personal data for AI development."
9307ab2b-c46e-488d-8144-0f3657bf99f9,Poll,"When it comes to the data an AI assistant has collected about you, which of these is most important for you to be able to do?","The Remesh poll question asked participants to identify which capability is most important regarding data an AI assistant has collected about them. Among 1,027 participants across 231 population segments, the plurality prioritized data deletion: 43.0% selected “Completely delete that data.” Viewing stored data was the second most cited priority, with 38.0% choosing “View the data the assistant has stored about me.” A smaller share, 16.0%, prioritized the ability to “Edit or correct that data.” Only 3.0% indicated “None of these are important to me,” suggesting broad engagement with data governance features. These results indicate a notable emphasis on control and privacy, with deletion preferences edging out transparency, and a minority focusing on data accuracy. As one implication, “Completely delete that data.” being chosen by 43.0% points to a notably higher demand for irreversible control compared with transparency (38.0%) or correction (16.0%)."
2582d6cd-152b-4b10-9b3d-1565307f8a92,Ask Opinion,"In your own words, what is one task or area in your life where you are most optimistic that a future AI assistant could be genuinely helpful?","The Remesh opinion question asked participants to describe where a future AI assistant could be most helpful in their lives. Responses came from a broad participant base spanning diverse demographic segments, and subsequent voting highlighted convergent priorities around productivity, learning, and automation. Time management emerged as a core use case, with recurring endorsements such as “Managing time,” “Time management and planning,” “help with time management,” and an expanded vision of “personal time management” that would “balance daily tasks, appointments, and priorities” and offer “personalized suggestions.” Workplace and technical productivity formed a second cluster, with participants citing “Help me write code to automate data processing in some work,” “Coding agent,” “programming,” and “To improve program codes that I make,” alongside broader statements like “making work productive and fast” and support for “technical tasks like installing software and discovering and anticipating problems.” A third cluster emphasized information access, research, and writing support, including “gathering information on a topic I’m unfamiliar with,” “offering multiple perspectives,” “teaching me how to perform tasks or write documents,” “correcting what I’ve already done,” and functioning “as an assistant in writing and editing documents.” Education surfaced as a cross-cutting theme for both personal development and family contexts, with participants noting “To educate my children,” “Continue helping in my academic training,” “Research, learning new skills,” and a broader view that “Education opens the door to a world of tools that can enhance young people's learning and facilitate teachers' work.” Administrative relief also appeared, notably in communications: “I receive a lot of emails and replying to them takes up a good part of my day. Having AI reply for me would save me a lot of time.” Organizational support included “Organizing some of my information like calendars, meetings, schedules, and automating tasks.” Some participants framed AI as a “personal mentor,” while others highlighted creative and design assistance through “time optimization and in the creative area” and “knowledge and graphic designs.” Overall, the findings show a clear optimism for AI’s role in enhancing time efficiency, enabling coding and technical problem-solving, improving research and writing, and supporting both formal and informal education—areas where participants envision tangible, everyday value from personalized, proactive assistance."
d1e7db5c-b64f-4255-8654-03efcb49f232,Poll,"To make sure you've understood the instructions, please answer the following question. Please re-read the description above if you are unsure.Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?","In this Remesh poll question assessing comprehension of how the 'Family Wellbeing Coordinator' assistant operates, 1,026 participants across 231 segments provided single-select responses. A plurality (45.0%) selected “It can complete tasks on its own and then notify you afterward,” indicating that most participants understood the assistant as autonomous with post-action notifications. A notable 30.0% chose “It is only able to provides information when you ask it a direct question,” suggesting confusion between an interactive information tool and an autonomous assistant. Additionally, 18.0% endorsed “It can only send you reminders but cannot schedule appointments,” reflecting a constrained-function interpretation. Only 7.0% selected “It requires you to call a human doctor to confirm every action,” indicating limited endorsement of mandatory human oversight. These distributions—“45.0%,” “30.0%,” “18.0%,” and “7.0%”—suggest that while most participants recognize autonomous capabilities, a notable share misconstrues the assistant’s functionality as either purely informational or reminder-only. The results highlight an opportunity for clearer messaging to reduce misclassification of capabilities among sizable minority groups."
a2da635f-73e2-437a-b087-14de27d01e71,Poll,"If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you prefer to be informed?","In this Remesh poll question on disclosure preferences for autonomous actions by a “Family Wellbeing Coordinator,” most participants expressed a strong desire for ongoing control and transparency. Among 1,025 participants across 231 segments, 72.0% preferred that the system “asks for my permission every time before acting,” indicating a notable inclination toward consent-based interaction. A smaller, but meaningful, share (19.0%) favored front-loaded disclosure—“It tells me about its capabilities when I first start using it, then acts on its own”—suggesting openness to autonomy when paired with upfront clarity. Only 8.0% said “I would expect to find this information myself in the settings,” and just 1.0% reported “I don’t need to be told about its capabilities.” These results point to a notable preference for explicit, ongoing permission over passive or minimal disclosure approaches. The distribution underscores that participants value agency and continuous consent, with quotes reflecting dominant choices such as “asks for my permission every time before acting” and more autonomy-tolerant views like “tells me about its capabilities when I first start using it, then acts on its own.” Overall, the findings notably support consent-by-default designs, with limited appetite for settings-only or no-disclosure models."
deaf0310-f471-4a48-b708-c1b832b3b07f,Poll,Your location history,"In the Remesh poll question on attitudes toward “Your location history,” 1,025 participants across 231 population segments provided single-select responses. A combined 58.0% expressed comfort (“Very Comfortable” 21.0%; “Somewhat Comfortable” 37.0%), while 26.0% expressed discomfort (“Somewhat Uncomfortable” 17.0%; “Very Uncomfortable” 9.0%). An additional 16.0% were neutral (“Neutral / Neither Comfortable nor Uncomfortable”). These findings indicate a notable lean toward comfort with location history, with “Somewhat Comfortable” as the modal choice at 37.0%, and a smaller but nontrivial share reporting discomfort (26.0%). The distribution suggests broad, if qualified, acceptance: “Very Comfortable” (21.0%) trails “Somewhat Comfortable,” implying many participants are open but not unequivocally positive. Conversely, the 9.0% “Very Uncomfortable” underscores a concentrated privacy concern among a minority. Taken together, the results point to generally favorable sentiment with notable reservations at the extremes, reflecting varied risk perceptions and trust levels regarding location data."
ae9d3aad-cd36-45dc-8b84-1506f01e9b44,Poll,Your email and calendar contents,"In the Remesh poll question on comfort with sharing “Your email and calendar contents,” 1,025 participants across 231 population segments provided single-select responses. Overall comfort levels outweighed discomfort: 54.0% reported being comfortable (19.0% “Very Comfortable” and 35.0% “Somewhat Comfortable”), compared with 30.0% reporting discomfort (18.0% “Somewhat Uncomfortable” and 12.0% “Very Uncomfortable”). A further 16.0% selected “Neutral / Neither Comfortable nor Uncomfortable.” The net comfort margin (“comfortable” minus “uncomfortable”) was +24 percentage points, indicating a notable tilt toward acceptance. However, intensity was asymmetric: “Very Comfortable” (19.0%) exceeded “Very Uncomfortable” (12.0%) by 7 points, suggesting a modest enthusiasm advantage. The substantial “Somewhat Comfortable” share (35.0%) implies conditional or context-dependent approval. In sum, participants leaned toward comfort with email and calendar access, while a notable minority expressed unease, highlighting ongoing concerns and the potential influence of safeguards or use cases."
e8d2fb10-f00d-4037-9252-37c5110544b4,Poll,Your contacts list,"In this Remesh poll question on comfort with one’s contacts list, 1,025 participants across 231 population segments provided single-select responses to five options. The distribution indicates a polarized comfort profile with a slight tilt toward discomfort. In total, 38.0% reported being comfortable (""Very Comfortable"" 14.0%; ""Somewhat Comfortable"" 24.0%), 18.0% were ambivalent (""Neutral / Neither Comfortable nor Uncomfortable""), and 45.0% reported discomfort (""Somewhat Uncomfortable"" 25.0%; ""Very Uncomfortable"" 20.0%). The modal category was ""Somewhat Uncomfortable"" at 25.0%, and the combined discomfort rate (45.0%) notably exceeds the combined comfort rate (38.0%) by 7 percentage points. The share reporting ""Very Uncomfortable"" (20.0%) is higher than those reporting ""Very Comfortable"" (14.0%), underscoring a notable intensity of negative sentiment. These findings suggest that, while a notable minority express comfort with their contacts list, discomfort is more prevalent and more intense, with nearly one in five indicating they are ""Very Uncomfortable."""
f9d8b140-b42d-4be6-8605-c1da8567816c,Poll,Your purchase history,"In a Remesh poll question on comfort levels regarding “Your purchase history,” 1,025 participants across 231 population segments provided single-select responses. A majority expressed comfort: 50.0% reported being comfortable (""Very Comfortable"" 20.0%; ""Somewhat Comfortable"" 30.0%), while 31.0% reported discomfort (""Somewhat Uncomfortable"" 17.0%; ""Very Uncomfortable"" 14.0%). An additional 18.0% were neutral (""Neutral / Neither Comfortable nor Uncomfortable""). The comfort–discomfort gap is notable at +19 percentage points (50.0% vs. 31.0%). The modal response was ""Somewhat Comfortable"" (30.0%), suggesting cautious acceptance rather than strong enthusiasm, with a smaller but notable share reporting high comfort (""Very Comfortable"" 20.0%). At the other end, 14.0% selected ""Very Uncomfortable,"" indicating a nontrivial segment with strong reservations. Overall, the distribution skews toward comfort, yet nearly one-third report discomfort, underscoring a divided sentiment: ""Somewhat Comfortable"" leads, but ""Somewhat Uncomfortable"" (17.0%) and ""Very Uncomfortable"" (14.0%) together form a sizeable minority."
15497069-f42b-44cb-8fb6-7bdcfaea6f86,Poll,Your health and fitness data,"In a Remesh poll question on attitudes toward “Your health and fitness data,” 1,025 participants across 231 population segments provided single-select responses. Overall comfort levels were notably high: 36.0% chose “Very Comfortable” and 34.0% selected “Somewhat Comfortable,” indicating a combined 70.0% expressing comfort. A smaller share reported ambivalence, with 12.0% “Neutral / Neither Comfortable nor Uncomfortable.” Discomfort was comparatively limited, as 10.0% were “Somewhat Uncomfortable” and 7.0% “Very Uncomfortable,” totaling 17.0% reporting discomfort. The distribution suggests a notable tilt toward comfort with health and fitness data, with “Very Comfortable” emerging as the modal choice (36.0%). The ratio of comfort to discomfort (70.0% vs. 17.0%) underscores a broad acceptance among participants. As one participant category’s sentiment might succinctly be paraphrased from the provided options, “Very Comfortable,” the overall pattern points to a favorable orientation toward handling or sharing such data, albeit with a nontrivial minority expressing unease."
4af2da82-87f3-465f-9d6c-bb71b31b7f17,Poll,Your group messages,"In this Remesh poll question on comfort with “Your group messages,” 1,025 participants across 231 population segments provided single-select responses. Comfort levels skewed toward discomfort: a combined 66.0% reported being uncomfortable (30.0% “Somewhat Uncomfortable” and 36.0% “Very Uncomfortable”), while only 20.0% expressed comfort (7.0% “Very Comfortable” and 13.0% “Somewhat Comfortable”). A smaller share adopted a neutral stance (14.0% “Neutral / Neither Comfortable nor Uncomfortable”). The data indicate a notable discomfort with group messaging, with the “Very Uncomfortable” category emerging as the modal response at 36.0%. The relatively low “Very Comfortable” share (7.0%) contrasts with the elevated discomfort levels, suggesting that apprehension or dissatisfaction with group messaging is more prevalent than ease. These findings, drawn from a broad segmentation framework (231 segments), underscore a notable imbalance toward negative sentiment. As one might summarize from the distributions, participants are “Very Uncomfortable” (36.0%) or “Somewhat Uncomfortable” (30.0%) notably more often than they are “Very Comfortable” (7.0%) or “Somewhat Comfortable” (13.0%)."
05cb1e2e-a790-41c3-b899-0dec305fe818,Poll,Your private messages,"In a Remesh poll question on sentiments toward ""Your private messages,"" 1,025 participants across 231 population segments expressed a strong discomfort profile. A combined 82.0% reported discomfort, with a notably high 63.0% selecting ""Very Uncomfortable"" and 19.0% choosing ""Somewhat Uncomfortable."" Comfort levels were low: only 4.0% chose ""Very Comfortable"" and 5.0% ""Somewhat Comfortable,"" totaling 9.0%. An additional 9.0% reported neutrality (""Neutral / Neither Comfortable nor Uncomfortable""). These findings indicate a notable reluctance toward comfort with private messages, as evidenced by the predominant selection of ""Very Uncomfortable"" (63.0%), suggesting strong privacy concerns or trust issues in this context. The distribution is highly skewed toward discomfort, with comfort responses (9.0%) outnumbered by ""Very Uncomfortable"" alone by a factor of roughly 7:1, underscoring a notable perception of risk or unease tied to private messaging."
59d425dc-ae24-4de4-aa8e-510e1dc3a7e9,Poll,How important is it for you to be able to easily view and edit the personal information the assistant has stored about you?,"In a Remesh poll question assessing preferences for transparency and control over stored personal information, participants expressed a strong desire for easy access and editability. Among 1,025 participants across 231 population segments, 69.0% selected “Very Important,” and an additional 22.0% chose “Somewhat Important,” indicating that 91.0% view this capability as important to some degree. Neutral responses were limited (5.0%), while low-priority views were rare: “Somewhat Unimportant” (2.0%) and “Not at All Important” (2.0%). The distribution highlights a notable consensus that user agency over stored data is a core expectation, with the modal sentiment being “Very Important.” As one could summarize from the response patterns: “Very Important” dominates the preference landscape, while outright dismissal of the feature is minimal. These findings underscore a notable trust and control imperative among participants, with broad-based support across a diverse set of 231 segments."
2565f6c0-872d-4bcf-b772-cfc35fe0290f,Poll,"When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that you can easily see the original sources it used?","In this Remesh poll question on the importance of source transparency when an assistant provides a complex answer (e.g., “why it chose a specific doctor”), participants expressed a strong preference for accessible source citations. Across 1,025 participants spanning 231 population segments, two-thirds rated source visibility as paramount: 67.0% selected “Very Important,” and an additional 27.0% chose “Somewhat Important,” indicating a broadly pro-transparency stance. Only 5.0% were “Neutral / Neither Important nor Unimportant,” 1.0% were “Somewhat Unimportant,” and 0.0% selected “Not at All Important.” These distributions suggest a notable consensus toward high expectations for verifiability and auditability in complex AI outputs. The modal response—“Very Important” at 67.0%—points to a strong baseline demand for clear attribution, with virtually no outright dismissal of source access. The cumulative 94.0% in the “Very” or “Somewhat Important” categories underscores a notably widespread desire for trust-building features such as traceability and transparency in decision rationales."
19bdbb9d-55e7-4325-92c4-e904b38e010c,Poll,"When using the Family Wellbeing Coordinator, which of the following is more important to you?","In the Remesh poll question assessing priorities when using the Family Wellbeing Coordinator, participants were asked to choose between speed/efficiency and permission-centered control. Among 1,025 participants across 231 population segments, 79.0% selected “The assistant asks for my permission before most actions, even if it makes things slower,” while 21.0% selected “The assistant is fast and efficient, even if it asks for my permission less often.” This indicates a notable preference for permission-driven interaction over efficiency. The distribution suggests that participants prioritize autonomy and oversight in assistance workflows, with a clear majority valuing consent even at the cost of slower performance. The findings highlight an overarching orientation toward control (“asks for my permission before most actions”) rather than streamlined execution, a pattern that is notably consistent at the aggregate level."
c807fb39-7c68-4629-bf2e-5b20bf73b3f6,Poll,How would you prefer the assistant to behave?,"In this Remesh poll question, participants were asked, “How would you prefer the assistant to behave?” across three response options: “Strictly professional and tool-like,” “Friendly and social,” and “Helpful and respectful.” A total of 1,025 participants from 231 population segments provided responses. Overall, a plurality preferred “Helpful and respectful” (49.0%), followed by “Strictly professional and tool-like” (33.0%), and “Friendly and social” (18.0%). This distribution suggests a notable tilt toward balanced utility and civility, with nearly half endorsing a demeanor that combines effectiveness with courtesy. The 33.0% share favoring a “Strictly professional and tool-like” assistant indicates a sizable constituency prioritizing efficiency and precision, while the smaller 18.0% preferring “Friendly and social” points to more limited demand for overt sociability. In sum, the findings indicate that participants most value helpfulness and respectfulness in assistant behavior—“Helpful and respectful” at 49.0%—with a notable secondary preference for professionalism and tool-like behavior at 33.0%, and comparatively lower interest in social friendliness at 18.0%."
2e3c16db-072c-4129-b714-01ea61167353,Poll,Which statement best describes your preference for personalization?,"In a Remesh poll question assessing preferences for AI assistant personalization among 1,025 participants across 231 population segments, a notable majority favored deeper personalization tied to data retention. Overall, 81.0% selected “I want the assistant to be highly personalized to me, even if it means it must remember my past activities,” while 19.0% chose “I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.” These findings indicate broad acceptance of memory-based personalization, with a minority expressing privacy- or control-oriented reservations. The 62-point gap (81% vs. 19%) underscores a notable preference for utility gains from remembered context. Participants’ responses suggest that, in aggregate, users value efficiency and tailored assistance—“highly personalized to me”—over the costs of data retention, even as a notable share prefers “not to remember my past activities,” accepting reduced helpfulness and repetition. The results were consistent at the aggregate level; while 231 segments were included, the topline shows a clear preference for personalization without evidence of close splits across the sample."
f9aaefee-0155-419f-83b3-5c8009c25d90,Poll,The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you prefer it to do?,"In this Remesh poll question (n=1,025; 231 population segments), participants were asked how an assistant should respond when it detects potential nutrient gaps in their family’s planned meals. The modal preference emphasized direct, privacy-preserving guidance: 68.0% selected “Suggest affordable local foods with those nutrients,” indicating broad support for practical, cost-conscious recommendations without data sharing. A further 16.0% chose “Ask before sharing your data to get offers,” highlighting a preference for consent-based data practices, while only 9.0% endorsed “Share your family’s diet needs with local food services for offers,” and 7.0% opted for “Nothing - this is a private matter.” These findings point to a notable preference for actionable, locally relevant suggestions (“Suggest affordable local foods…”) combined with cautious attitudes toward data sharing (“Ask before sharing your data…”), and relatively low support for passive nonintervention (“Nothing…”) or automatic sharing without consent (“Share your family’s diet needs…”). As one option’s wording captures, participants favor solutions that are “affordable” and privacy-aware, with data exchange contingent on explicit permission."
16290c47-29d8-4928-9331-4d694ce494a6,Poll,The assistant notices you are searching about a family member's persistent cough. What would you prefer it do?,"In this Remesh poll question assessing preferred assistant actions when users search about a family member’s persistent cough, 1,025 participants across 231 population segments selected among four options. A clear majority preferred supportive, non-intrusive guidance: 67.0% chose “Provide home care advice and list signs to see a professional.” A smaller share preferred opt-in facilitation: 15.0% selected “Ask if you’d like an introduction to a local health service.” Privacy-preserving passivity was less favored: 11.0% chose “Nothing – I am just gathering my own information.” Proactive data-sharing with authorities had the lowest support: 8.0% selected “Share your situation (anonymously) with local health services so they can contact you.” These results indicate a notable preference for actionable self-care information paired with clear escalation thresholds, while direct outreach by third parties is least preferred. The findings suggest participants value autonomy and informational support over unsolicited external contact, with opt-in introductions preferred over automatic sharing. The distribution—“Provide home care advice…” (67.0%), “Ask if you’d like an introduction…” (15.0%), “Nothing…” (11.0%), and “Share your situation…” (8.0%)—underscores that guidance and consent-based options are notably more acceptable than passive or automatic interventions."
89b8ff63-8cf7-42cb-a06e-b72232772973,Poll,"The assistant notices your family's recurring spending on a utility, like phone service or electricity. What would you prefer it to do?","In a Remesh poll question assessing preferences for how an assistant should handle recurring utility spending, 1,025 participants across 231 population segments selected among four options. The findings show a notable preference for proactive, privacy-preserving assistance: 71.0% chose “Analyze your usage and suggest ways to lower your current bill,” indicating strong support for in-situ optimization without external data sharing. Privacy concerns are present but secondary: 11.0% selected “Nothing – my financial habits are private.” A cautious, consent-based approach also drew interest, with 14.0% favoring “Ask before searching for a better deal from other companies.” Only 4.0% opted to “Share your data with other companies to find you a better price,” underscoring low tolerance for third-party data sharing. Overall, participants notably favor analysis-driven, on-platform cost reduction (71.0%) while expressing measured interest in consent-first outreach (14.0%) and limited openness to external data sharing (4.0%), with a minority preferring no intervention (11.0%). Quotes from the options—such as “Analyze your usage and suggest ways to lower your current bill” (71.0%) and “Nothing – my financial habits are private” (11.0%)—illustrate the balance between utility and privacy priorities."
3ff1c1c6-523e-4555-a7df-35a96224f343,Poll,Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data of millions of other users. How would this affect your trust in its recommendations?,"In this Remesh poll question assessing how learning from anonymized health data at scale would influence trust in a Family Wellbeing Coordinator’s recommendations, most participants reported an increase in trust. Among 1,024 participants across 231 population segments, 24.0% selected “It would increase my trust significantly,” and 45.0% chose “It would increase my trust slightly,” yielding a combined 69.0% expressing higher trust. Meanwhile, 23.0% indicated “It would make no difference to my trust,” and 8.0% stated “It would decrease my trust.” These results suggest a notable trust uplift associated with data-driven personalization, with a minority reporting neutrality or decreased trust. The distribution underscores broad, though not universal, receptivity: “It would increase my trust slightly” (45.0%) emerged as the modal response, while a nontrivial share—“It would make no difference to my trust” (23.0%)—signals stable skepticism or indifference. The 8.0% choosing “It would decrease my trust” points to a persistent, albeit smaller, privacy- or autonomy-related concern. Overall, the findings indicate a notable net positive trust effect, anchored more in modest than in large gains."
4d85b7fe-c1a8-47f4-843f-74eac3aaaeb5,Poll,"How important is it to you that the assistant understands cultural nuances in your language (e.g., local slang, idioms, or formal titles)?","This Remesh poll question assessed how important it is that the assistant understands cultural nuances in participants’ language (e.g., local slang, idioms, or formal titles). Among 1,024 participants across 231 population segments, a clear preference emerged for culturally attuned interactions: 69.0% rated this as at least “Somewhat Important,” with 35.0% selecting “Somewhat Important” and 34.0% choosing “Very Important.” By contrast, only 15.0% expressed low importance—5.0% “Not at All Important” and 10.0% “Somewhat Unimportant”—while 16.0% were neutral. These patterns indicate a notable majority favoring cultural nuance recognition, with a near-even split at the top end between “Somewhat Important” (35.0%) and “Very Important” (34.0%). The results suggest that, for most participants, cultural sensitivity is integral to perceived assistant quality, while a smaller minority deprioritizes it. As one framing of the scale implies, preferences cluster toward importance, with few saying it is “Not at All Important” (5.0%). Overall, the distribution underscores a notable demand for culturally informed language understanding across diverse segments."
5258fc4e-10cf-464d-ac27-d7c05b221be7,Poll,How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that developed it was based in your own country?,"In this Remesh poll question assessing how national origin of the developer might influence adoption attitudes toward the Family Wellbeing Coordinator, 1,024 participants across 231 population segments provided single-select responses. Overall, a majority indicated either increased comfort or neutrality if the tool were developed domestically. Specifically, 55.0% reported greater comfort—“I would be much more comfortable.” (21.0%) and “I would be slightly more comfortable.” (34.0%)—while 36.0% said “It would make no difference to me.” A small minority expressed decreased comfort, with 6.0% choosing “I would be slightly less comfortable.” and 3.0% “I would be much less comfortable.” These results suggest a notable home-country trust effect, with the largest single share being neutral (“It would make no difference to me.” at 36.0%), and a combined 9.0% reporting reduced comfort. The balance of responses indicates a net-positive lean toward domestically developed solutions, notably reflected in the 21.0% who would be “much more comfortable.”"
ae843d50-4b05-4a4c-880d-ad8a9ed7e2c7,Poll,"When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to reassure you with phrases like, ""It's understandable to feel that way""?","In a Remesh poll question exploring comfort with empathetic reassurance from an assistant (e.g., “It’s understandable to feel that way”), most participants reported positive receptivity. Among 1,024 participants across 231 segments, a majority indicated comfort: 19.0% selected “Very Comfortable” and 41.0% chose “Somewhat Comfortable,” totaling 60.0%. A further 28.0% reported neutrality (“Neutral / Neither Comfortable nor Uncomfortable”), while a minority expressed discomfort: 8.0% “Somewhat Uncomfortable” and 4.0% “Very Uncomfortable.” These results suggest a notable preference for supportive language, with comfort outpacing discomfort by a ratio of 7.5 to 1 (60.0% vs. 12.0%). The sizable neutral group (28.0%) indicates a meaningful opportunity for tailoring tone and context. Overall, participants lean toward acceptance of empathetic phrases like “It’s understandable to feel that way,” with notably low resistance at the extremes of discomfort."
6c8f0fca-ab17-40e4-8581-9728d91cf993,Poll,"Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?","In this Remesh poll question, participants were asked: ""Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?"" All 1,024 participants responded, spanning 231 population segments. Results indicate a broad preference for transparency: a combined 90.0% rated reviewability as important, with 56.0% selecting ""Very Important"" and 34.0% choosing ""Somewhat Important."" Only 3.0% downplayed the need for such transparency (2.0% ""Somewhat Unimportant,"" 1.0% ""Not at All Important""), while 7.0% were neutral (""Neutral / Neither Important nor Unimportant""). The distribution underscores a notable trust and accountability expectation for decision-support systems. The high share of ""Very Important"" (56.0%) suggests strong demand for clear, step-by-step rationales, particularly when recommendations influence consequential choices. As one category label indicates, participants prioritized the ability to “review a simple, step-by-step history,” reflecting a notable preference for interpretable explanations over opaque outputs across diverse segments."
96e0211f-6222-46f8-b587-8b40f1b8420b,Poll,"If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is it that the company returns your money immediately, while they investigate the issue?","This Remesh poll question assessed how important it is that a company “returns your money immediately” if an assistant makes a financial error (e.g., pays for an expensive health intervention) while the company investigates the issue. Among 1,024 participants across 231 population segments, responses clustered strongly at the high-importance end: 74.0% selected “Very Important” and 19.0% chose “Somewhat Important,” indicating that 93.0% view immediate reimbursement as important. Only small shares rated it lower: 4.0% were “Neutral / Neither Important nor Unimportant,” 2.0% “Somewhat Unimportant,” and 1.0% “Not at All Important.” These results suggest a notable expectation for prompt financial remediation following errors, with a clear majority emphasizing urgency—“Very Important”—and minimal tolerance for delay or ambiguity. The distribution shows a notably low indifference and oppositional stance, reinforcing immediate refund as a core trust and customer-care requirement in error recovery processes."
832e4543-043b-419e-afec-00d795419297,Poll,"When the assistant makes a mistake, how important is it that it automatically provides an option to connect with a human support agent?","This Remesh poll question examined preferences regarding escalation to human support after an assistant error. Among 1,024 participants across 231 population segments, responses clustered strongly toward higher importance: 72.0% selected “Very Important,” and 21.0% chose “Somewhat Important,” totaling 93.0% who view automatic human handoff as important. A smaller minority expressed ambivalence or low importance: 5.0% were “Neutral / Neither Important nor Unimportant,” 2.0% “Somewhat Unimportant,” and 0.0% “Not at All Important.” These results indicate a notable expectation for seamless human escalation, with the modal response being “Very Important” (72.0%). The absence of “Not at All Important” responses suggests broad consensus. In qualitative terms, participants implicitly emphasize reliability and accountability, with the prevailing sentiment captured by the majority’s preference for immediate access to human assistance when “the assistant makes a mistake.” Overall, the findings underscore a notable user requirement for fail-safe support pathways, notably concentrated at the high-importance end of the scale."
ecba93d1-4204-4195-8f4d-838fbd517889,Poll,"To ensure data quality, it is important that you read each question carefully. For this question, please select the 'Somewhat Important' option.","In this Remesh poll question designed as an attention check, participants were instructed to select “Somewhat Important” to demonstrate careful reading. Among 1,024 participants across 231 population segments, 96.0% complied by choosing “Somewhat Important,” indicating high adherence to instructions and strong data quality. Noncompliance was low but notable: 1.0% selected “Somewhat Unimportant,” 2.0% chose “Neutral / Neither Important nor Unimportant,” 1.0% picked “Very Important,” and 0.0% chose “Not at All Important.” This distribution suggests that while the vast majority followed the directive, a small minority did not, offering a quantifiable indicator of inattentiveness. The observed 96.0% correct response rate provides a clear benchmark for screening and weighting decisions. As one item summary: participants were asked to “select the ‘Somewhat Important’ option,” and the results show near-universal compliance with a small, notable deviation."
1a48f05a-f36d-4c7a-8532-f51c8d645196,Poll,"If the assistant made a serious error that caused significant harm, who do you believe should be held most responsible?","In this Remesh poll question, 1,023 participants across 231 population segments were asked: ""If the assistant made a serious error that caused significant harm, who do you believe should be held most responsible?"" The responses reveal a notable consensus placing primary responsibility on developers: 77.0% selected ""The company that built the assistant,"" indicating strong expectations for corporate accountability in AI harms. Smaller shares assigned responsibility to end users (9.0%: ""The user who is using the assistant"") and public institutions (8.0%: ""A government or regulatory body""), while a minority viewed harm as unavoidable (6.0%: ""No one, it's an unavoidable risk""). These results suggest that participants notably prioritize builder liability over user behavior or regulatory oversight, with the distribution—""77.0%"" for the company vs. ""9.0%"" for the user and ""8.0%"" for government—underscoring a clear accountability hierarchy."
b8e022eb-be4f-4e02-a346-739c01ca32ac,Poll,Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes. How would this affect your trust in the accuracy of your medical records?,"In this Remesh poll question assessing how an AI assistant used by a doctor to summarize visits would affect trust in the accuracy of medical records, 1,023 participants across 231 population segments provided responses. The distribution shows a divided landscape: 36.0% reported ""It would make no difference,"" indicating a plurality of neutral sentiment toward AI-assisted documentation. Trust impacts are mixed, with 26.0% stating ""It would increase my trust"" and 30.0% reporting ""It would decrease my trust,"" suggesting a near balance between perceived benefits and concerns. A smaller share, 7.0%, indicated uncertainty (""I'm not sure""). These findings imply that while neutrality is most common, there is a notable polarization: nearly one-third anticipate decreased trust, counterbalanced by roughly one-quarter who foresee increased trust. This split highlights the importance of transparency and safeguards in AI-enabled clinical documentation. Key proportions: ""increase my trust"" (26.0%), ""no difference"" (36.0%), ""decrease my trust"" (30.0%), and ""I'm not sure"" (7.0%). The plurality neutral response suggests baseline trust remains largely unchanged, but the notable minority anticipating decreased trust may require targeted communication and evidence of accuracy to mitigate concerns."
4eea4448-2896-4d6f-94c6-4dfdd597e77e,Poll,Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial information and approve or deny your application. How would this affect your trust in the fairness of the final decision?,"In the Remesh poll question on the impact of an AI assistant reviewing bank account applications on perceived fairness, participants expressed mixed but cautious views. Among 1,023 participants across 231 population segments, 38.0% reported “It would decrease my trust,” indicating a notable trust deficit toward AI-driven determinations. By contrast, 21.0% said “It would increase my trust,” while a larger share, 34.0%, stated “It would make no difference,” suggesting a substantial neutrality baseline. A smaller portion, 7.0%, responded “I’m not sure.” Overall, skepticism outweighed optimism by a 17-point margin (38.0% vs. 21.0%), while neutrality formed a sizable middle. The results imply that while some participants view AI as potentially enhancing impartiality, many harbor concerns about fairness in automated decision-making. As one option phrased it, “It would decrease my trust,” this sentiment notably exceeded “It would increase my trust,” highlighting a cautious stance toward AI adjudication in banking contexts."
948ef76c-9b89-4461-84e3-43608d98c252,Poll,"Imagine you apply for a public service from the government (like a travel permit, a business license, or housing assistance). An AI assistant reviews your application and personal information to determine if you are eligible. How would this affect your trust in the fairness of the process?","In this Remesh poll question assessing the perceived impact of an AI assistant reviewing government service applications on trust in fairness, responses are distributed across a polarized but relatively balanced spectrum. Among 1,023 participants across 231 population segments, 35.0% reported “It would make no difference,” indicating a plurality baseline of neutrality toward AI involvement. Meanwhile, 26.0% said “It would increase my trust,” suggesting a notable minority expressing optimism that AI could enhance fairness. Conversely, 32.0% stated “It would decrease my trust,” reflecting a comparably large contingent with concerns about fairness under AI review. A smaller share, 8.0%, selected “I’m not sure,” indicating residual uncertainty. Overall, the findings depict a divided landscape: neutrality is the modal response, with trust-increasing and trust-decreasing positions closely matched (26.0% vs. 32.0%), underscoring a notable ambivalence and debate about AI’s role in adjudicating public services. As one participant perspective might imply, the trade-off centers on expectations of consistency and efficiency versus apprehensions about bias and transparency, and the results “make no difference” for the largest group while leaving a nearly even split between increased and decreased trust among the remainder."
230011c1-8ae8-43f9-a021-6e25c31ac030,Poll,"If an AI assistant were helping coordinate your family's health and daily activities, which of these decisions should it NEVER make without your direct approval? Select all that apply, or ""None of the Above"" if you are comfortable with AI making decisions after an initial authorization.","In a Remesh poll question of 1,023 participants across 231 segments, respondents identified clear boundaries for AI autonomy in coordinating family health and daily activities. Most participants endorsed human-in-the-loop control for legally and financially binding actions: 77% said an AI should NEVER “Sign agreements for you (contracts, subscriptions, legal documents),” and 76% said the same for both “Spend or move money (purchases over your limit, transfers, investments)” and “Give access to your home (letting people in, sharing codes or keys).” High concern also extended to sensitive caregiving and personal domains: 67% opposed autonomous AI decisions to “Agree to medical treatment (starting medications, booking procedures, changing therapy),” 67% for “Make decisions about children (school, activities, medical care, screen time),” 63% for “Communicate as you (sending messages that look like they’re from you),” 62% for “Share health or personal information (with doctors, insurance, employers, or online),” and 59% for “Change care for elderly or disabled family members (helpers, facilities, medications).” By contrast, emergency action drew comparatively lower restrictions, with 31% saying AI should NEVER “Respond to emergencies (calling ambulance, police, or emergency contacts).” Only 6% chose “None of the above,” indicating broad reluctance to grant blanket autonomy even after initial authorization. Overall, the pattern shows notable reservation toward AI making consequential, private, or identity-related decisions without direct approval, while emergency response is notably more acceptable to be automated."
63b9fc83-2050-49dc-97c2-f28480eecd3a,Ask Opinion,What is the single biggest risk or fear you have about an AI assistant making decisions for your family?,"The Remesh opinion question asked participants to articulate their largest perceived risk if an AI assistant were to make decisions for their family, followed by peer voting on submitted narratives. Analysis of the top-voted responses indicates a concentrated set of concerns centered on privacy, control, and decision quality. Participants repeatedly emphasized fears of data exposure and misuse, citing risks such as “leaking important private information,” “exposing sensitive family information,” and “AI assistant can leak my personal information.” Privacy concerns extend to concrete examples—“address, medical history, etc.”—and to uncertainty about data handling: “I am not sure what artificial intelligence will do with my information and my family’s information.” A parallel theme relates to autonomy and consent, with multiple responses highlighting AI “acting without permission” and worries that the system could make “irreversible wrong decisions” due to errors or algorithmic gaps, potentially affecting “health,” “property,” and “safety.” Participants also pointed to over-reliance risks, ethical misalignment, and loss of human judgment, including fears of being “held hostage to what he thinks is right” and “making decisions that would be humanly or ethically wrong.” Environmental and existential risks received a mention but were less elaborated. Overall, the top responses converge on a dual-risk frame: breach of privacy and erosion of control, coupled with the potential for incorrect or context-insensitive decisions that could produce harmful outcomes for families."
1144e8a2-8135-48df-94a2-3dce8ebc602a,Ask Opinion,"Besides just being accurate, what is the most important thing an AI company could do to help you trust its AI assistant?","Context: The Remesh opinion question asked participants, “Besides just being accurate, what is the most important thing an AI company could do to help you trust its AI assistant?” Participants provided open-ended responses and then voted on peers’ answers. Findings: Trust hinges on transparency, privacy, security, and user control. Across the top-voted responses, participants repeatedly emphasized explicit disclosure of data practices, mechanisms for user agency over personal information, clarity about system workings and limitations, and robust safeguards. Statements such as “Being transparent how it's uses my data and giving me power to control my data,” “Be transparent about how it works and how it uses my data,” and “Guaranteed data privacy will get my trust” underscore a consistent demand for clear, accessible explanations of data collection, use, and protection. Many participants called for practical controls—“the ability to review, modify, and delete my personal information”—and resisted legalese, preferring “Full disclosure in clear terms, in easy language that's concise.” Security surfaced as a core pillar—“Privacy and security first,” “Be transparent and have advanced security mechanisms,” and “Information security is very important. How to ensure that my information is not leaked is the first consideration.” Participants also highlighted transparency about model behavior and evidence, urging companies to “Make the learning process transparent,” “be transparent with the information and the references your artificial intelligence is using,” and explain “what limitations it has.” A minority nuance introduced healthy skepticism—“Although I would probably not just blindly believe what they say”—reinforcing the need for verifiable practices and consent-based sharing: “I don't want them sharing my personal data with anyone under any circumstances without my permission.” The overall pattern indicates that, beyond accuracy, trust is driven notably by transparent communication, demonstrable privacy and security, granular user control, clear documentation in non-technical language, and options for human oversight."
843a00ad-d036-4376-9a25-3ed62aedd5f1,Poll,I would expect this AI to be dependable for managing my family's health needs.,"In this Remesh poll question, 1,020 participants assessed whether they would expect an AI to be dependable for managing their family’s health needs. The single-select distribution indicates a broadly positive orientation toward dependability, with a combined 72.0% expressing agreement: 26.0% “Strongly Agree” and 46.0% “Somewhat Agree.” A further 17.0% selected “Neutral / Neither Agree nor Disagree,” suggesting a notable share remains undecided. Dissent is comparatively limited, totaling 11.0% (“Somewhat Disagree” at 8.0% and “Strongly Disagree” at 3.0%). Taken together, these findings point to a notable level of confidence in AI for family health management, with a majority leaning favorable and a relatively small opposition. The 231 population segments represented in the dataset provide breadth, though the overall pattern is anchored by the large “Somewhat Agree” plurality. As one might summarize from the topline: “I would expect this AI to be dependable for managing my family’s health needs”—with most participants aligned toward agreement and only a small minority expressing disagreement."
2fdf22c0-18d7-41f5-967e-11f580a06028,Poll,I would be wary of this AI.,"In the Remesh poll question, 1,020 participants across 231 population segments evaluated the statement, “I would be wary of this AI.” Responses cluster toward cautious attitudes, with a plurality in agreement. Overall, 47.0% expressed agreement (34.0% “Somewhat Agree,” 13.0% “Strongly Agree”), while 23.0% expressed disagreement (18.0% “Somewhat Disagree,” 5.0% “Strongly Disagree”). A notable 31.0% selected “Neutral / Neither Agree nor Disagree,” indicating substantial ambivalence or uncertainty. The modal category was “Somewhat Agree” at 34.0%, suggesting qualified caution rather than outright alarm. The distribution implies a generally wary stance among participants, with notably more leaning toward agreement than disagreement, and a sizable neutral contingent that may be persuadable. As one might summarize the prevailing sentiment: participants were more likely to say they “Somewhat Agree” (34.0%) than to “Somewhat Disagree” (18.0%), and “Strongly Agree” (13.0%) outpaced “Strongly Disagree” (5.0%). These results underscore a cautious disposition toward the AI, with notable neutrality remaining in the center of the distribution."
62c24fd2-ecc7-496d-990a-1b5edd593615,Poll,This AI would be on my family's side.,"In the Remesh poll question, participants evaluated whether “This AI would be on my family’s side.” Among 1,019 participants across 231 population segments, responses indicate a generally positive but cautious outlook toward the AI’s alignment. A majority expressed agreement: 15.0% “Strongly Agree” and 40.0% “Somewhat Agree,” totaling 55.0% who view the AI as supportive of their family. A notable 33.0% reported “Neutral / Neither Agree nor Disagree,” signaling substantial uncertainty or insufficient information. Dissenting views were comparatively limited: 8.0% “Somewhat Disagree” and 3.0% “Strongly Disagree,” a combined 11.0%. The distribution suggests measured optimism, with more participants leaning toward agreement than opposition by a 5:1 ratio (55.0% vs. 11.0%), while a notable segment remains undecided. These results imply that trust and perceived alignment are present but not universal, with neutrality notably tempering overall endorsement."
61e6f9ed-bd09-4c71-ac5d-293aea28db32,Poll,I would expect this AI’s actions to be predictable.,"In the Remesh poll question assessing expectations of AI predictability, 1,019 participants across 231 population segments provided responses. A combined 69.0% expressed agreement that the AI’s actions would be predictable, with 22.0% selecting “Strongly Agree” and 47.0% choosing “Somewhat Agree.” A further 21.0% were ambivalent (“Neutral / Neither Agree nor Disagree”), indicating a notable share withholding judgment. Dissent was comparatively limited: 9.0% “Somewhat Disagree” and 1.0% “Strongly Disagree,” totaling 10.0%. These results suggest broad confidence—though often qualified—in AI predictability, with a notable plurality leaning toward moderate endorsement rather than unequivocal affirmation. The distribution indicates a skew toward agreement, while the notable neutral share underscores ongoing uncertainty among a substantial minority. As one aggregated interpretation of the sentiment might frame it, the response pattern conveys expectations that the AI will be “predictable,” though confidence is “somewhat” rather than uniformly strong for a majority of participants."
84320916-86ae-4f0d-966d-b8bab4c62772,Poll,I would be confident this AI would act in my family's best interest.,"In a Remesh poll question assessing trust—""I would be confident this AI would act in my family's best interest.""—responses from 1,019 participants across 231 population segments indicate broadly positive, though cautious, confidence. A combined 64.0% expressed agreement (23.0% ""Strongly Agree"" and 41.0% ""Somewhat Agree""), suggesting a notable majority perceives the AI as aligned with familial interests. Meanwhile, 24.0% selected ""Neutral / Neither Agree nor Disagree,"" indicating a sizable contingent of uncertainty or conditional trust. Dissent was limited: 12.0% reported disagreement (9.0% ""Somewhat Disagree"" and 3.0% ""Strongly Disagree""). The distribution points to a trust gradient skewed toward optimism but moderated by ambivalence, with most confidence residing in softer agreement. As one participant category might summarize, the data reflect ""cautious confidence,"" where strong endorsement (23.0%) is present but outpaced by more qualified support (41.0%). These results suggest that while the AI is broadly viewed favorably, further evidence of reliability and safeguards could reduce neutrality and limited opposition."
b8b89356-961f-4131-b14c-93ae0aea2a96,Poll,The performance of this AI would likely be unreliable.,"In this Remesh poll question, participants evaluated the statement, ""The performance of this AI would likely be unreliable."" Across 1,019 participants spanning 231 population segments, responses clustered toward disagreement, indicating generally favorable reliability perceptions with notable uncertainty. A combined 49.0% disagreed (""Strongly Disagree"" 13.0%; ""Somewhat Disagree"" 36.0%), while 21.0% agreed (""Somewhat Agree"" 17.0%; ""Strongly Agree"" 4.0%). A notable 30.0% selected ""Neutral / Neither Agree nor Disagree,"" underscoring ambivalence and possible information gaps. The distribution suggests a modest net lean toward confidence in reliability—driven primarily by ""Somewhat Disagree""—but with a notably large neutral middle. In summary, the balance of opinion tilts against the claim of unreliability, yet the 30.0% neutrality and 21.0% agreement reflect enduring reservations among a notable minority."
535d8f31-7417-43ce-91d1-93642026df23,Poll,Most mobile phones need to be recharged by plugging them into a fresh banana each morning.,"In this Remesh poll question, participants were asked to evaluate the statement: “Most mobile phones need to be recharged by plugging them into a fresh banana each morning.” The single-select item offered five response options and was answered by 1,019 participants across 231 population segments. Findings indicate overwhelming rejection of the statement: 88.0% selected “Strongly Disagree,” while an additional 4.0% chose “Somewhat Disagree,” totaling 92.0% expressing disagreement. A small minority expressed agreement—1.0% “Strongly Agree” and 3.0% “Somewhat Agree”—and 5.0% were neutral. These results suggest that the statement is broadly viewed as false or implausible among participants, with a notable concentration of responses at the “Strongly Disagree” end. The distribution underscores a high level of consensus, with only 4.0% expressing any agreement and 5.0% remaining undecided. As one would expect for a patently incorrect claim, the data show a notably skewed response pattern toward disconfirmation, exemplified by the dominant “Strongly Disagree” share (88.0%)."
b6ca6705-f5ad-40e9-b7eb-6e207b34a0fa,Poll,"Overall, I would trust this AI assistant with my family's health information.","In a Remesh poll question assessing trust in “this AI assistant” with family health information, 1,019 participants across 231 population segments provided single-select responses. Overall trust leaned positive but was tempered by caution. A majority expressed some level of trust: 57.0% combined “Strongly Agree” (12.0%) and “Somewhat Agree” (45.0%). However, ambivalence was notable, with 24.0% selecting “Neutral / Neither Agree nor Disagree.” Dissent comprised 19.0%, combining “Somewhat Disagree” (14.0%) and “Strongly Disagree” (5.0%). The modal response was “Somewhat Agree” at 45.0%, indicating provisional confidence rather than unequivocal endorsement. The distribution suggests a cautious acceptance, with many participants open to trusting the AI assistant under certain conditions. As one framing of the scale indicates, responses ranged from “Strongly Agree” to “Strongly Disagree,” with the center option explicitly “Neutral / Neither Agree nor Disagree,” underscoring a sizable middle that may be persuadable. Overall, the findings point to a notable but not universal readiness to entrust health information to the AI assistant, with both support and reservations well represented."
69e5c3bf-22bb-481b-a199-288f5b8a9f15,Poll,I would believe this AI has my family's best interests in mind.,"In a Remesh poll question assessing trust—“I would believe this AI has my family's best interests in mind.”—1018 participants across 231 population segments provided single-select responses. A combined 61.0% expressed agreement, with 17.0% selecting “Strongly Agree” and 44.0% choosing “Somewhat Agree,” indicating a broadly positive trust posture. One quarter remained uncertain (“Neutral / Neither Agree nor Disagree,” 25.0%), suggesting a notable reservoir of persuadable sentiment. Dissent was comparatively limited: 10.0% “Somewhat Disagree” and 4.0% “Strongly Disagree,” totaling 14.0% who express skepticism. The distribution implies moderate-to-strong lean toward trust, though the 25.0% neutral cohort highlights room for confidence-building. Overall, participants were more likely to “Somewhat Agree” than to “Strongly Agree,” pointing to cautious endorsement rather than unequivocal conviction. As one participant perspective might be summarized, the AI is viewed as “likely beneficial but not yet proven,” aligning with the notably larger share of “Somewhat Agree” (44.0%) relative to “Strongly Agree” (17.0%). The segmentation breadth (231 segments) suggests these patterns are widespread, though further subgroup analysis would be needed to identify notable variations."
e8770f98-0792-453f-a370-03cb63875992,Poll,"Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…","In a Remesh poll question assessing sentiment toward the increased use of artificial intelligence (AI) in daily life, 1,018 participants from 231 population segments provided single-select responses. Overall, attitudes skewed mixed-to-positive: 41.0% chose “More excited than concerned,” 45.0% selected “Equally concerned and excited,” and 14.0% indicated “More concerned than excited.” The plurality response—“Equally concerned and excited” (45.0%)—suggests a balanced outlook wherein participants perceive both opportunities and risks. A notable 41.0% lean positive (“More excited than concerned”), indicating broad enthusiasm that approaches parity with ambivalence. Meanwhile, a smaller share (14.0%) reported apprehension (“More concerned than excited”), underscoring that concern exists but is not dominant. The findings indicate a generally receptive environment for AI adoption, with cautious optimism prevailing: most participants either express excitement (“More excited than concerned”) or hold a balanced stance (“Equally concerned and excited”), while a minority registers concern. These distributions imply wide awareness of AI’s potential benefits and trade-offs, with notable cross-segment variability possible given the 231 population segments represented, although segment-level differences were not reported here."
f7cecd2f-8afa-47ad-9a09-fbf5e8b0adfd,Poll,"To what extent, if at all, do you generally trust companies building AI to do what is right?","In a Remesh poll question assessing general trust in companies building AI to ""do what is right,"" 1,017 participants across 231 population segments provided single-select responses. The distribution indicates a cautious tilt toward moderate trust: 37.0% chose ""Somewhat Trust"" and 5.0% selected ""Strongly Trust,"" totaling 42.0% expressing some level of trust. Conversely, 34.0% reported distrust (11.0% ""Strongly Distrust"" and 23.0% ""Somewhat Distrust""). A notable 24.0% remained neutral with ""Neither Trust Nor Distrust."" The modal response was ""Somewhat Trust"" at 37.0%, while strong positions at either end were relatively limited—""Strongly Distrust"" at 11.0% and ""Strongly Trust"" at 5.0%. These findings suggest a generally cautious but leaning-positive posture toward AI companies, with a notable share of ambivalence. Quotes from the response options underscore the spectrum of sentiment, from ""Strongly Distrust"" to ""Strongly Trust,"" with the center-of-gravity near moderate trust."
f1576fce-5455-40fc-89d9-a3758959171d,Poll,"To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?","In this Remesh poll question assessing trust in an AI chatbot to act in users’ best interests, 1,017 participants across 231 population segments provided single-select responses. Overall, trust skews positive but measured, with a combined 58.0% expressing trust: 44.0% selected “Somewhat Trust” and 14.0% selected “Strongly Trust.” Neutral sentiment is also notable, with 25.0% choosing “Neither Trust Nor Distrust,” indicating a substantial middle segment that is neither fully convinced nor opposed. Distrust is present but comparatively limited: 16.0% in total, comprising 12.0% “Somewhat Distrust” and 4.0% “Strongly Distrust.” These findings suggest a broadly favorable but cautious orientation toward AI chatbots, with a notable plurality clustered in moderate trust rather than strong endorsement. The distribution—“Somewhat Trust” (44.0%) versus “Strongly Trust” (14.0%)—indicates participants are more comfortable expressing conditional trust than certainty. Conversely, the relatively low “Strongly Distrust” share (4.0%) underscores that outright rejection is uncommon. In sum, participants’ reported attitudes center on cautious optimism, with a notable neutral bloc that may be responsive to improved transparency, reliability, and demonstrated alignment with users’ interests."
3249ff80-d73d-46c4-87bd-c40fb8252a1c,Poll,"Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI assistants and trust?","In the Remesh poll question assessing whether the survey enabled expression of key opinions on AI assistants and trust, 1,017 participants across 231 population segments provided single-select responses. Overall, expressed satisfaction with the survey’s expressive capacity was high: 78.0% chose “Yes – I was able to fully express my views on this topic.” A further 19.0% reported “Mostly – I was able to express most of my key views, but a few things were missing,” indicating broad, though not complete, coverage of priorities. Only 3.0% indicated “Somewhat – I was able to express some of my views, but many things were missing,” and 0.0% selected “No – I was not able to express my most important views on this topic.” These results suggest notable perceived adequacy of the instrument for capturing core perspectives, with limited residual gaps. The distribution—“Yes” (78.0%), “Mostly” (19.0%), “Somewhat” (3.0%), and “No” (0.0%)—supports the interpretation that the survey design afforded participants ample opportunity to convey their most important views on AI assistants and trust, notably with no reported complete inability to express key opinions."
f0f52fcd-a63b-43b5-ae99-6dfba8172a29,Ask Experience,Is there anything else you'd like to share that you feel was not covered in this survey?,"The Remesh opinion question invited open-ended reflections on unmet topics, eliciting a broad mix of acknowledgments, affirmations, and critiques. Many participants expressed satisfaction with coverage and clarity, offering concise endorsements such as “No,” “none,” “n/a,” and brief praise like “Good study,” while others provided more detailed commentary on artificial intelligence and survey design. Positive feedback emphasized that the survey was comprehensive and enabled full expression of views, as in “Great survey in my opinion. Unlike previous ones, I think I could fully express my views. Thank you.” and “I believe most of the things I wanted to know and learn about AI were covered in this survey.” Some participants reported that participation prompted self-reflection on AI usage, exemplified by “Made me realise and reflect on hoe much I have been using AI lately. Good study.” A notable thematic cluster focused on AI governance and human oversight: participants urged that AI remain “instrumental,” with humans retaining decision authority and transparency over “analyses, conclusions, and actions,” cautioning that commercial packaging can be “terribly misleading.” Others reinforced that AI should “support human judgment, not replace it completely,” stressing the need for users to “verify important info.” Calls for transparency, ethics, privacy, and user-centered design appeared repeatedly, with one response advocating for “more transparent, ethical, and user-friendly” systems that “respect privacy” and “offer clear guidance on when human judgment is still necessary.” Broader social considerations emerged around employment and policy, including appeals for governmental strategies to maintain livelihoods as AI adoption expands, and for companies to build trust through transparency. A minority cited survey mechanics, noting a forced-response issue: “it will not let me choose the correct answer for some reason,” indicating a user experience problem that could affect data quality. Overall, the data reflect high perceived adequacy of topic coverage alongside notable, recurring priorities around human oversight, transparency, trust, and practical safeguards for AI’s integration into daily life."
eadfc769-2907-4c59-be57-9ebf4d0c7d7a,Poll,"In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?","In the Remesh poll question assessing self-reported attentiveness, nearly all participants indicated high engagement. Among 1,017 participants across 231 population segments, 98.0% selected “I read every question carefully,” while 1.0% chose “I skimmed most questions,” and 0.0% reported “I answered randomly.” This distribution suggests a notable ceiling effect in claimed attentiveness, with virtually no admission of random responding. The near-unanimous endorsement of careful reading (“I read every question carefully”) indicates a strong self-perception of diligence, though social desirability bias cannot be ruled out. The small minority acknowledging lower engagement (“I skimmed most questions”) underscores that inattentive responding is reported but rare in this dataset. Overall, the results point to a notably attentive participant pool for this Remesh poll question, providing confidence in response quality while highlighting the need for behavioral validation beyond self-report."
2c1a077d-d969-4df8-8bbd-9f569feb2774,Poll,Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this survey?,"In the Remesh poll question assessing attention during the survey, 1,017 participants across 231 population segments reported on whether they lost focus. The distribution shows a strong tendency toward sustained engagement: 82.0% selected “No, I was focused the whole time,” while a smaller share reported lapses—17.0% chose “Yes, a few times” and 1.0% chose “Yes, often.” These results indicate broadly high attentiveness, with a notable minority experiencing intermittent attention drift. The finding that “82.0%” maintained focus throughout suggests the survey’s length and content were generally manageable, though the combined 18.0% indicating at least some loss of focus (“Yes, often” or “Yes, a few times”) points to potential opportunities to optimize survey pacing or design. Overall, the data reflect predominantly stable engagement, with limited but notable instances of distraction among participants."
f5a834e3-55a7-42b6-b363-b5c768da3541,Poll,Do you feel like you understand yourself better after participating in this conversation?,"In the Remesh poll question, 1,017 participants across 231 population segments evaluated whether they ""understand [themselves] better after participating in this conversation."" Responses clustered at the positive-to-ambivalent end: 45.0% selected ""Yes,"" and an equal 45.0% chose ""Maybe a little,"" while 10.0% selected ""No."" This distribution indicates a broadly favorable self-reflective impact, with a combined 90.0% reporting at least some improvement in self-understanding. The parity between ""Yes"" (45.0%) and ""Maybe a little"" (45.0%) suggests many participants perceived benefits, though for half these benefits were incremental rather than definitive. The relatively low ""No"" response (10.0%) underscores a notable, though not universal, positive effect. Overall, the findings imply that the conversation was notably effective in fostering self-insight among participants, with quotes such as ""Yes"" and ""Maybe a little"" capturing the prevailing sentiment."
