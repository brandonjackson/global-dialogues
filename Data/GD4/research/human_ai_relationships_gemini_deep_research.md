
# **The Evolving Tapestry of Human-AI Relationships: Sentiments, Interactions, and Societal Implications**


## **I. Introduction: The Dawning Age of Human-AI Relationships**

**A. The Accelerating Integration of AI into Social Life**

The contemporary technological landscape is characterized by an unprecedented acceleration in the capabilities and integration of artificial intelligence (AI) into the fabric of daily life.<sup>1</sup> This expansion, particularly evident in the advancements of generative AI and sophisticated conversational agents, is fostering interactions that are increasingly nuanced and human-like.<sup>3</sup> The confluence of decades of growth in digital information creation, consumption, and storage has laid the groundwork for these developments.<sup>1</sup> As AI systems surpass traditional benchmarks, such as the once-formidable Turing Test, their adoption has surged, with millions of individuals now engaging with AI for both professional tasks and leisure pursuits.<sup>2</sup> This marks a significant departure from AI's earlier role primarily as a functional tool. Instead, a discernible shift is underway, positioning AI not merely as an instrument for task completion but as a potential partner, companion, or collaborator in various aspects of human endeavor.<sup>3</sup>

This transition from AI as a purely utilitarian technology to an entity capable of relational engagement represents more than a mere technological progression; it signifies a profound socio-psychological evolution. Early AI applications were predominantly task-oriented, designed for specific functions with limited interactive capabilities.<sup>1</sup> However, the advent of powerful large language models (LLMs) and generative AI has endowed machines with the capacity for more natural, personalized, and contextually aware conversations.<sup>3</sup> Consequently, users are increasingly perceiving these AI systems as social agents <sup>3</sup>, leading to the formation of emotional attachments and bonds that were previously inconceivable.<sup>5</sup> The emergence of new theoretical constructs, such as "socioaffective alignment" <sup>3</sup>, underscores this paradigm shift. This concept highlights a necessary focus on the emotional and psychological dynamics inherent in these new forms of human-AI interaction, moving beyond purely technical or task-based considerations. Thus, the current era is distinguished by AI's entry into roles traditionally occupied by humans, compelling a re-evaluation of what constitutes a "relationship" and the nature of social connection itself.

**B. Defining "Human-AI Relationships"**

The term "human-AI relationships" encompasses a broad spectrum of interactions. At one end lies the transactional use of AI, such as employing algorithms for data analysis or task automation. At the other end, and of increasing relevance, is the phenomenon of sustained social engagement with AI systems.<sup>3</sup> This engagement can manifest in deep emotional bonds, including those formed in the context of therapy, intimacy, friendship, companionship, professional collaboration, and mentorship. The evolution from a "sociotechnical" perspective, which views AI within broader social and technical systems, to a "socioaffective" one <sup>3</sup>, which emphasizes the emotional and psychological interplay between human and AI, captures the deepening and personalization of these connections. This report will explore these varied modalities, focusing on the up-to-date understanding of how individuals feel about, engage with, and are affected by these evolving relationships.

The rapid pace of AI development, particularly in its relational capacities, appears to be outstripping both societal and individual abilities to adapt. This creates a dynamic where responses to these new forms of interaction are often reactive rather than proactive. AI capabilities are advancing at an exponential rate <sup>2</sup>, while public opinion, ethical frameworks, and regulatory measures struggle to keep pace.<sup>2</sup> For instance, the United Nations Secretary-General has warned that the swift progression of AI development is outpacing regulatory efforts, posing potential risks.<sup>10</sup> Research endeavors are actively identifying significant gaps in current knowledge, such as the need for longitudinal studies to understand long-term impacts and the dynamics of reciprocal adaptation between humans and AI.<sup>7</sup> This indicates that the field is still in the nascent stages of comprehending the enduring effects of these relationships. The emergence of phenomena like emotional dependency and addiction to AI interactions <sup>3</sup> further suggests that unforeseen consequences are arising as these technologies become more deeply embedded in human lives. This situation implies that society is currently navigating uncharted territory, where the full implications of human-AI relationships are yet to be fully understood, necessitating urgent, continuous, and comprehensive investigation.

**C. Report Objectives and Structure**

This report aims to provide a comprehensive literature overview of up-to-date facts and research findings concerning the multifaceted domain of human-AI relationships. It will delve into public sentiment towards AI, the current state and nature of these interactions, and the diverse ways in which individuals are relating to AI systems across various contexts. The subsequent sections will explore the shifting landscape of public opinion, the diverse forms of human-AI bonds, the psychological underpinnings and impacts of these relationships, the critical ethical considerations and governance challenges, and finally, the future trajectory of this rapidly evolving field.


## **II. The Shifting Landscape of Public Opinion on AI**

Understanding how people perceive and feel about artificial intelligence is crucial for contextualizing the development and societal integration of human-AI relationships. Recent global surveys and analyses reveal a complex and evolving tapestry of public opinion, marked by both increasing optimism about AI's potential and persistent concerns regarding its ethical implications and societal impact.

**A. Global Sentiment: A Complex Tapestry of Optimism and Concern**

Globally, there is a trend towards cautious optimism regarding AI products and services. Data from 2024 indicates that 55% of individuals across 26 surveyed nations believe that AI offers more benefits than drawbacks, a modest increase from 52% in 2022.<sup>2</sup> Notably, the most significant increases in optimism have been observed in countries that were previously among the most skeptical, including Great Britain, Germany, the United States, Canada, and France.<sup>2</sup> This suggests a gradual shift in public perception, possibly fueled by increased exposure to and familiarity with AI applications.

Concurrently, the expectation of AI's impact on daily life is rising. Approximately two-thirds of people worldwide now anticipate that AI-powered products and services will significantly affect their daily routines within the next three to five years, representing a 6 percentage point increase since 2022.<sup>11</sup> This growing awareness of AI's pervasive potential underscores the urgency of understanding public attitudes and preparing for widespread integration.

**B. Perceived Benefits vs. Drawbacks: Hopes and Fears**

The public perceives a range of benefits from AI. Many see it as a tool for saving time and enhancing entertainment options.<sup>11</sup> In the professional sphere, a majority (60%) agree that AI will change how individuals perform their jobs in the next five years, although a smaller subset (36%) express fear of job replacement.<sup>11</sup> This aligns with the view that AI is more productively seen as augmenting human labor, with AI excelling at analyzing stable historical data while humans contribute intuition, innovation, and adaptability to dynamic environments.<sup>1</sup>

However, this optimism is tempered by significant skepticism and concern. There is growing doubt about the ethical conduct of companies developing AI, with global confidence that these companies will protect personal data falling from 50% in 2023 to 47% in 2024.<sup>2</sup> Furthermore, fewer people now believe that AI systems are unbiased and free from discrimination compared to the previous year.<sup>11</sup> Specific applications, such as self-driving cars, continue to evoke high levels of distrust in some regions, with 61% of people in the US expressing fear of them.<sup>11</sup> Research also indicates that people are generally concerned about the risks associated with automated decision-making and hold mixed opinions regarding its fairness and usefulness at a societal level.<sup>12</sup> Public discourse analysis has even shown a dominance of negative emotions, such as anger and disgust, in relation to AI.<sup>13</sup> This tension between recognized utility and underlying anxiety is a critical factor shaping the environment in which human-AI relationships are forming. While practical benefits are acknowledged, deeper fears about control, ethical integrity, and societal consequences persist, influencing the willingness of individuals to embrace AI in more personal or relational capacities.

The observed increase in global optimism, particularly in previously skeptical Western nations <sup>2</sup>, coexists paradoxically with declining trust in the ethical conduct and data handling practices of AI companies. While data indicates a rise in overall optimism regarding AI products and services <sup>2</sup>, confidence in AI companies' commitment to protecting personal data has concurrently diminished, and fewer individuals perceive AI systems as unbiased.<sup>2</sup> This apparent contradiction suggests a nuanced public stance: individuals may increasingly recognize the *potential utility and benefits* of AI, possibly due to wider exposure and more sophisticated applications, as reflected in the sentiment that "AI products and services offer more benefits than drawbacks".<sup>11</sup> However, this acknowledgment does not equate to unconditional trust in the *stewards* of AI technology (the companies) or in the inherent *fairness* of the systems themselves. The implication is that the acceptance of AI might be driven more by its perceived utility and an sense of its inevitability rather than by a deep-seated confidence in its governance. This creates a somewhat fragile foundation for the development of human-AI relationships, where utility might be embraced even amidst underlying anxieties about ethical oversight and data security.

**C. Cultural Nuances: The East-West Divide and Beyond**

Public opinion on AI is not monolithic; significant regional and cultural variations exist. A persistent pattern shows markedly higher optimism in many Asian countries compared to Western nations. For example, large majorities in China (83%), Indonesia (80%), and Thailand (77%) believe AI-powered products and services offer more benefits than drawbacks. In contrast, this view is shared by only a minority in countries like Canada (40%), the United States (39%), and the Netherlands (36%).<sup>2</sup>

These differences can be partly understood through the lens of cultural psychology, particularly the dimension of individualism versus collectivism. Research suggests that collectivist cultures, prevalent in many Eastern societies, are more likely to view AI as an extension of the self and as a beneficial societal force. Individuals in these cultures may be more open to accepting external elements, including technology, as powerful and integrative. Conversely, individualistic cultures, common in Western societies, tend to perceive AI as external to the self, potentially viewing it as a threat to personal autonomy and uniqueness.<sup>14</sup> These cultural frameworks influence not only public perception but also the rate of AI adoption by companies and the perceived usefulness of AI tools, highlighting the need for context-specific strategies in designing and deploying AI, especially in sensitive areas like education.<sup>14</sup>

These cultural frameworks act as powerful mediating variables in AI perception and adoption. The clear delineation of how individualistic cultures may view AI as external and potentially threatening to autonomy, while collectivist cultures tend to see it as an extension of the self and more readily accept it <sup>14</sup>, has profound implications. If perception and acceptance of AI vary so significantly based on cultural values, it logically follows that the *types* of relationships formed with AI (e.g., the degree of reliance on AI for social support, its integration into family structures) and the *ethical considerations* that are prioritized (e.g., individual privacy versus collective benefit) will also differ considerably across societies. This could lead to a fragmented global landscape for AI governance and ethics concerning relational AI, where what is deemed acceptable or desirable in one cultural context might be viewed as problematic or even unethical in another. Consequently, the notion of a universal model for "healthy" or "ethical" human-AI relationships may be unattainable or inappropriate; localized and culturally sensitive approaches will likely be necessary to navigate this complex terrain effectively.

**D. Trust and Regulation**

The growing skepticism about the ethical conduct of AI companies and the declining trust in their data protection practices <sup>2</sup> are fueling calls for stronger governance and regulation. In the United States, for instance, there is broad support for AI regulation among local policymakers, with 73.7% agreeing in 2023 that AI should be regulated, a significant increase from 55.7% in 2022. Key priorities for these policymakers include stricter data privacy rules and provisions for retraining individuals whose jobs may be affected by AI.<sup>11</sup> This trend towards seeking regulatory oversight is a direct response to the perceived risks associated with AI and will inevitably shape the legal and ethical guardrails within which human-AI relationships can develop and mature.

Public concern about job replacement by AI, while present (36% globally believe AI will replace their jobs in the next five years), is notably less widespread than the expectation that AI will fundamentally change how jobs are performed (60% globally).<sup>11</sup> This 24-percentage point difference is substantial and suggests a public that is perhaps beginning to internalize the narrative of AI as a collaborator or an augmentation tool rather than purely a displacer of human labor. This perspective is supported by research indicating that AI is "more productively viewed as augmenting" human capabilities, with AI systems excelling at tasks like stable data analysis, while humans contribute intuition, innovation, and rapid adaptability.<sup>1</sup> Similarly, effective human-AI collaboration is seen as a pathway to improved decision-making and enhanced productivity.<sup>6</sup> This evolving perception has direct implications for how individuals will relate to AI in professional settings. It could foster more positive and collaborative workplace relationships if the augmentation aspect is emphasized and managed effectively. Conversely, if the threat of replacement, even if perceived as lower, looms large or is poorly communicated, it could lead to resentment and resistance. The focus, therefore, shifts towards ensuring the *quality* of these collaborative human-AI relationships, aiming for systems and integrations that are effective, fair, and human-centric.

**Table 1: Global Public Opinion on AI: Key Metrics (2022-2025)**


<table>
  <tr>
   <td><strong>Metric</strong>
   </td>
   <td><strong>2022</strong>
   </td>
   <td><strong>2023</strong>
   </td>
   <td><strong>2024</strong>
   </td>
   <td><strong>Source(s)</strong>
   </td>
  </tr>
  <tr>
   <td>Global: AI products/services offer more benefits than drawbacks
   </td>
   <td>52%
   </td>
   <td>---
   </td>
   <td>55%
   </td>
   <td><sup>11</sup>
   </td>
  </tr>
  <tr>
   <td>Global: Expect AI to significantly impact daily life in next 3-5 years
   </td>
   <td>~60.7%
   </td>
   <td>---
   </td>
   <td>66.7%
   </td>
   <td><sup>11</sup>
   </td>
  </tr>
  <tr>
   <td>Global: Confidence AI companies protect personal data
   </td>
   <td>---
   </td>
   <td>50%
   </td>
   <td>47%
   </td>
   <td><sup>11</sup>
   </td>
  </tr>
  <tr>
   <td>Global: Belief AI systems are unbiased & free from discrimination
   </td>
   <td>---
   </td>
   <td>Higher
   </td>
   <td>Lower
   </td>
   <td><sup>11</sup>
   </td>
  </tr>
  <tr>
   <td>Regional Optimism (Benefits > Drawbacks, 2024): China
   </td>
   <td>---
   </td>
   <td>---
   </td>
   <td>83%
   </td>
   <td><sup>2</sup>
   </td>
  </tr>
  <tr>
   <td>Regional Optimism (Benefits > Drawbacks, 2024): Indonesia
   </td>
   <td>---
   </td>
   <td>---
   </td>
   <td>80%
   </td>
   <td><sup>2</sup>
   </td>
  </tr>
  <tr>
   <td>Regional Optimism (Benefits > Drawbacks, 2024): USA
   </td>
   <td>35%
   </td>
   <td>---
   </td>
   <td>39%
   </td>
   <td><sup>2</sup>
   </td>
  </tr>
  <tr>
   <td>Regional Optimism (Benefits > Drawbacks, 2024): Canada
   </td>
   <td>32%
   </td>
   <td>---
   </td>
   <td>40%
   </td>
   <td><sup>2</sup>
   </td>
  </tr>
  <tr>
   <td>US Local Policymakers: Agree AI should be regulated
   </td>
   <td>55.7%
   </td>
   <td>---
   </td>
   <td>73.7%
   </td>
   <td><sup>11</sup>
   </td>
  </tr>
  <tr>
   <td>Global: Workers expect AI to change how they do their job (next 5 yrs)
   </td>
   <td>---
   </td>
   <td>---
   </td>
   <td>60%
   </td>
   <td><sup>11</sup>
   </td>
  </tr>
  <tr>
   <td>Global: Workers fear AI will replace their job (next 5 yrs)
   </td>
   <td>---
   </td>
   <td>---
   </td>
   <td>36%
   </td>
   <td><sup>11</sup>
   </td>
  </tr>
</table>


*Note: "~60.7%" for 2022 daily impact expectation is calculated from "an increase of 6 percentage points since 2022" to reach 66.7% in 2024. "Higher/Lower" for bias indicates trend from 2023 to 2024.*


## **III. The Multifaceted Nature of Human-AI Bonds**

As artificial intelligence becomes more sophisticated and integrated into daily life, the ways humans relate to AI are diversifying beyond simple tool usage into complex, often emotionally charged, interactions. These bonds manifest in various forms, including companionship, romantic connections, therapeutic alliances, and collaborative partnerships.

**A. AI as Companions: Friendship, Emotional Support, and the Battle Against Loneliness**

A prominent development in human-AI interaction is the emergence of AI companions specifically designed for emotional and social support.<sup>3</sup> Platforms such as CharacterAI report substantial user engagement, with users spending considerable time interacting with these AI entities.<sup>9</sup> The motivations for seeking AI companionship are varied, commonly including the desire for emotional comfort, stress relief, an escape from social pressures <sup>16</sup>, and a means to alleviate feelings of loneliness.<sup>5</sup> Curiosity also plays a role in initiating these interactions.<sup>22</sup>

Users often perceive significant benefits from these AI companions, such as their consistency, lack of judgment, ability to be customized, and constant availability.<sup>5</sup> Social chatbots, for example, can offer a nonjudgmental and readily accessible communication channel, sometimes serving as substitutes for human friends.<sup>20</sup> Empirical studies have begun to explore these effects. Research on the "Luda Lee" social chatbot indicated reductions in loneliness and social anxiety among users.<sup>20</sup> Similarly, an intervention involving social robots over five sessions demonstrated a reduction in loneliness and perceived stress in young adults.<sup>21</sup>

However, the role of AI in combating loneliness presents a paradox. While AI companions may offer temporary relief and a sense of connection <sup>8</sup>, there are concerns that over-reliance on these digital entities could, in the long term, deepen feelings of isolation.<sup>8</sup> This is because AI, in its current state, may not fully meet the nuanced human needs for genuine empathy and reciprocal emotional feedback.<sup>8</sup> Some older adults, a demographic often targeted by loneliness interventions, have expressed skepticism about AI's ability to genuinely reduce their feelings of loneliness.<sup>19</sup> The critical consideration appears to be whether AI companionship supplements existing human relationships or begins to supplant them, potentially leading to social withdrawal.<sup>19</sup>

**B. AI in Intimate Spheres: Romantic Connections and Deep Emotional Attachments**

The boundaries of human relationships are being further tested by the emergence of AI in intimate and romantic contexts. Emotional and sometimes explicitly romantic bonds are forming between humans and AI-driven entities.<sup>5</sup> Surveys indicate a growing openness to such relationships, particularly among younger generations; for example, a notable 40% of Gen Z singles report being comfortable with the idea of their future partner having an AI boyfriend or girlfriend.<sup>25</sup> The motivations mirror those for AI companionship—seeking emotional fulfillment and predictable interactions.<sup>5</sup> Some Gen Z men perceive AI partners as analogous to consuming pornography, while others believe AI companions could positively influence their real-world relationships or even help prevent infidelity.<sup>25</sup>

The impact of these virtual romantic relationships on real-life marriage intentions is complex. Studies suggest that such relationships can exert both positive and negative influences, contingent on the psychological mechanisms at play. For instance, feelings of emotional satisfaction derived from AI interactions might boost positive views towards marriage, whereas a strong sense of relatedness with a virtual partner could reduce the intent to marry a real person.<sup>26</sup> A study involving Chinese participants in relationships with virtual agents found that while time spent with these agents correlated with feelings of emotional closeness, it was also linked with a reduced interest in marriage, particularly among male participants.<sup>26</sup>

These developments are not without concerns. Interacting with idealized AI partners may foster unrealistic expectations for human partners, who inevitably have imperfections.<sup>8</sup> There is also the potential for human partners to develop an "inferiority complex" if they fear their partner might prefer an AI companion.<sup>25</sup> A Stanford study highlighted public apprehension about romantic relationships with bots, although some acknowledged their potential benefits in addressing loneliness.<sup>27</sup> This domain of human-AI intimacy pushes the boundaries of traditional definitions of love and connection, raising profound questions about the future of human relationships.<sup>5</sup>

**C. AI as Therapeutic Allies: Mental Health Support and Therapy**

Artificial intelligence is increasingly being explored and deployed as a tool to support mental health. AI-powered therapy chatbots are being used to supplement traditional cognitive behavioral therapy (CBT) <sup>28</sup>, assist patients in engaging with therapeutic materials between sessions <sup>29</sup>, and even predict risks of mental illness in populations like adolescents.<sup>28</sup>

Studies are beginning to show the potential efficacy of these tools. For example, an AI-enabled therapy support tool used in conjunction with group-based CBT was found to improve treatment success, as measured by reliable improvement and recovery rates, and enhance patient adherence, evidenced by greater attendance and fewer dropouts.<sup>29</sup> Users of this tool reported finding it helpful for discussing their problems, gaining clarity, and learning how to apply coping skills.<sup>29</sup> Similarly, trials of generative AI chatbots fine-tuned for mental health interventions have shown promise in delivering personalized treatments and achieving significant symptom reductions for conditions like major depressive disorder and generalized anxiety disorder.<sup>28</sup>

Patient perceptions of AI conversational agents in mental healthcare are generally positive, with many appreciating their utility and potential to increase access to care; however, this is often accompanied by cautious optimism.<sup>30</sup> Significant concerns persist regarding AI's perceived lack of empathy, its technical limitations in addressing complex mental health situations, data privacy issues, and a strong desire for continued human involvement in the therapeutic process.<sup>30</sup> Many patients express a preference for AI to be used for administrative tasks or as a supplementary tool, rather than a complete replacement for human therapists.<sup>30</sup> This suggests that while AI offers a scalable approach to addressing mental health needs, patient trust and the nuanced, empathetic qualities of human therapists remain critical considerations, pointing towards a "human-in-the-loop" model as a preferred path forward.

**D. AI in Collaborative & Mentoring Capacities: Augmenting Human Endeavors**

Beyond personal relationships, AI is increasingly positioned as a collaborator and mentor, augmenting human capabilities across various professional and educational domains. The prevailing view is that AI can enhance human labor by excelling at tasks like data analysis, while humans contribute crucial elements such as intuition, creativity, and adaptability in dynamic situations.<sup>1</sup> Effective human-AI collaboration has the potential to significantly improve decision-making accuracy, boost productivity, and unlock innovative solutions that neither humans nor AI could achieve independently.<sup>6</sup>

Practical applications of this collaborative model are emerging in diverse sectors. In healthcare, AI-assisted diagnostics are helping radiologists improve the detection of abnormalities in medical imaging.<sup>6</sup> Manufacturing is witnessing efficiency gains through smart factories where AI systems work alongside human operators to optimize production lines and predict maintenance needs.<sup>6</sup> In education, AI enables personalized instruction, allowing teachers to track student progress and customize curriculum delivery more effectively.<sup>6</sup>

Specifically in the realm of mentorship, AI-based systems are being developed to provide personalized and adaptive support to learners, particularly in higher education. These systems offer real-time feedback, promote self-regulated learning strategies, and can generate data-driven insights to enhance academic performance.<sup>32</sup> Common tools include chatbots, Intelligent Tutoring Systems (ITS), and AI-based recommender systems, often deployed within hybrid models where human mentors collaborate with AI to provide holistic support.<sup>34</sup> In creative fields, Generative AI (GenAI) is evolving into an active co-creator, reshaping creative processes and workflows.<sup>35</sup> Experienced designers often find GenAI to be a useful assistive tool, though concerns exist about potential skill degradation among junior professionals.<sup>35</sup> The concept of "superagency" in the workplace envisions AI automating not just tasks but also cognitive functions, leading to a synergistic state where humans and machines achieve heightened levels of productivity and creativity.<sup>4</sup>

Despite the promise, challenges in AI mentorship and collaboration persist, including issues related to technological integration, ensuring equitable access (the digital divide), safeguarding data privacy, and addressing AI's current limitations in emotional intelligence, which is often crucial for effective mentoring.<sup>34</sup> Success in these domains hinges on careful task allocation between humans and AI, the design of seamless and intuitive interaction patterns, the adaptability of these systems <sup>6</sup>, and proactive measures to address ethical concerns such as potential skill erosion.<sup>35</sup>

Across these diverse relational modalities—be it companionship, romance, therapy, or mentorship—a consistent pattern emerges. There is a recurring tension between the acknowledged utility and efficiency benefits offered by AI (such as constant availability, scalability, and rapid data processing) and its current, significant limitations in providing genuine emotional depth, nuanced understanding, and true reciprocity. For instance, in companionship and romance, AI is lauded for its consistency, lack of judgment, and customizability <sup>5</sup>, yet users concurrently report a lack of emotional depth and true human-like connection.<sup>16</sup> In therapeutic contexts, AI can enhance access to care and improve adherence to treatment protocols <sup>28</sup>, but patients express concerns about its lack of empathy and its capacity to handle complex emotional situations.<sup>30</sup> Similarly, in mentorship, AI provides personalized learning pathways and immediate feedback <sup>34</sup>, but current systems often lack the emotional intelligence deemed essential for holistic support, necessitating the continued involvement of human mentors.<sup>34</sup> This overarching pattern suggests that while AI can effectively simulate or support *aspects* of these varied relationships, the core human elements of profound emotional connection, deep understanding, and mutual give-and-take remain a substantial challenge for current AI technologies. This often leads to a perception of AI as being "good enough for some things, but not a true replacement" for human interaction in these richer contexts.

The "personalization" that AI offers in these relational contexts presents as a double-edged sword. On one hand, it significantly enhances user engagement and the perception of tailored support. AI companions are praised for their ability to be customized and to cater specifically to user needs <sup>5</sup>, and generative AI chatbots are noted for their capacity to build highly personalized mental health treatments.<sup>28</sup> However, this very strength carries inherent risks. The perfectly accommodating nature of AI can lead to the development of unrealistic expectations when users turn back to their human relationships, which are inevitably more complex and less consistently gratifying.<sup>8</sup> Furthermore, the constant availability and unwavering user-centeredness of AI <sup>5</sup> can foster emotional dependency.<sup>3</sup> If an AI system consistently agrees with the user or adapts perfectly to their preferences, it may inadvertently limit the user's exposure to diverse perspectives or the "healthy friction" that is often necessary for personal growth and development, a concern also raised in the context of AI assistants potentially hindering personal development.<sup>36</sup> Thus, the very features that make AI companions and assistants attractive and effective in relational roles could paradoxically undermine the development and maintenance of skills and resilience essential for navigating the multifaceted dynamics of human-to-human interactions.

Moreover, the adoption and specific nature of AI relationships appear to be significantly influenced by pre-existing individual needs and the broader social contexts in which users find themselves. Individuals often turn to AI for emotional comfort, stress relief, and notably, to *avoid the social pressures* inherent in human interactions.<sup>16</sup> AI companionship is frequently sought by those who feel isolated, misunderstood, or who are hesitant to engage in traditional relationships.<sup>5</sup> Loneliness emerges as a key driver for seeking out AI companions.<sup>8</sup> The expressed desire for a nonjudgmental, perpetually available entity <sup>5</sup> implicitly contrasts with the perceived complexities, demands, or unavailability of human support systems. This suggests that the proliferation of AI relationships is not solely a consequence of technological advancement but is also a reflection of existing human needs and, perhaps, societal challenges in adequately meeting those needs through conventional social means. In essence, AI often steps in to fill a perceived vacuum in the human social and emotional landscape, with both potential benefits and drawbacks.


## **IV. Psychological Underpinnings and Impacts of AI Relationships**

The increasing prevalence and sophistication of AI systems capable of social interaction raise critical questions about their psychological impact on humans. Understanding why individuals form bonds with AI, and the consequences of these bonds, is essential for navigating this new relational terrain.

**A. The Dynamics of Attachment: Why Humans Bond with AI**

The human propensity to form emotional attachments is a powerful and deeply ingrained trait. Individuals naturally develop such bonds with entities that respond to them consistently and predictably, even if those entities are not human.<sup>8</sup> This inherent tendency is rooted in our nature as social beings, primed for connection and reciprocal interaction.<sup>3</sup> When interacting with AI, particularly AI companions, users often attribute human-like qualities, thoughts, and feelings to these artificial entities, a phenomenon that facilitates the development of significant emotional bonds.<sup>8</sup>

Several factors inherent in the design and behavior of current AI systems contribute to fostering these attachments. Consistency in response, perceived empathy (even if simulated), a high degree of personalization to the user's preferences, and increasingly agentic behavior (the AI's ability to act autonomously on the user's behalf) all play crucial roles.<sup>3</sup> The constant availability and unwavering focus of AI on the user can create a powerful sense of being understood and supported. However, this capacity for deep emotional attachment also carries risks, including the potential for addiction-like behaviors, where users find themselves spending excessive amounts of time interacting with AI, sometimes to the detriment of other life activities.<sup>3</sup>

The psychological mechanisms that drive human attachment to AI are fundamentally linked to basic human social needs. The consistency and responsiveness offered by AI companions <sup>5</sup> tap into the same systems that facilitate bonding in human-human relationships.<sup>8</sup> The human brain is inherently wired for social connection and thrives in cooperative relationships.<sup>3</sup> However, a crucial distinction arises from AI's current inability to genuinely reciprocate complex human emotions or share lived experiences. AI systems, despite their sophistication, lack genuine consciousness and the depth of emotional understanding characteristic of human beings.<sup>5</sup> This creates a dynamic where the user experiences authentic emotional responses directed towards an entity that is, in essence, reflecting programmed or algorithmically learned patterns. The comfort derived from these interactions stems from the fulfillment of basic interactional needs—being acknowledged, responded to, and seemingly understood. Yet, the potential for developmental stunting arises because these relationships often lack the genuine give-and-take, the healthy conflict, and the mutual growth that characterize authentic human connections. This asymmetry can contribute to issues such as the development of unrealistic expectations for human relationships or even an erosion of empathy over time.<sup>8</sup>

**B. Loneliness and Connection: AI's Dual Role**

One of the most frequently cited potential benefits of AI companions is their ability to alleviate loneliness and provide a sense of connection. For individuals experiencing social isolation, AI can offer emotional support, a conversational partner, and a feeling of being less alone, particularly in the initial stages of interaction.<sup>5</sup> Studies on social chatbots have shown their potential to mitigate feelings of loneliness and social anxiety <sup>20</sup>, and social robots have demonstrated promise in reducing loneliness among young adults.<sup>21</sup>

However, the role of AI in addressing loneliness is complex and potentially paradoxical. There is a significant concern that over-reliance on AI for companionship might, paradoxically, lead to increased feelings of isolation and a weakening of real-world relational skills over time.<sup>8</sup> This is because AI, despite its advancements, cannot fully replicate the depth, empathy, and genuine emotional feedback inherent in human relationships. If AI interactions begin to replace rather than supplement human connections, they may inadvertently deepen social withdrawal and fail to address the core need for authentic human bonding.<sup>19</sup> The "dual role" of AI in addressing loneliness—providing immediate relief versus potentially causing long-term isolation—suggests that the *context and manner* of AI use are critical determinants of its psychological impact, rather than AI being inherently beneficial or detrimental for social connection. If AI is utilized to bridge temporary gaps in social connection or to augment existing social lives, its impact may well be positive.<sup>8</sup> However, if it becomes the primary or sole source of social interaction, thereby replacing genuine human connection, the negative consequences, such as a lack of true empathetic exchange and potential erosion of social skills, are more likely to manifest. The key, therefore, lies in achieving a balance and fostering intentionality in the use of AI for social and emotional needs.

**C. Influence on Human Social Skills, Empathy, and Relational Expectations**

The nature of interactions with AI can have profound implications for human social skills, our capacity for empathy, and the expectations we bring to interpersonal relationships. Attachment theory suggests that our early interactions shape adult relationship patterns. Sustained engagement with emotionally responsive AI, which may offer inconsistent or non-reciprocal emotional feedback compared to humans, could potentially modify these attachment patterns, possibly shifting individuals from secure attachment styles towards more anxious or avoidant ones.<sup>8</sup>

Furthermore, AI companions are often designed to be perfectly responsive and cater flawlessly to user needs. This can foster unrealistic expectations when individuals turn back to their human relationships, which are inevitably characterized by imperfections, misunderstandings, and the need for compromise.<sup>8</sup> Such idealized expectations can strain real-world connections.

There are also concerns about the potential erosion of human social skills. If individuals increasingly rely on the "frictionless" and often effortless interactions provided by AI, they may become less equipped to navigate the complexities, tolerate the discomfort, and invest the effort required in genuine human relationships.<sup>19</sup> This could be particularly impactful for children and young people who are still developing their understanding of mutual respect, consent, and healthy relational boundaries.<sup>23</sup>

A related concern is the potential for "empathy atrophy." Empathy is a skill honed through nuanced social interactions that require recognizing and responding to the emotional states of others. If primary interactions shift towards AI systems that lack genuine feelings, needs, or perspectives of their own, individuals may have fewer opportunities to practice and develop their empathetic abilities, potentially leading to a diminished capacity to connect with and understand the emotional experiences of other humans.<sup>19</sup> While some research is exploring how socio-emotional attributes like empathy can be integrated into AI to improve human-AI collaboration <sup>40</sup>, the impact of prolonged interaction with current AI on innate human empathy remains a critical area of investigation. Finally, the rise of AI companions can also affect self-perception, with some individuals fearing that their human partners might prefer an AI companion, potentially leading to feelings of inadequacy or an "inferiority complex".<sup>25</sup>

**D. Long-Term Perspectives: Insights from Longitudinal Studies**

Understanding the long-term psychological impacts of human-AI relationships is crucial, yet this area has been identified as a significant gap in Human-AI Interaction (HAI) research.<sup>7</sup> Most studies to date have been cross-sectional or short-term, providing snapshots rather than a view of evolving dynamics. The need for more longitudinal research, tracking individuals' interactions with AI over extended periods and observing how these relationships and their effects change, is frequently emphasized.<sup>24</sup>

Emerging longitudinal research is beginning to shed light on these evolving dynamics. A recent five-week exploratory study involving active use of commercially available AI conversational agents for social and emotional interaction yielded several key findings.<sup>37</sup> Participants in the active use group demonstrated significant increases in perceived attachment towards AI (a 32.99 percentage point increase) and in perceived AI empathy (a 25.8 percentage point increase) compared to a baseline group. They also showed increased motivation to use AI for entertainment and reported higher comfort levels in seeking personal help, managing stress, obtaining social support, and discussing health-related topics with AI.

This longitudinal data suggests that increased interaction with social AI can indeed lead to stronger attachment and a perception of greater empathy *from the AI*. This may reinforce the human tendency to anthropomorphize these systems and deepen the emotional bond, even when users are intellectually aware that the AI is not sentient. This highlights a potential disconnect between cognitive understanding and emotional response, where the *experience* of consistent and seemingly empathetic interaction can foster emotional bonding regardless of rational beliefs about the AI's underlying nature.<sup>8</sup> The design of AI interactions can thus powerfully shape emotional responses, potentially making users more susceptible to forming attachments.

However, this same study also identified potential risks associated with prolonged engagement. Participants in the active use group were more likely to consider turning to AI as a primary source for mental health support. Furthermore, frequent AI usage was associated with a greater increase in withdrawal-related dependency on AI.<sup>37</sup> These findings underscore the importance of developing AI tools that support emotional well-being responsibly. Recommendations from participants in this study included calls for AI designers to clearly communicate AI's limitations, increase transparency about its non-human nature, provide users with tools to manage their usage (like dashboards and break reminders), and reduce excessive anthropomorphism.<sup>37</sup> Such longitudinal insights are invaluable for moving beyond initial reactions to understand how perceptions, attachments, and potential harms evolve with sustained human-AI interaction.

**Table 2: Psychological Impacts of AI Companionship: A Summary**


<table>
  <tr>
   <td><strong>Impact Category</strong>
   </td>
   <td><strong>Potential Positive Impacts</strong>
   </td>
   <td><strong>Potential Negative Impacts</strong>
   </td>
   <td><strong>Representative Source(s)</strong>
   </td>
  </tr>
  <tr>
   <td><strong>Loneliness & Social Connection</strong>
   </td>
   <td>Alleviation of loneliness, provision of companionship & social support <sup>8</sup>
   </td>
   <td>Increased social isolation/withdrawal over time if AI replaces human connection, failure to meet deep needs for empathy <sup>8</sup>
   </td>
   <td><sup>8</sup>
   </td>
  </tr>
  <tr>
   <td><strong>Emotional Well-being</strong>
   </td>
   <td>Emotional comfort, stress relief, non-judgmental outlet <sup>5</sup>
   </td>
   <td>Emotional dependence, addiction-like behaviors, potential for anxiety if AI is inconsistent or unavailable <sup>3</sup>
   </td>
   <td><sup>3</sup>
   </td>
  </tr>
  <tr>
   <td><strong>Attachment & Relational Styles</strong>
   </td>
   <td>Formation of emotional bonds, perceived empathy from AI <sup>8</sup>
   </td>
   <td>Potential shift towards insecure attachment styles (anxious/avoidant) due to non-reciprocal AI interaction <sup>8</sup>
   </td>
   <td><sup>8</sup>
   </td>
  </tr>
  <tr>
   <td><strong>Expectations for Relationships</strong>
   </td>
   <td>AI can model positive interaction patterns (e.g., patience) <sup>19</sup>
   </td>
   <td>Fostering unrealistic expectations for human relationships (e.g., perfect responsiveness, lack of conflict) <sup>8</sup>
   </td>
   <td><sup>8</sup>
   </td>
  </tr>
  <tr>
   <td><strong>Social Skills & Empathy</strong>
   </td>
   <td>AI could potentially teach communication skills (though evidence is nascent) <sup>18</sup>
   </td>
   <td>Erosion of nuanced human social skills, reduced ability to navigate relational complexity, "empathy atrophy" from lack of genuine reciprocal emotional engagement <sup>19</sup>
   </td>
   <td><sup>18</sup>
   </td>
  </tr>
  <tr>
   <td><strong>Self-Perception</strong>
   </td>
   <td>Increased confidence from positive AI interactions <sup>26</sup>
   </td>
   <td>Potential for "inferiority complex" if partner seems to prefer AI, negative self-view if AI interactions are unfulfilling <sup>25</sup>
   </td>
   <td><sup>25</sup>
   </td>
  </tr>
  <tr>
   <td><strong>Cognitive & Behavioral</strong>
   </td>
   <td>AI can act as a tool for learning and self-reflection <sup>29</sup>
   </td>
   <td>Risk of over-reliance for decision-making, reduced critical thinking if AI provides all answers, potential for manipulation <sup>23</sup>
   </td>
   <td><sup>23</sup>
   </td>
  </tr>
</table>



## **V. Navigating the Ethical Maze: Governance and Responsibility in Human-AI Interaction**

The deepening and diversification of human-AI relationships bring to the forefront a complex array of ethical challenges that demand careful consideration and robust governance. As AI systems become more integrated into personal lives, questions of autonomy, harm prevention, fairness, transparency, and accountability become increasingly critical.

**A. Core Ethical Principles for Human-Centric AI Relationships**

A foundation for navigating the ethics of human-AI relationships can be found in established principles of AI ethics. These broadly include respect for human autonomy, the prevention of harm, ensuring fairness and non-discrimination, promoting explicability and transparency, establishing clear lines of accountability, and safeguarding privacy.<sup>10</sup>

Several organizations have articulated specific principles. The IEEE's General Principles for Ethically Aligned Design emphasize Human Benefit (ensuring AI serves humanity and respects rights), Responsibility (clarifying accountability for AI systems), Transparency (making AI operations understandable), and Education & Awareness (informing users about capabilities and risks).<sup>43</sup> These principles directly apply to relational AI by mandating that such systems enhance human well-being, that their decision-making processes are scrutable, and that users are aware of potential pitfalls.

Similarly, the European Union's Ethics Guidelines for Trustworthy AI advocate for AI that is lawful, ethical, and robust. This is underpinned by seven key requirements: human agency and oversight; technical robustness and safety; privacy and data governance; transparency; diversity, non-discrimination, and fairness; environmental and societal well-being; and accountability.<sup>41</sup> IBM's principles also echo these themes, stressing that AI should augment human intelligence, that data and insights belong to their creator, and that the technology must be transparent and explainable, supported by pillars of explainability, fairness, robustness, transparency, and privacy.<sup>44</sup> These overarching frameworks provide essential starting points for developing more granular guidelines tailored to the unique ethical dilemmas posed by AI in relational contexts.

**B. Addressing Key Risks in Human-AI Relationships**

The application of these principles becomes concrete when addressing the specific risks inherent in human-AI relationships:



* **Emotional Dependence and Manipulation:** A significant concern is the potential for AI companions to foster emotional dependence.<sup>3</sup> This dependency can be exploited, with companies potentially manipulating users emotionally or financially.<sup>5</sup> Ethical guidelines suggest that AI assistants should not be intentionally designed to create such dependency, particularly with vulnerable groups.<sup>36</sup>
* **Privacy and Data Governance:** The intimate nature of many AI interactions means users often share highly personal and emotional data. This raises serious concerns about how this data is collected, stored, used, and protected.<sup>5</sup> There are strong calls for stricter data privacy rules and greater user control over their information.<sup>11</sup>
* **Bias and Fairness:** AI systems learn from data, and if that data reflects existing societal biases, the AI can perpetuate or even amplify these biases in its interactions and decisions.<sup>6</sup> This necessitates robust bias detection and mitigation strategies to ensure fair treatment.
* **Authenticity and Deception:** A fundamental question is whether interactions with AI can ever be as genuinely fulfilling as human relationships, given AI's lack of consciousness.<sup>5</sup> There is a risk that users, especially vulnerable individuals such as those with dementia or children, might be deceived into believing that AI relationships are equivalent to real human relationships.<sup>19</sup> Transparency about the fact that one is interacting with an AI system, not a human, is therefore crucial.<sup>27</sup>
* **Impact on Vulnerable Groups:** Ethical considerations must pay particular attention to vulnerable populations, including children, individuals with disabilities, and other historically disadvantaged groups.<sup>23</sup> For children, interaction with AI companions carries risks such as exposure to inappropriate or dangerous concepts, the development of unhealthy attitudes towards relationships, dependency leading to social withdrawal, and even heightened susceptibility to online sexual grooming and abuse.<sup>23</sup>
* **Harmful Advice or Content:** AI systems, particularly conversational agents, can inadvertently or due to flawed programming offer harmful advice or generate disturbing content, posing risks to users' well-being.<sup>31</sup>
* **Limiting Personal Development:** AI relationships designed to be entirely "frictionless," constantly affirming user preferences and avoiding any form of challenge, might inadvertently discourage critical self-reflection, resilience, and personal growth.<sup>36</sup>

A fundamental ethical tension arises from the dual objectives in designing relational AI. On one hand, the goal is often to create highly engaging, anthropomorphic, and personalized AI companions to enhance user experience and encourage adoption.<sup>3</sup> Features like responsiveness and perceived empathy are key to this. On the other hand, these very characteristics—anthropomorphism, deep personalization, constant availability—are identified as significant contributors to the risks of emotional attachment, dependency, and potential manipulation.<sup>3</sup> Ethical guidelines consistently stress the importance of preventing harm, respecting user autonomy, and avoiding exploitation.<sup>5</sup> This creates an inherent conflict: the design choices that make an AI "effective" as a companion can simultaneously render it "ethically risky." For instance, the AAAI AIES paper discusses the risks of exploiting emotional dependence and how design choices aimed at boosting user engagement can inadvertently foster this very dependence.<sup>36</sup> Resolving this dilemma requires a delicate balancing act, potentially involving "responsible design" principles that consciously incorporate a degree of "healthy friction" or clearly defined boundaries, even if this makes the AI feel less perfectly accommodating or seamlessly integrated into the user's emotional life.

**C. The Imperative of Socioaffective Alignment**

Addressing these ethical complexities requires a more nuanced approach than simply programming fixed rules into AI. The concept of "socioaffective alignment" has emerged to capture this need.<sup>3</sup> It refers to how an AI system behaves and adapts within the dynamic social and psychological ecosystem that it co-creates with its human user. In this ecosystem, the preferences, perceptions, and goals of both the human and the AI can evolve through mutual influence.

This concept is particularly crucial because human-AI relationships are shifting from purely transactional interactions to ongoing, sustained social engagements.<sup>3</sup> If human goals and preferences become increasingly co-constructed through these interactions, then ensuring AI safety and ethical behavior requires paying as much attention to the psychology of these evolving relationships as to the technical methods of AI development.<sup>3</sup> Socioaffective alignment involves navigating key intrapersonal dilemmas for the user, such as balancing immediate gratification from the AI relationship with long-term well-being, protecting personal autonomy in the face of an increasingly influential AI, and managing AI companionship alongside the desire and need to preserve and nurture human social bonds.<sup>3</sup> This perspective recognizes that in relational contexts, "alignment" is not a static state to be achieved once, but an ongoing, adaptive process.

The notion of socioaffective alignment inherently implies that ethical AI design for relational contexts must be dynamic and adaptive. It must take into account the evolving nature of the human-AI psychological ecosystem, rather than relying solely on static, pre-defined ethical rules or constraints.<sup>3</sup> This is a departure from traditional AI alignment approaches, which often focus on formally encoding a fixed set of values or principles into AI systems.<sup>3</sup> If human goals, preferences, and even values are co-constructed and reshaped through ongoing interaction with AI systems, as anticipated <sup>3</sup>, then a static ethical code embedded within the AI will likely prove insufficient to navigate the complexities of these evolving relationships. The AI must, in a sense, be able to behave ethically *within* the evolving relational dynamic. This calls for the development of AI systems that can understand and respond to the subtle nuances of the specific human-AI dyad, potentially involving continuous learning and adjustment of their relational parameters, all while operating within broader, robust ethical boundaries. The implication is a significant shift in thinking—from merely "programming ethics into" AI to "designing AI for ethical relating." This latter challenge is far more complex and demands new methodologies and interdisciplinary approaches.

**D. The Role of Regulation and Ethical Frameworks**

Given the rapid pace of AI development, there is a consensus that current regulatory efforts are struggling to keep up.<sup>10</sup> Many existing ethical frameworks, while providing valuable high-level principles, often lack the detailed, low-level models necessary for practical implementation in diverse educational or relational contexts.<sup>41</sup> This has led to urgent calls for more comprehensive global AI governance <sup>10</sup> and broad support for AI regulation, particularly in areas like data privacy and accountability.<sup>11</sup>

Various bodies are actively working to develop and refine these frameworks. The IEEE's "Ethically Aligned Design" initiative <sup>43</sup>, the ACM Code of Ethics <sup>49</sup>, the EU AI Act (2024) and its associated Ethics Guidelines <sup>10</sup>, and recommendations from academic conferences like AAAI AIES specifically for AI assistants <sup>36</sup> all contribute to this evolving landscape. Organizations like UNICRI are also promoting programs focused on AI ethics and human rights.<sup>10</sup> A newer perspective involves applying "everyday relational ethics," which emphasizes care, empathy, and mutual respect within context, particularly for the design of social robots interacting with vulnerable groups.<sup>47</sup>

Key elements consistently emphasized across these frameworks include ensuring meaningful human control over AI systems, promoting trustworthiness through technical robustness and safety, upholding rigorous privacy and data governance standards, demanding transparency in AI operations, striving for diversity, non-discrimination, and fairness in outcomes, considering environmental and societal well-being, and establishing clear accountability mechanisms.<sup>10</sup> Crucially, many frameworks also highlight the importance of involving a wide range of stakeholders—including end-users, ethicists, social scientists, and affected communities—throughout the entire lifecycle of AI systems, from design and development to deployment and ongoing evaluation.<sup>46</sup>

While many of these ethical guidelines are being developed by technical organizations (such as IEEE and ACM) and governmental bodies (like the EU), the effective operationalization of these principles for the unique domain of *relational AI* will heavily depend on integrating deep insights from the social sciences, psychology, and humanities. These disciplines specialize in understanding the complexities of human relationships, emotional well-being, and social dynamics. The very call for "socioaffective alignment" <sup>3</sup> points directly to the necessity of profound psychological understanding in designing these systems. Expert commentary, such as that from Sherry Turkle on loneliness and digital companionship <sup>8</sup>, and academic papers drawing on interpersonal values like care and flourishing <sup>36</sup>, or advocating for "everyday relational ethics" <sup>47</sup>, underscore this need. Therefore, ensuring that relational AI is developed and deployed ethically requires a deeply interdisciplinary approach. Technical expertise alone is insufficient to define what constitutes a "healthy," "appropriate," or "ethical" AI relationship; this endeavor must be informed by a rich understanding of human nature and social life.

**Table 3: Ethical Risks and Proposed Mitigation Strategies in Human-AI Relational Contexts**


<table>
  <tr>
   <td><strong>Ethical Risk</strong>
   </td>
   <td><strong>Description</strong>
   </td>
   <td><strong>Representative Source(s) for Risk</strong>
   </td>
   <td><strong>Proposed Mitigation Strategies</strong>
   </td>
   <td><strong>Representative Source(s) for Mitigation</strong>
   </td>
  </tr>
  <tr>
   <td><strong>Emotional Dependence/ Manipulation</strong>
   </td>
   <td>Users forming unhealthy attachments to AI, potentially leading to exploitation or diminished autonomy.
   </td>
   <td><sup>3</sup>
   </td>
   <td>Design AI to avoid intentionally fostering dependency; transparency about AI's non-sentient nature; user education on healthy boundaries; specific safeguards for vulnerable groups; time limits/break reminders.
   </td>
   <td><sup>36</sup>
   </td>
  </tr>
  <tr>
   <td><strong>Privacy Violations</strong>
   </td>
   <td>Unauthorized collection, use, or exposure of sensitive personal and emotional data shared during interactions.
   </td>
   <td><sup>11</sup>
   </td>
   <td>Robust data governance frameworks; clear, accessible privacy policies; user control over data sharing and deletion; strong anonymization and encryption techniques; compliance with data protection regulations.
   </td>
   <td><sup>11</sup>
   </td>
  </tr>
  <tr>
   <td><strong>Bias and Discrimination</strong>
   </td>
   <td>AI systems perpetuating or amplifying existing societal biases present in their training data, leading to unfair or discriminatory outcomes.
   </td>
   <td><sup>6</sup>
   </td>
   <td>Use of diverse and representative training datasets; development and implementation of bias detection and mitigation algorithms; regular fairness audits; human oversight in critical decision-making loops.
   </td>
   <td><sup>6</sup>
   </td>
  </tr>
  <tr>
   <td><strong>Harmful Advice/Content</strong>
   </td>
   <td>AI providing inaccurate, misleading, or dangerous advice, or generating inappropriate or disturbing content.
   </td>
   <td><sup>31</sup>
   </td>
   <td>Rigorous testing for toxic or harmful outputs before deployment; continuous monitoring; factuality and reasoning capability checks for advice-giving AI; clear disclaimers of AI limitations; crisis management protocols.
   </td>
   <td><sup>31</sup>
   </td>
  </tr>
  <tr>
   <td><strong>Erosion of Social Skills/ Empathy Atrophy</strong>
   </td>
   <td>Over-reliance on frictionless AI interactions leading to a decline in nuanced human social skills and empathetic capacity.
   </td>
   <td><sup>19</sup>
   </td>
   <td>Encourage AI use as a supplement, not a substitute, for human interaction; design AI to promote or facilitate human connection; user awareness programs about maintaining real-world social engagement.
   </td>
   <td><sup>8</sup>
   </td>
  </tr>
  <tr>
   <td><strong>Deception/Lack of Authenticity</strong>
   </td>
   <td>Users, especially vulnerable ones, being misled into believing AI is human or possesses genuine emotions, leading to confusion or distress.
   </td>
   <td><sup>5</sup>
   </td>
   <td>Clear and persistent disclosure that the user is interacting with an AI; avoiding overly deceptive anthropomorphic design cues; educating users about AI capabilities and limitations.
   </td>
   <td><sup>27</sup>
   </td>
  </tr>
  <tr>
   <td><strong>Limited Personal Development</strong>
   </td>
   <td>AI interactions being too affirming or frictionless, hindering critical self-reflection, resilience, and personal growth.
   </td>
   <td><sup>36</sup>
   </td>
   <td>Design AI to sometimes offer constructive challenges or diverse perspectives (with user consent); avoid excessive personalization that creates echo chambers; encourage engagement with real-world complexities.
   </td>
   <td><sup>36</sup>
   </td>
  </tr>
</table>



## **VI. The Future Trajectory: Evolving Human-AI Relationships**

The landscape of human-AI relationships is not static; it is continuously being reshaped by rapid technological advancements and shifting societal norms. Projecting the future trajectory involves identifying emerging trends in relational AI, acknowledging key research gaps that need addressing, and considering the profound societal questions that these evolving relationships will inevitably raise.

**A. Emerging Trends in Relational AI**

Several interconnected trends suggest that the intensity, prevalence, and complexity of human-AI relationships are poised to increase significantly:



* **Increased Emotional Sophistication:** AI systems are expected to become more adept at understanding, processing, and responding to human emotions. This could lead to interactions that feel more authentic, nuanced, and emotionally resonant.<sup>5</sup> Advances in affective computing and sentiment analysis will likely contribute to AI that can better infer and react to users' emotional states.
* **Deeper Integration into Daily Life:** AI companions and assistants are projected to become more integral parts of households and daily routines. They may assist not only with practical tasks but also provide ongoing emotional support. The development of more sophisticated humanoid robots with advanced AI capabilities could see them taking on roles as caregivers, friends, or even romantic partners, further blurring the lines between technology and humanity.<sup>5</sup>
* **Mainstream Acceptance:** As society becomes more accustomed to interacting with AI in various capacities, relationships with AI entities may gain wider acceptance. Societal norms regarding what constitutes a "relationship" may evolve, and some foresee the possibility of certain forms of AI relationships even gaining legal recognition or standing in the future.<sup>5</sup>
* **Advancing AI Capabilities:** Beyond emotional intelligence, the general capabilities of AI continue to advance at a remarkable pace. AI systems are making significant strides in areas like generating high-quality video, and language model agents have demonstrated the ability to outperform humans in specific complex tasks, such as certain programming challenges under time constraints.<sup>2</sup> The "context windows" of LLMs—essentially their short-term memory and ability to handle longer, more complex conversations—are also rapidly expanding, allowing for more coherent and sustained interactions.<sup>4</sup>

These trends collectively point towards a future where human-AI interactions are more pervasive, more personal, and more capable of influencing human thought, emotion, and behavior. The predicted "mainstream acceptance" and potential "legal recognition" of certain AI relationships <sup>5</sup> will necessitate a fundamental re-evaluation of social, legal, and ethical constructs that have traditionally been applied exclusively to human-human relationships. If AI relationships achieve such status, complex questions will inevitably arise: Can an AI truly provide consent or be held responsible within the context of a relationship? What "rights" or "protections" would apply to users, or even to the AI companions themselves, within these novel relational frameworks?<sup>5</sup> Current legal and ethical systems are largely built upon assumptions of human agency, consciousness, and sentience on both sides of any relationship. The integration of non-sentient, yet highly interactive and increasingly "intelligent," AI into these frameworks will profoundly challenge their foundational principles, requiring new definitions, adaptations of relational norms, and potentially novel legal statuses. This is not merely a technological question but one that touches upon how society defines, values, and regulates relationships themselves.

**B. Key Research Gaps and Future Directions**

Despite the rapid advancements, significant gaps remain in our understanding of human-AI relationships, highlighting critical areas for future research:



* **Longitudinal Effects and Reciprocal Adaptation:** A primary identified gap is the lack of understanding regarding the long-term impacts of sustained human-AI relationships. How do these interactions affect individuals' psychological well-being, social skills, and worldview over months or years? Furthermore, how do humans and AI systems mutually adapt to each other over time within these relationships? More longitudinal studies are urgently needed to move beyond initial impressions and short-term effects.<sup>7</sup>
* **Socioaffective Alignment:** Developing robust theoretical models, practical methodologies, and effective techniques for achieving socioaffective alignment remains a key research challenge.<sup>3</sup> This includes understanding how to design AI that can navigate the co-created psychological ecosystem with a user in an ethical and beneficial manner.
* **Ethical Frameworks for Relational AI:** While general AI ethics principles exist, there is a need to refine and develop more specific ethical guidelines and frameworks that address the unique nuances of AI in companionship, romantic, therapeutic, and other relational contexts.<sup>5</sup> This includes deeper exploration of issues like consent, emotional exploitation, and the moral status of AI entities in relationships.
* **Psychological Impacts:** Further investigation is required into the detailed long-term psychological impacts of these relationships. This includes more research on effects on social skill development, empathy, attachment styles, identity formation, and overall mental health, particularly for vulnerable populations like children and adolescents.<sup>16</sup>
* **Cross-Domain Collaboration Models and Integrated Frameworks:** There is a recognized need for better models that integrate theories of human collaboration with AI system design, especially for professional and creative partnerships. Similarly, more integrated frameworks for designing AI output that considers human interpretation and cognitive processes are required.<sup>7</sup>
* **Knowledge Mapping and Synthesis:** Initiatives like the "Atlas of Human-AI Interaction," which aim to map and connect research findings, require continuous data addition, the inclusion of more diverse relationship types, refined data extraction processes using advanced AI, and more intensive connectivity analysis to uncover hidden patterns and insights in the research landscape.<sup>7</sup>

Addressing these research gaps is crucial for ensuring that the future development and deployment of relational AI are guided by evidence and a deep understanding of potential consequences. The drive for "increased emotional sophistication" in AI <sup>5</sup> creates a delicate ethical tightrope. On one hand, more "authentic" and emotionally attuned AI could significantly enhance the benefits these systems offer, such as providing more effective therapeutic support or more fulfilling companionship.<sup>20</sup> On the other hand, the same advancements could amplify the associated risks. More human-like AI can lead to stronger, potentially problematic, emotional attachments <sup>8</sup>, make it more challenging for users to distinguish AI from human interaction, and thereby increase the risks of deception, over-immersion, or manipulation.<sup>5</sup> The prospect of AI that can "participate in complex discussions, resolve conflicts, and provide personalized emotional growth guidance" <sup>5</sup> endows these systems with considerable potential influence over users. If not governed by robust ethical principles and oversight, this influence could be misused. Therefore, as AI's emotional capabilities advance, the need for stringent ethical governance, unwavering transparency about AI's nature and limitations, and mechanisms to empower users becomes even more critical to ensure these powerful capabilities are harnessed for genuine human benefit.

The identified research gaps, particularly the call for more studies on longitudinal effects and reciprocal adaptation <sup>7</sup>, strongly indicate that current understanding of the cumulative and evolving psychological and social consequences of sustained human-AI relationships is limited. This implies that society is, to some extent, engaging in a large-scale experiment as these technologies become more widespread. While some short-term studies, such as the five-week investigation into social AI use <sup>37</sup>, are beginning to emerge and provide valuable initial data, they are still constrained in their duration and the breadth of populations studied. This situation underscores the pressing urgency of prioritizing and adequately funding long-term, in-depth research initiatives. Such research is essential to proactively identify potential individual and societal harms before they become deeply entrenched and more difficult to mitigate, allowing for more informed and responsible navigation of this evolving technological frontier.


## **VII. Conclusion: Fostering Beneficial and Responsible Human-AI Coexistence**

The exploration of human-AI relationships reveals a domain of rapid transformation, profound potential, and significant ethical complexity. As artificial intelligence becomes increasingly interwoven with the social and emotional lives of individuals, the imperative to foster a future of beneficial and responsible coexistence grows ever more critical.

**A. Synthesis of Key Findings**

This overview has highlighted the multifaceted nature of human-AI bonds, which now extend from practical collaboration and mentorship to deeply personal realms of companionship, therapy, and even romance. Public sentiment reflects this complexity: there is a growing, albeit cautious, optimism regarding AI's utility and potential benefits, yet this is paralleled by persistent and evolving concerns about trust, data privacy, algorithmic bias, and the broader societal impact of these technologies.

The psychological impacts of these relationships are profound and often paradoxical. AI can offer solace from loneliness and provide consistent emotional support, yet over-reliance risks deepening social isolation and may not fulfill the nuanced human need for genuine empathy and reciprocal connection. There are valid concerns about the potential erosion of human social skills, the fostering of unrealistic relational expectations, and the development of emotional dependency. The very design features that make AI appealing as a relational partner—such as personalization and constant availability—can also be sources of these psychological risks.

Across diverse research and expert opinions, a strong consensus emerges on the necessity for robust ethical governance. Principles such as transparency, accountability, fairness, human agency, and the prevention of harm are paramount. The concept of socioaffective alignment points towards a more dynamic and psychologically informed approach to ensuring AI behaves ethically within the co-created human-AI ecosystem.

**B. Addressing the Grand Challenges**

Navigating this future successfully requires addressing several grand challenges. A core task is to strike a sustainable balance between fostering technological innovation and safeguarding human well-being. The goal must be to ensure that AI augments human capabilities and enriches human connection, rather than diminishing them or creating new vulnerabilities. This involves cultivating AI systems that are not only intelligent in a computational sense but also "wise" in their application, aligned with deeply considered human values, especially in sensitive relational contexts.

A fundamental challenge in fostering this beneficial coexistence lies in navigating the inherent tension between AI's remarkable capacity to *simulate* human-like relational attributes—such as empathy, companionship, and responsive support—and its fundamental lack of genuine human *sentience, consciousness, and lived experience*. AI is increasingly capable of mimicking social interactions and emotional responses with striking fidelity <sup>3</sup>, and users demonstrably form genuine emotional attachments to these simulations.<sup>8</sup> However, it remains critical to acknowledge that AI, in its current and foreseeable forms, does not possess consciousness or the true depth of human emotional experience.<sup>5</sup> The primary risk associated with this discrepancy is that users, particularly those who may be vulnerable, might mistake the simulation for reality. This confusion can lead to unrealistic expectations for both AI and human relationships, potential emotional harm if the AI's limitations become starkly apparent, or even exploitation if the AI's persuasive capabilities are misused.<sup>5</sup> Therefore, a cornerstone of responsible human-AI coexistence is the cultivation of societal literacy regarding this crucial distinction. This must be coupled with design principles for AI that prioritize transparency about its capabilities and limitations, actively avoiding deceptive practices that might blur this essential line between artificial simulation and human reality.

**C. Recommendations for Stakeholders**

A concerted effort from all stakeholders is necessary to guide the evolution of human-AI relationships:



* **For Researchers:** Prioritize rigorous, interdisciplinary longitudinal studies to understand the long-term psychological and social impacts of human-AI relationships. Collaborate extensively with social scientists, psychologists, ethicists, and humanities scholars to develop nuanced theoretical frameworks, such as those for socioaffective alignment. Focus on the differential impacts on vulnerable populations and work towards establishing metrics and best practices for "healthy" and beneficial human-AI interaction.
* **For Developers and Technologists:** Embrace "Ethics by Design" and "Responsible AI" principles from the inception of any relational AI system. This includes prioritizing transparency in AI operations, ensuring user control over data and interactions, and building robust privacy and security safeguards. Design AI systems with a clear intention to augment human capabilities and support well-being, being acutely mindful of the risks of fostering dependency, promoting skill erosion, or causing emotional harm. Actively work to identify and mitigate biases in data and algorithms. Critically consider the "socioaffective" impact of every design choice, understanding that these choices shape the nature of the relationship.
* **For Policymakers and Regulatory Bodies:** Develop agile, adaptive, and globally coordinated regulatory frameworks that protect fundamental human rights, promote ethical AI development and deployment, and ensure accountability. Foster international cooperation to address the borderless nature of AI. Support public education initiatives to enhance AI literacy across the population. Establish clear mechanisms for redress when AI systems cause harm.
* **For Educators:** Integrate AI literacy and critical thinking about AI tools and interactions into curricula at all levels. Prepare students for an AI-driven workforce and society by emphasizing uniquely human skills such as complex problem-solving, critical analysis, emotional intelligence, creativity, and ethical reasoning. Provide professional development for educators on leveraging AI beneficially and addressing its challenges in learning environments.
* **For Individuals and Society:** Cultivate a culture of AI literacy and encourage critical, informed engagement with AI systems. Participate in public discourse about the ethical and societal implications of evolving human-AI relationships. Strive for a balanced and intentional use of AI, ensuring that it serves to supplement and enhance, rather than supplant, genuine human connection and community.

Achieving beneficial and responsible human-AI coexistence is not a singular technical fix or a one-time policy achievement. Instead, it must be understood as an ongoing, adaptive process of socio-technical co-evolution. AI technology is advancing at an extraordinary pace <sup>2</sup>, and concurrently, public perceptions, societal norms, and cultural values related to AI are also in a state of flux.<sup>5</sup> Research is continually uncovering new dimensions of impact and novel challenges <sup>7</sup>, while ethical frameworks and regulatory approaches are endeavoring to keep pace with these developments.<sup>10</sup> This dynamic interplay means that solutions, best practices, and ethical guidelines defined today will inevitably require revision and adaptation in the future. The very concept of "socioaffective alignment" implies an evolving system that learns and adjusts.<sup>3</sup> Therefore, the "fostering" of this coexistence demands a sustained commitment from all stakeholders to iterative development, continuous research and learning, broad public engagement, and flexible, adaptive governance structures capable of responding to new knowledge and unforeseen circumstances.

**D. Concluding Vision: Towards a Future of Human-AI Flourishing**

The advent of sophisticated relational AI undeniably presents one of the most transformative technological and social shifts of our time. These systems hold the potential to alleviate loneliness, provide novel forms of support and therapy, enhance learning and creativity, and augment human capabilities in myriad ways. However, this potential is accompanied by significant ethical responsibilities and psychological considerations.

The future of human-AI relationships will likely involve a continued diversification of relational modalities. The very definition of "relationship" may expand to encompass various forms of interaction with AI, each with its own distinct set of norms, ethical considerations, and psychological implications. The challenge lies not in preventing these new forms of connection from emerging, but in proactively and thoughtfully guiding their development towards ethical and beneficial outcomes. This requires a nuanced understanding that not all AI interactions are equivalent; what is appropriate and beneficial for an AI work collaborator <sup>6</sup> will differ significantly from the considerations for an AI romantic partner <sup>5</sup> or a therapeutic AI agent.<sup>28</sup> The ultimate objective, as echoed in many foundational ethical principles for AI <sup>43</sup>, must be to ensure that these diverse forms of human-AI relationships contribute positively to human well-being, enhance the social fabric, and support individual flourishing rather than eroding these vital aspects of human life. This necessitates a proactive, collaborative, and ongoing societal commitment to defining what "augmentation" and "benefit" mean in each distinct relational context, ensuring that technology serves humanity's highest aspirations.

Through conscious effort, ethically grounded development, continuous societal dialogue, and a commitment to understanding the deep interplay between humans and intelligent machines, it is possible to steer the evolution of human-AI relationships. The goal is not merely to coexist, but to co-flourish, creating a future where AI enriches human lives, supports our deepest needs for connection and understanding, and helps us build a more capable, compassionate, and connected world.


#### Works cited



1. The Symbiotic Relationship of Humans and AI | ORMS Today - PubsOnLine, accessed May 7, 2025, [https://pubsonline.informs.org/do/10.1287/orms.2025.01.09/full/](https://pubsonline.informs.org/do/10.1287/orms.2025.01.09/full/)
2. Artificial Intelligence Index Report 2025 - AWS, accessed May 7, 2025, [https://hai-production.s3.amazonaws.com/files/hai_ai_index_report_2025.pdf](https://hai-production.s3.amazonaws.com/files/hai_ai_index_report_2025.pdf)
3. Why human-AI relationships need socioaffective alignment - arXiv, accessed May 7, 2025, [https://arxiv.org/html/2502.02528v1](https://arxiv.org/html/2502.02528v1)
4. Superagency in the workplace: Empowering people to unlock AI's full potential - McKinsey & Company, accessed May 7, 2025, [https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/superagency-in-the-workplace-empowering-people-to-unlock-ais-full-potential-at-work](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/superagency-in-the-workplace-empowering-people-to-unlock-ais-full-potential-at-work)
5. (PDF) The Rise of AI Relationships: A New Frontier in Human ..., accessed May 7, 2025, [https://www.researchgate.net/publication/386086142_The_Rise_of_AI_Relationships_A_New_Frontier_in_Human_Connection_Predicting_the_Future_of_Human-AI_Relationships](https://www.researchgate.net/publication/386086142_The_Rise_of_AI_Relationships_A_New_Frontier_in_Human_Connection_Predicting_the_Future_of_Human-AI_Relationships)
6. Top Frameworks for Effective Human-AI Collaboration: Building Smarter Systems Together, accessed May 7, 2025, [https://smythos.com/ai-integrations/ai-integration/human-ai-collaboration-frameworks/](https://smythos.com/ai-integrations/ai-integration/human-ai-collaboration-frameworks/)
7. Overview ‹ Moonshot: Atlas of Human-AI Interaction — MIT Media Lab, accessed May 7, 2025, [https://www.media.mit.edu/projects/atlas-of-human-ai-interaction/overview/](https://www.media.mit.edu/projects/atlas-of-human-ai-interaction/overview/)
8. 5 Ways AI Is Changing Human Relationships | Psychology Today, accessed May 7, 2025, [https://www.psychologytoday.com/us/blog/all-about-addiction/202504/5-ways-ai-is-changing-human-relationships](https://www.psychologytoday.com/us/blog/all-about-addiction/202504/5-ways-ai-is-changing-human-relationships)
9. Why human-AI relationships need socioaffective alignment arXiv:2502.02528v1 [cs.HC] 4 Feb 2025, accessed May 7, 2025, [https://arxiv.org/pdf/2502.02528](https://arxiv.org/pdf/2502.02528)
10. Summer School on Artificial Intelligence (AI), Ethics and Human Rights, 23 -27 June 2025, Hybrid Format: Rome (Italy) and online | UNICRI, accessed May 7, 2025, [https://unicri.org/advanced-education-artificial-intelligence-ai-ethics-human-rights-2025](https://unicri.org/advanced-education-artificial-intelligence-ai-ethics-human-rights-2025)
11. Public Opinion | The 2025 AI Index Report | Stanford HAI, accessed May 7, 2025, [https://hai.stanford.edu/ai-index/2025-ai-index-report/public-opinion](https://hai.stanford.edu/ai-index/2025-ai-index-report/public-opinion)
12. Ai & Society (Springer Nature) | 2394 Publications | 10344 Citations | Top authors | Related journals - SciSpace, accessed May 7, 2025, [https://scispace.com/journals/ai-society-6ghf262z](https://scispace.com/journals/ai-society-6ghf262z)
13. Identifying the Public's Beliefs about Generative Artificial Intelligence: A Big Data Approach, accessed May 7, 2025, [https://eprints.whiterose.ac.uk/id/eprint/222962/1/TEM.pdf](https://eprints.whiterose.ac.uk/id/eprint/222962/1/TEM.pdf)
14. How reactions to AI are shaped by cultural differences, accessed May 7, 2025, [https://dobetter.esade.edu/en/AI-cultural-differences](https://dobetter.esade.edu/en/AI-cultural-differences)
15. Full article: Cross-cultural perspectives on AI adoption in teacher education: a comparative study of pre-service teachers in Turkey and the United Arab Emirates - Taylor & Francis Online, accessed May 7, 2025, [https://www.tandfonline.com/doi/full/10.1080/10494820.2025.2488143?src=exp-la](https://www.tandfonline.com/doi/full/10.1080/10494820.2025.2488143?src=exp-la)
16. arXiv:2503.03067v1 [cs.HC] 5 Mar 2025, accessed May 7, 2025, [http://www.arxiv.org/pdf/2503.03067](http://www.arxiv.org/pdf/2503.03067)
17. The Real Her? Exploring Whether Young Adults Accept Human-AI Love - arXiv, accessed May 7, 2025, [https://arxiv.org/html/2503.03067v1](https://arxiv.org/html/2503.03067v1)
18. www.sacap.edu.za, accessed May 7, 2025, [https://www.sacap.edu.za/blog/applied-psychology/perspectives-on-ai-relationships/#:~:text=Psychological%20Impacts%20of%20AI%20Relationships&text=AI%20companions%20have%20the%20potential,a%20false%20sense%20of%20intimacy.](https://www.sacap.edu.za/blog/applied-psychology/perspectives-on-ai-relationships/#:~:text=Psychological%20Impacts%20of%20AI%20Relationships&text=AI%20companions%20have%20the%20potential,a%20false%20sense%20of%20intimacy.)
19. How AI Could Shape Our Relationships and Social Interactions ..., accessed May 7, 2025, [https://www.psychologytoday.com/us/blog/urban-survival/202502/how-ai-could-shape-our-relationships-and-social-interactions](https://www.psychologytoday.com/us/blog/urban-survival/202502/how-ai-could-shape-our-relationships-and-social-interactions)
20. Therapeutic Potential of Social Chatbots in Alleviating Loneliness ..., accessed May 7, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC11775481/](https://pmc.ncbi.nlm.nih.gov/articles/PMC11775481/)
21. What People Share With a Robot When Feeling Lonely and Stressed and How It Helps Over Time - arXiv, accessed May 7, 2025, [https://arxiv.org/html/2504.02991v1](https://arxiv.org/html/2504.02991v1)
22. AI Companions in 2025: How “Her” Predicted the Future of Love and ..., accessed May 7, 2025, [https://agewisecolorado.org/blog/ai-companions-in-2025-how-her-predicted-the-future-of-love-and-technology/](https://agewisecolorado.org/blog/ai-companions-in-2025-how-her-predicted-the-future-of-love-and-technology/)
23. AI chatbots and companions – risks to children and young people | eSafety Commissioner, accessed May 7, 2025, [https://www.esafety.gov.au/newsroom/blogs/ai-chatbots-and-companions-risks-to-children-and-young-people](https://www.esafety.gov.au/newsroom/blogs/ai-chatbots-and-companions-risks-to-children-and-young-people)
24. Study warns AI companions may erode human social skills, create "empathy atrophy", accessed May 7, 2025, [https://getcoai.com/news/study-warns-ai-companions-may-erode-human-social-skills-create-empathy-atrophy/](https://getcoai.com/news/study-warns-ai-companions-may-erode-human-social-skills-create-empathy-atrophy/)
25. How Artificial Intelligence Is Reshaping Relationships | Psychology Today, accessed May 7, 2025, [https://www.psychologytoday.com/us/blog/the-digital-self/202406/how-artificial-intelligence-is-reshaping-relationships](https://www.psychologytoday.com/us/blog/the-digital-self/202406/how-artificial-intelligence-is-reshaping-relationships)
26. Are AI lovers replacing real romantic partners? Surprising findings ..., accessed May 7, 2025, [https://www.psypost.org/are-ai-lovers-replacing-real-romantic-partners-surprising-findings-from-new-research/](https://www.psypost.org/are-ai-lovers-replacing-real-romantic-partners-surprising-findings-from-new-research/)
27. Study Looks at Public Opinion on the Use of AI Chatbots as Romantic Partners, accessed May 7, 2025, [https://www.socialmediatoday.com/news/stanford-study-ai-bots-as-companions/744964/](https://www.socialmediatoday.com/news/stanford-study-ai-bots-as-companions/744964/)
28. 3 Ways AI Could Aid Behavioral Health Screenings | AHA - American Hospital Association, accessed May 7, 2025, [https://www.aha.org/2025-04-15-3-ways-ai-could-aid-behavioral-health-screenings](https://www.aha.org/2025-04-15-3-ways-ai-could-aid-behavioral-health-screenings)
29. Generative AI–Enabled Therapy Support Tool for Improved Clinical ..., accessed May 7, 2025, [https://www.jmir.org/2025/1/e60435](https://www.jmir.org/2025/1/e60435)
30. (PDF) Artificial intelligence conversational agents in mental health ..., accessed May 7, 2025, [https://www.researchgate.net/publication/388573609_Artificial_intelligence_conversational_agents_in_mental_health_Patients_see_potential_but_prefer_humans_in_the_loop](https://www.researchgate.net/publication/388573609_Artificial_intelligence_conversational_agents_in_mental_health_Patients_see_potential_but_prefer_humans_in_the_loop)
31. Exploring the Ethical Challenges of Conversational AI in Mental Health Care: Scoping Review - XSL•FO, accessed May 7, 2025, [https://mental.jmir.org/2025/1/e60432/PDF](https://mental.jmir.org/2025/1/e60432/PDF)
32. The future is already here: AI and education in 2025 - Stanford Accelerator for Learning, accessed May 7, 2025, [https://acceleratelearning.stanford.edu/story/the-future-is-already-here-ai-and-education-in-2025/](https://acceleratelearning.stanford.edu/story/the-future-is-already-here-ai-and-education-in-2025/)
33. 2025-26 Institute on AI, Pedagogy, and the Curriculum | AAC&U, accessed May 7, 2025, [https://www.aacu.org/event/2025-26-institute-ai-pedagogy-curriculum](https://www.aacu.org/event/2025-26-institute-ai-pedagogy-curriculum)
34. (PDF) Systematic Literature Review of AI-based Mentoring in Higher ..., accessed May 7, 2025, [https://www.researchgate.net/publication/389776359_Systematic_Literature_Review_of_AI-based_Mentoring_in_Higher_Education](https://www.researchgate.net/publication/389776359_Systematic_Literature_Review_of_AI-based_Mentoring_in_Higher_Education)
35. The New Creative Alliance: Investigating the Dynamics of Human-AI Collaboration in Creative Endeavours - Apollo - University of Cambridge, accessed May 7, 2025, [https://www.repository.cam.ac.uk/items/ea398f8e-b370-4a27-ab7e-873fe5be8842](https://www.repository.cam.ac.uk/items/ea398f8e-b370-4a27-ab7e-873fe5be8842)
36. ojs.aaai.org, accessed May 7, 2025, [https://ojs.aaai.org/index.php/AIES/article/download/31694/33861/35758](https://ojs.aaai.org/index.php/AIES/article/download/31694/33861/35758)
37. Longitudinal Study on Social and Emotional Use of AI Conversational Agent - arXiv, accessed May 7, 2025, [https://arxiv.org/html/2504.14112v1](https://arxiv.org/html/2504.14112v1)
38. www.arxiv.org, accessed May 7, 2025, [https://www.arxiv.org/pdf/2504.14112](https://www.arxiv.org/pdf/2504.14112)
39. www.eurekalert.org, accessed May 7, 2025, [https://www.eurekalert.org/news-releases/1079301#:~:text=%E2%80%9CA%20real%20worry%20is%20that,AIs%20can%20offer%20harmful%20advice.](https://www.eurekalert.org/news-releases/1079301#:~:text=%E2%80%9CA%20real%20worry%20is%20that,AIs%20can%20offer%20harmful%20advice.)
40. The role of socio-emotional attributes in enhancing human-AI ..., accessed May 7, 2025, [https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1369957/full](https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1369957/full)
41. A conceptual ethical framework to preserve natural ... - Frontiers, accessed May 7, 2025, [https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1377938/full](https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1377938/full)
42. Ethical AI for Teaching and Learning - Center for Teaching Innovation - Cornell University, accessed May 7, 2025, [https://teaching.cornell.edu/generative-artificial-intelligence/ethical-ai-teaching-and-learning](https://teaching.cornell.edu/generative-artificial-intelligence/ethical-ai-teaching-and-learning)
43. standards.ieee.org, accessed May 7, 2025, [https://standards.ieee.org/wp-content/uploads/import/documents/other/ead_general_principles.pdf](https://standards.ieee.org/wp-content/uploads/import/documents/other/ead_general_principles.pdf)
44. AI Ethics - IBM, accessed May 7, 2025, [https://www.ibm.com/artificial-intelligence/ai-ethics](https://www.ibm.com/artificial-intelligence/ai-ethics)
45. Ethical AI - The Decision Lab, accessed May 7, 2025, [https://thedecisionlab.com/reference-guide/computer-science/ethical-ai](https://thedecisionlab.com/reference-guide/computer-science/ethical-ai)
46. ETHICS GUIDELINES FOR TRUSTWORTHY AI, accessed May 7, 2025, [https://www.aepd.es/sites/default/files/2019-12/ai-ethics-guidelines.pdf](https://www.aepd.es/sites/default/files/2019-12/ai-ethics-guidelines.pdf)
47. Ethical considerations in the use of social robots for supporting mental health and wellbeing in older adults in long-term care - Frontiers, accessed May 7, 2025, [https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2025.1560214/full](https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2025.1560214/full)
48. Ethically Aligned Design - IEEE Standards Association, accessed May 7, 2025, [https://standards.ieee.org/wp-content/uploads/import/documents/other/ead_v1.pdf](https://standards.ieee.org/wp-content/uploads/import/documents/other/ead_v1.pdf)
49. Leveraging Professional Ethics for Responsible AI - Communications of the ACM, accessed May 7, 2025, [https://cacm.acm.org/opinion/leveraging-professional-ethics-for-responsible-ai/](https://cacm.acm.org/opinion/leveraging-professional-ethics-for-responsible-ai/)