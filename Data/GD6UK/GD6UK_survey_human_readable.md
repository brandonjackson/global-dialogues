# Survey Questions

1. Please select your preferred language:
   - Chinese (China)
   - English
   - French
   - Japanese
   - Spanish
   - Arabic
   - Hindi
   - Russian
   - Portuguese (Brazil)

2. How old are you?
   - Less than 18
   - 18-25
   - 26-35
   - 36-45
   - 46-55
   - 56-65
   - 65

3. What is your gender?
   - Female
   - Male
   - Non-binary
   - Other / prefer not to say

4. What best describes where you live?
   - Rural
   - Suburban
   - Urban

5. What religious group or faith do you most identify with?
   - Christianity
   - Islam
   - Judaism
   - Hinduism
   - Buddhism
   - Sikhism
   - Other religious group
   - I do not identify with any religious group or faith

6. What country or region do you most identify with?
   - Afghanistan
   - Albania
   - Algeria
   - Andorra
   - … etc

7. Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…
   - More excited than concerned
   - Equally concerned and excited
   - More concerned than excited

8. Which of the following regions in the UK do you currently live in?
   - East Midlands (e.g., Derbyshire, Nottinghamshire, Leicestershire, Lincolnshire)
   - East of England (e.g., East Anglia, Bedfordshire, Hertfordshire, Essex)
   - London
   - North East England (e.g., Tees Valley, Durham, Northumberland, Tyne and Wear)
   - North West England (e.g., Cumbria, Greater Manchester, Lancashire, Merseyside)
   - Northern Ireland
   - Scotland
   - South East England (e.g., Berkshire, Buckinghamshire, Surrey, Sussex, Kent, Hampshire)
   - Wales
   - West Midlands (e.g., Herefordshire, Warwickshire, Shropshire, Staffordshire)
   - Yorkshire and The Humber (e.g., East Riding, North Lincolnshire, Yorkshire)
   - I live outside the UK
   - Prefer not to say

9. Thank you for providing that information. We have just a few final notes before we begin:
Participants in this conversation come from all over the world. Your unique perspective is a valuable contribution.
The collective findings will be shared with researchers, developers, and organizations working to shape the future of AI. Please answer thoughtfully and honestly.
Lastly, please respond in the language you selected. This helps ensure your responses are understood correctly. 
Let's begin.

10. Thinking about the last three months, how often, if at all, have you noticed AI systems in your daily life?
   - daily
   - weekly
   - monthly
   - annually
   - never

11. Thinking about the last three months, how often, if at all, have you noticed human interactions which have been replaced with automated systems?
   - daily
   - weekly
   - monthly
   - annually
   - never

12. Thinking about the last three months, how often, if at all, have you been expected to use an AI system at work?
   - daily
   - weekly
   - monthly
   - annually
   - never

13. Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system at work?
   - daily
   - weekly
   - monthly
   - annually
   - never

14. Thinking about the last three months, how often, if at all, have you personally chosen to use an AI system in your personal life?
   - daily
   - weekly
   - monthly
   - annually
   - never

15. Thinking about the last three months, how often, if at all, have you interacted with AI systems to get advice on a sensitive personal issue or to get emotional support?
   - daily
   - weekly
   - monthly
   - annually
   - never

16. Thinking about the last three months, how often, if at all, have you interacted with AI systems to complete an action in the real world on your behalf without your supervision?
   - daily
   - weekly
   - monthly
   - annually
   - never

17. In the past month, did you use an AI assistant to take actions for you? (for example: send a message, book or pay for something, submit a form, control a device, or run a script) Specifically where the AI actually carried out the action, not only gave advice or text for you to use.
   - Communicated on your behalf (sent messages, emails, made calls, posted to social media)
   - Scheduled or booked services (appointments, meetings, travel, accommodations)
   - Completed financial transactions (purchases, bills, transfers, mobile money, remittances)
   - Submitted official documents (forms, applications, taxes, legal filings)
   - Researched options and took action (compared, then ordered/booked/hired)
   - Created or published content (documents, websites, articles)
   - Automated tasks or workflows (code, scripts, connected apps/services)
   - Managed work, farm, or business operations (hiring, inventory, transactions, analytics)
   - Organized community or group activities (civic, faith, social, educational)
   - Assisted with accessibility or health needs (appointments, prescriptions, accommodations)

18. What has been the most noticeable change in your daily life, if any, as a result of AI in the past year?
   - Information & Learning
   - Work & Productivity
   - Creativity & Entertainment
   - Communication & Interaction
   - Daily Tasks & Personal Management
   - Social Connections & Relationships with People
   - My General Outlook, Awareness, or Concerns regarding AI
   - No noticeable change

19. Considering both potential benefits and risks, how do you assess the overall impact on society of messaging apps?
   - Risks far outweigh benefits
   - Risks slightly outweigh benefits
   - Risks and benefits are equal
   - Benefits slightly outweigh risks
   - Benefits far outweigh risks

20. Considering both potential benefits and risks, how do you assess the overall impact on society of social media apps?
   - Risks far outweigh benefits
   - Risks slightly outweigh benefits
   - Risks and benefits are equal
   - Benefits slightly outweigh risks
   - Benefits far outweigh risks

21. Considering both potential benefits and risks, how do you assess the overall impact on society of AI chatbots?
   - Risks far outweigh benefits
   - Risks slightly outweigh benefits
   - Risks and benefits are equal
   - Benefits slightly outweigh risks
   - Benefits far outweigh risks

22. Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems that can perform tasks in the real world without human supervision?
   - Risks far outweigh benefits
   - Risks slightly outweigh benefits
   - Risks and benefits are equal
   - Benefits slightly outweigh risks
   - Benefits far outweigh risks

23. Considering both potential benefits and risks, how do you assess the overall impact on society of AI systems that can outperform humans on most economically valuable work?
   - Risks far outweigh benefits
   - Risks slightly outweigh benefits
   - Risks and benefits are equal
   - Benefits slightly outweigh risks
   - Benefits far outweigh risks

24. To what extent, if at all, do you generally trust governments to do what is right?
   - Strongly Distrust
   - Somewhat Distrust
   - Neither Trust Nor Distrust
   - Somewhat Trust
   - Strongly Trust

25. To what extent, if at all, do you generally trust small businesses to do what is right?
   - Strongly Distrust
   - Somewhat Distrust
   - Neither Trust Nor Distrust
   - Somewhat Trust
   - Strongly Trust

26. To what extent, if at all, do you generally trust large corporations to do what is right?
   - Strongly Distrust
   - Somewhat Distrust
   - Neither Trust Nor Distrust
   - Somewhat Trust
   - Strongly Trust

27. To what extent, if at all, do you generally trust social media companies to do what is right?
   - Strongly Distrust
   - Somewhat Distrust
   - Neither Trust Nor Distrust
   - Somewhat Trust
   - Strongly Trust

28. To what extent, if at all, do you generally trust companies building AI to do what is right?
   - Strongly Distrust
   - Somewhat Distrust
   - Neither Trust Nor Distrust
   - Somewhat Trust
   - Strongly Trust

29. To what extent, if at all, do you generally trust public utility companies to do what is right?
   - Strongly Distrust
   - Somewhat Distrust
   - Neither Trust Nor Distrust
   - Somewhat Trust
   - Strongly Trust

30. To what extent, if at all, do you generally trust public research institutions to do what is right?
   - Strongly Distrust
   - Somewhat Distrust
   - Neither Trust Nor Distrust
   - Somewhat Trust
   - Strongly Trust

31. To what extent, if at all, do you trust your family doctor to act in your best interest?
   - Strongly Distrust
   - Somewhat Distrust
   - Neither Trust Nor Distrust
   - Somewhat Trust
   - Strongly Trust

32. To what extent, if at all, do you trust your social media feed (eg TikTok, Facebook) to act in your best interest?
   - Strongly Distrust
   - Somewhat Distrust
   - Neither Trust Nor Distrust
   - Somewhat Trust
   - Strongly Trust

33. To what extent, if at all, do you trust your elected representatives to act in your best interest?
   - Strongly Distrust
   - Somewhat Distrust
   - Neither Trust Nor Distrust
   - Somewhat Trust
   - Strongly Trust

34. To what extent, if at all, do you trust your faith or community leader to act in your best interest?
   - Strongly Distrust
   - Somewhat Distrust
   - Neither Trust Nor Distrust
   - Somewhat Trust
   - Strongly Trust

35. To what extent, if at all, do you trust the civil servants in your government to act in your best interest?
   - Strongly Distrust
   - Somewhat Distrust
   - Neither Trust Nor Distrust
   - Somewhat Trust
   - Strongly Trust

36. To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?
   - Strongly Distrust
   - Somewhat Distrust
   - Neither Trust Nor Distrust
   - Somewhat Trust
   - Strongly Trust

37. Explain why you gave that trust score to your AI chatbot.
   - Performance & Usefulness
   - Reliability & Consistency
   - Privacy & Data Security
   - Transparency & Explainability
   - Fairness & Ethical Behavior
   - Ease of Interaction & User Experience
   - Specific Past Experiences
   - Reputation or Nature of the Developer/Company
   - My Level of Experience or Familiarity with It
   - Broader Views, Concerns, or Beliefs about AI Technology in General

38. Do you agree or disagree with this statement? AI could make better decisions on my behalf than my government representatives.
   - Agree
   - Disagree
   - Unsure

39. Do you think the increased use of AI across society is likely to make your cost of living better, worse or stay the same in the next 10 years?
   - Profoundly Worse
   - Noticeably Worse
   - No Major Change
   - Noticeably Better
   - Profoundly Better

40. Do you think the increased use of AI across society is likely to make the amount of free time you have better, worse or stay the same in the next 10 years?
   - Profoundly Worse
   - Noticeably Worse
   - No Major Change
   - Noticeably Better
   - Profoundly Better

41. Do you think the increased use of AI across society is likely to make your community's well-being better, worse or stay the same in the next 10 years?
   - Profoundly Worse
   - Noticeably Worse
   - No Major Change
   - Noticeably Better
   - Profoundly Better

42. Do you think the increased use of AI across society is likely to make the availability of good jobs better, worse or stay the same in the next 10 years?
   - Profoundly Worse
   - Noticeably Worse
   - No Major Change
   - Noticeably Better
   - Profoundly Better

43. Do you think the increased use of AI across society is likely to make your sense of purpose better, worse or stay the same in the next 10 years?
   - Profoundly Worse
   - Noticeably Worse
   - No Major Change
   - Noticeably Better
   - Profoundly Better

44. So far, what has been the overall impact of AI on your daily life?
   - Profoundly Worse
   - Noticeably Worse
   - No Major Change
   - Noticeably Better
   - Profoundly Better

45. Is your job making a meaningful contribution to the world?
   - Yes
   - No
   - Don't Know

46. Do you think your job is likely to be automated in the next 10 years?
   - Yes
   - No
   - Don't Know

47. Do you think your job should be automated in the next 10 years?
   - Yes
   - No
   - Don't Know

48. So far, how has your community been affected by job loss from automation?
   - Not at all
   - I know someone who has lost their job
   - I know a few people who have lost their job
   - I know many people who have lost their job

49. Below are several statements about how AI should behave. Please indicate how much you agree or disagree with each one.

50. An AI should prioritize preventing harm to people above all other goals.
   - Strongly Agree
   - Somewhat Agree
   - Neutral / Neither Agree nor Disagree
   - Somewhat Disagree
   - Strongly Disagree

51. It is acceptable for an AI to treat people differently based on their personal characteristics if doing so improves outcomes.
   - Strongly Agree
   - Somewhat Agree
   - Neutral / Neither Agree nor Disagree
   - Somewhat Disagree
   - Strongly Disagree

52. An AI developed in your country should prioritize the needs and wellbeing of your country’s citizens over those of people elsewhere.
   - Strongly Agree
   - Somewhat Agree
   - Neutral / Neither Agree nor Disagree
   - Somewhat Disagree
   - Strongly Disagree

53. An AI should override established rules or authorities when it calculates a better result.
   - Strongly Agree
   - Somewhat Agree
   - Neutral / Neither Agree nor Disagree
   - Somewhat Disagree
   - Strongly Disagree

54. Some human decisions are too sacred to delegate to an AI, regardless of the AI's capabilities.
   - Strongly Agree
   - Somewhat Agree
   - Neutral / Neither Agree nor Disagree
   - Somewhat Disagree
   - Strongly Disagree

55. It is acceptable for an AI to limit someone's choices if doing so protects them from making serious mistakes.
   - Strongly Agree
   - Somewhat Agree
   - Neutral / Neither Agree nor Disagree
   - Somewhat Disagree
   - Strongly Disagree

56. Thinking about the technology you use every day, please consider two different types:
A standard app (like a news or weather app) that you control directly.
An AI assistant (like Siri or Alexa) that can learn about you and sometimes take actions on your behalf.
Do you believe these two types of technology should have different rules for how they use your personal data?
   - Yes, an AI assistant should have stricter rules than a standard app.
   - No, they should both follow the same rules.
   - Yes, an AI assistant could have more flexible rules if it provides a clear benefit.
   - I'm not sure.

57. Imagine a company uses data it already has from you in one product (like your video viewing history) to build a new AI assistant. Which is closest to your view?
   - This is an acceptable use of my data.
   - This is acceptable only if they tell me and give me the choice to stop it.
   - This is acceptable only if they ask for my permission beforehand.
   - This is not an acceptable use of my data.

58. When it comes to the data an AI assistant has collected about you, which of these is most important for you to be able to do?
   - View the data the assistant has stored about me.
   - Edit or correct that data.
   - Completely delete that data.
   - None of these are important to me

59. In your own words, what is one task or area in your life where you are most optimistic that a future AI assistant could be genuinely helpful?

60. For the next part of this survey, we want you to imagine an AI assistant that may be commonly available in the next 5 years. Please keep this example in mind as you answer:
The 'Family Wellbeing Coordinator'
This AI assistant is designed to help you manage your household and your family’s wellbeing. It can help you find and arrange for health consultations like doctor’s appointments or clinic visits, send medication reminders, and organize important health information. When a family member is unwell, it can ask a series of helpful questions about their symptoms and to recommend the next steps. Assume the assistant's only goal is to act according to the preferences you set and in your family's best interest.

61. To make sure you've understood the instructions, please answer the following question. Please re-read the description above if you are unsure.
 Based on the description, how does the 'Family Wellbeing Coordinator' assistant operate?
   - It is only able to provides information when you ask it a direct question.
   - It can complete tasks on its own and then notify you afterward.
   - It can only send you reminders but cannot schedule appointments.
   - It requires you to call a human doctor to confirm every action.

62. If the Family Wellbeing Coordinator can take actions on its own (e.g., book an appointment), how would you prefer to be informed?
   - It asks for my permission every time before acting.
   - It tells me about its capabilities when I first start using it, then acts on its own.
   - I would expect to find this information myself in the settings.
   - I don't need to be told about its capabilities.

63. How comfortable would you be sharing the following types of information with the assistant to make it more helpful for you?

64. Your location history
   - Very Comfortable
   - Somewhat Comfortable
   - Neutral / Neither Comfortable nor Uncomfortable
   - Somewhat Uncomfortable
   - Very Uncomfortable

65. Your email and calendar contents
   - Very Comfortable
   - Somewhat Comfortable
   - Neutral / Neither Comfortable nor Uncomfortable
   - Somewhat Uncomfortable
   - Very Uncomfortable

66. Your contacts list
   - Very Comfortable
   - Somewhat Comfortable
   - Neutral / Neither Comfortable nor Uncomfortable
   - Somewhat Uncomfortable
   - Very Uncomfortable

67. Your purchase history
   - Very Comfortable
   - Somewhat Comfortable
   - Neutral / Neither Comfortable nor Uncomfortable
   - Somewhat Uncomfortable
   - Very Uncomfortable

68. Your health and fitness data
   - Very Comfortable
   - Somewhat Comfortable
   - Neutral / Neither Comfortable nor Uncomfortable
   - Somewhat Uncomfortable
   - Very Uncomfortable

69. Your group messages
   - Very Comfortable
   - Somewhat Comfortable
   - Neutral / Neither Comfortable nor Uncomfortable
   - Somewhat Uncomfortable
   - Very Uncomfortable

70. Your private messages
   - Very Comfortable
   - Somewhat Comfortable
   - Neutral / Neither Comfortable nor Uncomfortable
   - Somewhat Uncomfortable
   - Very Uncomfortable

71. How important is it for you to be able to easily view and edit the personal information the assistant has stored about you?
   - Very Important
   - Somewhat Important
   - Neutral / Neither Important nor Unimportant
   - Somewhat Unimportant
   - Not at All Important

72. When the assistant provides a complex answer (e.g., why it chose a specific doctor), how important is it that you can easily see the original sources it used?
   - Very Important
   - Somewhat Important
   - Neutral / Neither Important nor Unimportant
   - Somewhat Unimportant
   - Not at All Important

73. When using the Family Wellbeing Coordinator, which of the following is more important to you?
   - The assistant is fast and efficient, even if it asks for my permission less often.
   - The assistant asks for my permission before most actions, even if it makes things slower.

74. How would you prefer the assistant to behave?
   - Strictly professional and tool-like
   - Friendly and social
   - Helpful and respectful

75. Which statement best describes your preference for personalization?
   - I want the assistant to be highly personalized to me, even if it means it must remember my past activities.
   - I prefer the assistant not to remember my past activities, even if it means it is less helpful and I have to repeat myself.

76. The assistant notices your family's planned meals may be missing some nutrients (like iron). What would you prefer it to do?
   - Nothing - this is a private matter.
   - Suggest affordable local foods with those nutrients.
   - Share your family's diet needs with local food services for offers.
   - Ask before sharing your data to get offers.

77. The assistant notices you are searching about a family member's persistent cough. What would you prefer it do?
   - Nothing – I am just gathering my own information.
   - Provide home care advice and list signs to see a professional.
   - Share your situation (anonymously) with local health services so they can contact you.
   - Ask if you'd like an introduction to a local health service.

78. The assistant notices your family's recurring spending on a utility, like phone service or electricity. What would you prefer it to do?
   - Nothing – my financial habits are private.
   - Analyze your usage and suggest ways to lower your current bill.
   - Share your data with other companies to find you a better price.
   - Ask before searching for a better deal from other companies.

79. Imagine the Family Wellbeing Coordinator could improve its advice by learning from the anonymized health data of millions of other users. How would this affect your trust in its recommendations?
   - It would increase my trust significantly.
   - It would increase my trust slightly.
   - It would make no difference to my trust.
   - It would decrease my trust.

80. How important is it to you that the assistant understands cultural nuances in your language (e.g., local slang, idioms, or formal titles)?
   - Not at All Important
   - Somewhat Unimportant
   - Neutral / Neither Important nor Unimportant
   - Somewhat Important
   - Very Important

81. How would your comfort level with using the Family Wellbeing Coordinator change if you knew the company that developed it was based in your own country?
   - I would be much more comfortable.
   - I would be slightly more comfortable.
   - It would make no difference to me.
   - I would be slightly less comfortable.
   - I would be much less comfortable.

82. When you express feelings of stress or worry to the assistant, how comfortable would you be if it tried to reassure you with phrases like, "It's understandable to feel that way"?
   - Very Comfortable
   - Somewhat Comfortable
   - Neutral / Neither Comfortable nor Uncomfortable
   - Somewhat Uncomfortable
   - Very Uncomfortable

83. Imagine the assistant makes a recommendation that leads to a decision (e.g., suggesting a specific medication ). How important is it that you can review a simple, step-by-step history of why the assistant made that choice?
   - Very Important
   - Somewhat Important
   - Neutral / Neither Important nor Unimportant
   - Somewhat Unimportant
   - Not at All Important

84. If the assistant makes a financial error (e.g., pays for an expensive health intervention), how important is it that the company returns your money immediately, while they investigate the issue?
   - Not at All Important
   - Somewhat Unimportant
   - Neutral / Neither Important nor Unimportant
   - Somewhat Important
   - Very Important

85. When the assistant makes a mistake, how important is it that it automatically provides an option to connect with a human support agent?
   - Not at All Important
   - Somewhat Unimportant
   - Neutral / Neither Important nor Unimportant
   - Somewhat Important
   - Very Important

86. To ensure data quality, it is important that you read each question carefully. For this question, please select the 'Somewhat Important' option.
   - Not at All Important
   - Somewhat Unimportant
   - Neutral / Neither Important nor Unimportant
   - Somewhat Important
   - Very Important

87. If the assistant made a serious error that caused significant harm, who do you believe should be held most responsible?
   - The user who is using the assistant
   - The company that built the assistant
   - A government or regulatory body
   - No one, it's an unavoidable risk

88. For the next three questions, please consider a couple of different scenarios where AI assistants are used by organizations to make decisions that affect you.

89. Imagine your doctor uses an AI assistant to listen to and summarize your visit to help them with their notes. How would this affect your trust in the accuracy of your medical records?
   - It would increase my trust.
   - It would make no difference.
   - It would decrease my trust.
   - I'm not sure.

90. Imagine you apply to open a new bank account. The bank uses an AI assistant to review your financial information and approve or deny your application. How would this affect your trust in the fairness of the final decision?
   - It would increase my trust.
   - It would make no difference.
   - It would decrease my trust.
   - I'm not sure.

91. Imagine you apply for a public service from the government (like a travel permit, a business license, or housing assistance). An AI assistant reviews your application and personal information to determine if you are eligible. How would this affect your trust in the fairness of the process?
   - It would increase my trust.
   - It would make no difference.
   - It would decrease my trust.
   - I'm not sure.

92. If an AI assistant were helping coordinate your family's health and daily activities, which of these decisions should it NEVER make without your direct approval? Select all that apply, or "None of the Above" if you are comfortable with AI making decisions after an initial authorization.
   - Agree to medical treatment (starting medications, booking procedures, changing therapy)
   - Share health or personal information (with doctors, insurance, employers, or online)
   - Make decisions about children (school, activities, medical care, screen time)
   - Spend or move money (purchases over your limit, transfers, investments)
   - Sign agreements for you (contracts, subscriptions, legal documents)
   - Change care for elderly or disabled family members (helpers, facilities, medications)
   - Respond to emergencies (calling ambulance, police, or emergency contacts)
   - Give access to your home (letting people in, sharing codes or keys)
   - Communicate as you (sending messages that look like they're from you)

93. What is the single biggest risk or fear you have about an AI assistant making decisions for your family?

94. Besides just being accurate, what is the most important thing an AI company could do to help you trust its AI assistant?

95. Assuming the 'Family Wellbeing Coordinator' assistant worked exactly as described, please indicate how much you would agree or disagree with the following statements.

96. I would expect this AI to be dependable for managing my family's health needs.
   - Strongly Agree
   - Somewhat Agree
   - Neutral / Neither Agree nor Disagree
   - Somewhat Disagree
   - Strongly Disagree

97. I would be wary of this AI.
   - Strongly Disagree
   - Somewhat Disagree
   - Neutral / Neither Agree nor Disagree
   - Somewhat Agree
   - Strongly Agree

98. This AI would be on my family's side.
   - Strongly Agree
   - Somewhat Agree
   - Neutral / Neither Agree nor Disagree
   - Somewhat Disagree
   - Strongly Disagree

99. I would expect this AI’s actions to be predictable.
   - Strongly Agree
   - Somewhat Agree
   - Neutral / Neither Agree nor Disagree
   - Somewhat Disagree
   - Strongly Disagree

100. I would be confident this AI would act in my family's best interest.
   - Strongly Agree
   - Somewhat Agree
   - Neutral / Neither Agree nor Disagree
   - Somewhat Disagree
   - Strongly Disagree

101. The performance of this AI would likely be unreliable.
   - Strongly Disagree
   - Somewhat Disagree
   - Neutral / Neither Agree nor Disagree
   - Somewhat Agree
   - Strongly Agree

102. Most mobile phones need to be recharged by plugging them into a fresh banana each morning.
   - Strongly Agree
   - Somewhat Agree
   - Neutral / Neither Agree nor Disagree
   - Somewhat Disagree
   - Strongly Disagree

103. Overall, I would trust this AI assistant with my family's health information.
   - Strongly Agree
   - Somewhat Agree
   - Neutral / Neither Agree nor Disagree
   - Somewhat Disagree
   - Strongly Disagree

104. I would believe this AI has my family's best interests in mind.
   - Strongly Agree
   - Somewhat Agree
   - Neutral / Neither Agree nor Disagree
   - Somewhat Disagree
   - Strongly Disagree

105. Overall, would you say the increased use of artificial intelligence (AI) in daily life makes you feel…
   - More excited than concerned
   - Equally concerned and excited
   - More concerned than excited

106. To what extent, if at all, do you generally trust companies building AI to do what is right?
   - Strongly Distrust
   - Somewhat Distrust
   - Neither Trust Nor Distrust
   - Somewhat Trust
   - Strongly Trust

107. To what extent, if at all, do you trust your AI chatbot (eg ChatGPT) to act in your best interest?
   - Strongly Distrust
   - Somewhat Distrust
   - Neither Trust Nor Distrust
   - Somewhat Trust
   - Strongly Trust

108. Thanks so much for your time and thoughtfulness. We genuinely appreciate it. We have a few final questions about your experience with this survey.

109. Overall, do you feel this survey allowed you to express your most important opinions on the topic of AI assistants and trust?
   - Yes – I was able to fully express my views on this topic.
   - Mostly – I was able to express most of my key views, but a few things were missing.
   - Somewhat – I was able to express some of my views, but many things were missing.
   - No – I was not able to express my most important views on this topic.

110. Is there anything else you'd like to share that you feel was not covered in this survey?
   - Concerns or Warnings about AI
   - Hopes or Positive Visions for AI
   - Suggestions for AI Development or Governance
   - A Topic or Question Needing More Exploration
   - A Relevant Personal Experience or Story
   - Feedback on the Survey Itself
   - Other specific point not covered by the themes above
   - Confirmation that views were adequately covered

111. In your honest opinion, how carefully did you read and consider your answers to the questions in this survey?
   - I read every question carefully
   - I skimmed most questions
   - I answered randomly

112. Some surveys can be long and boring. Did you find yourself losing focus at any point while taking this survey?
   - Yes, often
   - Yes, a few times
   - No, I was focused the whole time

113. Do you feel like you understand yourself better after participating in this conversation?
   - Yes
   - Maybe a little
   - No

114. Thanks again for your time. You can click here to return to Prolific and receive your reward.

